// Copyright 2025 The IREE Authors
//
// Licensed under the Apache License v2.0 with LLVM Exceptions.
// See https://llvm.org/LICENSE.txt for license information.
// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception

#include "iree/compiler/Codegen/Dialect/PCF/IR/PCF.h"
#include "iree/compiler/Codegen/Dialect/PCF/IR/PCFOps.h"
#include "iree/compiler/Codegen/Dialect/PCF/Transforms/Passes.h"
#include "iree/compiler/Codegen/Dialect/PCF/Transforms/Transforms.h"
#include "llvm/ADT/STLExtras.h"
#include "llvm/ADT/SmallVectorExtras.h"
#include "mlir/Dialect/Affine/IR/AffineOps.h"
#include "mlir/Dialect/Arith/Utils/Utils.h"
#include "mlir/Dialect/SCF/IR/SCF.h"
#include "mlir/Dialect/Tensor/IR/Tensor.h"
#include "mlir/IR/BuiltinOps.h"
#include "mlir/IR/Dominance.h"
#include "mlir/IR/ValueRange.h"
#include "mlir/Interfaces/DestinationStyleOpInterface.h"
#include "mlir/Interfaces/InferTypeOpInterface.h"
#include "mlir/Interfaces/TilingInterface.h"
#include "mlir/Support/WalkResult.h"
#include "mlir/Transforms/GreedyPatternRewriteDriver.h"

#define DEBUG_TYPE "iree-pcf-fuse-consumers"

namespace mlir::iree_compiler::IREE::PCF {

#define GEN_PASS_DEF_FUSECONSUMERSPASS
#include "iree/compiler/Codegen/Dialect/PCF/Transforms/Passes.h.inc"

namespace {

struct FuseConsumersPass final
    : impl::FuseConsumersPassBase<FuseConsumersPass> {
  void runOnOperation() override;
};

struct FuseIntoGenericOp final : OpRewritePattern<IREE::PCF::GenericOp> {
  using Base::Base;
  LogicalResult matchAndRewrite(IREE::PCF::GenericOp genericOp,
                                PatternRewriter &rewriter) const override {
    ConsumerFusionParams params;
    TilingInterface fusionTarget;
    for (Operation *user : genericOp->getUsers()) {
      fusionTarget = dyn_cast<TilingInterface>(user);
      ConsumerFusionParams tempParams;
      if (fusionTarget && succeeded(matchTilableConsumer(
                              rewriter, genericOp, fusionTarget, tempParams))) {
        std::swap(params, tempParams);
        break;
      }
      fusionTarget = TilingInterface();
    }
    if (!fusionTarget) {
      // Match failure reason message generated by `matchTilableConsumer`.
      return failure();
    }
    fuseTilableConsumer(rewriter, genericOp, fusionTarget, params);
    return success();
  }
};

struct FuseIntoLoopOp final : OpRewritePattern<IREE::PCF::LoopOp> {
  using Base::Base;
  LogicalResult matchAndRewrite(IREE::PCF::LoopOp loopOp,
                                PatternRewriter &rewriter) const override {
    ConsumerFusionParams params;
    TilingInterface fusionTarget;
    for (Operation *user : loopOp->getUsers()) {
      fusionTarget = dyn_cast<TilingInterface>(user);
      ConsumerFusionParams tempParams;
      if (fusionTarget && succeeded(matchTilableConsumer(
                              rewriter, loopOp, fusionTarget, tempParams))) {
        std::swap(params, tempParams);
        break;
      }
      fusionTarget = TilingInterface();
    }
    if (!fusionTarget) {
      // Match failure reason message generated by `matchTilableConsumer`.
      return failure();
    }
    fuseTilableConsumer(rewriter, loopOp, fusionTarget, params);
    return success();
  }
};

struct FuseExtractSliceIntoLoopOp final
    : OpRewritePattern<tensor::ExtractSliceOp> {
  using Base::Base;
  LogicalResult matchAndRewrite(tensor::ExtractSliceOp extractSliceOp,
                                PatternRewriter &rewriter) const override {
    auto loopOp = extractSliceOp.getSource().getDefiningOp<IREE::PCF::LoopOp>();
    if (!loopOp) {
      return rewriter.notifyMatchFailure(extractSliceOp, "No loop op producer");
    }

    if (failed(fuseExtractSliceIntoProducerLoop(rewriter, loopOp,
                                                extractSliceOp))) {
      return failure();
    }
    return success();
  }
};

struct FuseExtractSliceIntoGenericOp final
    : OpRewritePattern<tensor::ExtractSliceOp> {
  using Base::Base;
  LogicalResult matchAndRewrite(tensor::ExtractSliceOp extractSliceOp,
                                PatternRewriter &rewriter) const override {
    auto genericOp =
        extractSliceOp.getSource().getDefiningOp<IREE::PCF::GenericOp>();
    if (!genericOp) {
      return rewriter.notifyMatchFailure(extractSliceOp,
                                         "No generic op producer");
    }

    if (failed(fuseExtractSliceIntoProducerGeneric(rewriter, genericOp,
                                                   extractSliceOp))) {
      return failure();
    }
    return success();
  }
};

struct FuseExpandShapeIntoGenericOp final
    : OpRewritePattern<tensor::ExpandShapeOp> {
  using Base::Base;
  LogicalResult matchAndRewrite(tensor::ExpandShapeOp expandOp,
                                PatternRewriter &rewriter) const override {
    IREE::PCF::GenericOp genericOp =
        expandOp.getSrc().getDefiningOp<IREE::PCF::GenericOp>();
    if (!genericOp) {
      return rewriter.notifyMatchFailure(expandOp, "no generic op producer");
    }
    return fuseExpandShapeIntoProducerGeneric(rewriter, genericOp, expandOp);
  }
};

struct FuseExpandShapeIntoLoopOp final
    : OpRewritePattern<tensor::ExpandShapeOp> {
  using Base::Base;
  LogicalResult matchAndRewrite(tensor::ExpandShapeOp expandOp,
                                PatternRewriter &rewriter) const override {
    IREE::PCF::LoopOp loopOp =
        expandOp.getSrc().getDefiningOp<IREE::PCF::LoopOp>();
    if (!loopOp) {
      return rewriter.notifyMatchFailure(expandOp, "no loop op producer");
    }
    return fuseExpandShapeIntoProducerLoop(rewriter, loopOp, expandOp);
  }
};

WalkResult verifyOperationLegality(Operation *op) {
  if (isa<UnrealizedConversionCastOp>(op)) {
    return WalkResult::interrupt();
  }
  return WalkResult::advance();
}

void FuseConsumersPass::runOnOperation() {
  RewritePatternSet patterns(&getContext());
  patterns.add<FuseIntoGenericOp, FuseIntoLoopOp>(&getContext());
  patterns.add<FuseExtractSliceIntoLoopOp, FuseExtractSliceIntoGenericOp>(
      &getContext());
  patterns.add<FuseExpandShapeIntoGenericOp, FuseExpandShapeIntoLoopOp>(
      &getContext());
  populatePCFDropUnusedResultPatterns(patterns);
  if (failed(applyPatternsGreedily(getOperation(), std::move(patterns)))) {
    return signalPassFailure();
  }

  // Verify that no unrealized conversion casts remain.
  if (getOperation()->walk(verifyOperationLegality).wasInterrupted()) {
    return signalPassFailure();
  }
}

//===---------------------------------------------------------------------===//
// Consumer fusion impls
//===---------------------------------------------------------------------===//

template <typename OpTy>
static LogicalResult
lookupProducerSlices(OpResult result,
                     SmallVectorImpl<PCF::WriteSliceOp> &slices) {
  OpTy owner = cast<OpTy>(result.getOwner());
  Value tiedArg = owner.getRegionRefArgs()[result.getResultNumber()];
  auto srefType = cast<PCF::ShapedRefType>(tiedArg.getType());
  if (!srefType.isReturnOnlySync()) {
    return failure();
  }
  for (auto user : tiedArg.getUsers()) {
    // We can ignore memory reads.
    if (isa<PCF::ReadSliceOp>(user)) {
      continue;
    }
    auto sliceOp = dyn_cast<PCF::WriteSliceOp>(user);
    // TODO: Support vector operands.
    if (!sliceOp || !isa<RankedTensorType>(sliceOp.getSourceType()) ||
        !sliceOp.hasUnitStride()) {
      return failure();
    }
    slices.push_back(sliceOp);
  }
  return success();
}

// Two cases: one operand with multiple producer slices or multiple operands
// with a single producer slice per operand.
// Currently multiple operands <-> multiple producers is unsupported.
template <typename OpTy>
static LogicalResult
matchTilableConsumerImpl(RewriterBase &rewriter, OpTy producerOp,
                         TilingInterface target, ConsumerFusionParams &params) {
  // To create a loop result we need either an initializer or a shape. This
  // can come from either ReifyRankedShapedTypeOpInterface or DPS. If the
  // operand being fused along is itself a destination we get the shape via
  // passthrough with the producer's init/shape.
  if (!isa<ReifyRankedShapedTypeOpInterface, DestinationStyleOpInterface>(
          *target)) {
    return rewriter.notifyMatchFailure(
        target, "unsupported non-reify result shapes or dps op");
  }

  SmallVector<unsigned> &targetOperands = params.operands;
  SetVector<unsigned> &targetResults = params.results;
  SmallVector<PCF::WriteSliceOp> &slices = params.slices;
  assert(targetOperands.empty() && "unexpected non-empty operand list");
  assert(targetResults.empty() && "unexpected non-empty result set");
  assert(slices.empty() && "unexpected non-empty slice list");
  mlir::DominanceInfo dominanceInfo(producerOp->getParentOp());
  // First collect the set of operands/results fused along. Additionally verify
  // dominance for other operands.
  for (OpOperand &operand : target->getOpOperands()) {
    auto opResult = dyn_cast<OpResult>(operand.get());
    if (opResult && opResult.getOwner() == producerOp) {
      targetOperands.push_back(operand.getOperandNumber());
      targetResults.insert(opResult.getResultNumber());
    } else {
      if (!dominanceInfo.dominates(operand.get(), producerOp)) {
        return rewriter.notifyMatchFailure(
            target, "unable to fuse due to operand dominance");
      }
    }
  }

  if (targetOperands.empty()) {
    return rewriter.notifyMatchFailure(target, "no operands to fuse along");
  }

  // This dominance check can be expensive in the most general case, however
  // the majority of tilable ops have no or small regions so in practice this
  // isn't so bad.
  WalkResult res = target->walk([&](Operation *containedOp) -> WalkResult {
    if (containedOp == target) {
      return WalkResult::advance();
    }
    bool dominates = llvm::all_of(containedOp->getOperands(), [&](Value v) {
      auto bbArg = dyn_cast<BlockArgument>(v);
      // Check if the tilable op owns the producer of this operand or if the
      // producer dominates the loop we're fusing into.
      Operation *owner = bbArg ? bbArg.getParentRegion()->getParentOp()
                               : cast<OpResult>(v).getOwner();
      return target->isAncestor(owner) ||
             dominanceInfo.dominates(v, producerOp);
    });
    return dominates ? WalkResult::advance() : WalkResult::interrupt();
  });
  if (res.wasInterrupted()) {
    return rewriter.notifyMatchFailure(
        target, "target region users don't dominate producer");
  }

  // Case 1: Single result to fuse along.
  if (targetResults.size() == 1) {
    unsigned resultIndex = *targetResults.begin();
    if (failed(lookupProducerSlices<OpTy>(producerOp->getOpResult(resultIndex),
                                          slices))) {
      return rewriter.notifyMatchFailure(producerOp,
                                         "non write slice producer");
    }

    for (PCF::WriteSliceOp writeSlice : slices) {
      SmallVector<SmallVector<OpFoldResult>> allOffsets(
          targetOperands.size(), writeSlice.getMixedOffsets());
      SmallVector<SmallVector<OpFoldResult>> allSizes(
          targetOperands.size(), writeSlice.getMixedSizes());
      if (!target.isOpFusableWithProducerSlices(targetOperands, allOffsets,
                                                allSizes)) {
        return rewriter.notifyMatchFailure(
            target, "unsupported fusion for single producer");
      }
    }
  } else {
    // Case 2: Multiple results. We must find the most dominated slice to use
    // as the insertion point in this case.
    int64_t leader = -1;
    for (auto operandIndex : targetOperands) {
      int64_t currNumSlices = slices.size();
      auto opResult = cast<OpResult>(target->getOperand(operandIndex));
      if (failed(lookupProducerSlices<OpTy>(opResult, slices))) {
        return rewriter.notifyMatchFailure(producerOp,
                                           "non write slice producer");
      }
      if (slices.size() - currNumSlices != 1) {
        return rewriter.notifyMatchFailure(
            target,
            "multiple operand fusion with multiple producers unsupported");
      }

      if (leader < 0) {
        leader = currNumSlices;
      } else {
        PCF::WriteSliceOp currLeader = slices[leader];
        PCF::WriteSliceOp next = slices.back();
        if (next != currLeader) {
          // Match for all writes within the same block to guarantee all
          // required result values are produced "together" (i.e. all required
          // operand slices are written at the same time by the same thread per
          // the *control flow* rather than just the slice offsets/shape).
          if (next->getBlock() != currLeader->getBlock()) {
            return rewriter.notifyMatchFailure(
                target, "unsupported different block insertion points");
          }
          if (dominanceInfo.dominates(currLeader, next)) {
            leader = currNumSlices;
          } else if (!dominanceInfo.dominates(next, currLeader)) {
            return rewriter.notifyMatchFailure(
                target, "could not find single insertion point for multiple "
                        "producer slices");
          }
        }
      }
    }
    SmallVector<SmallVector<OpFoldResult>> allOffsets = llvm::map_to_vector(
        slices, [](PCF::WriteSliceOp op) { return op.getMixedOffsets(); });
    SmallVector<SmallVector<OpFoldResult>> allSizes = llvm::map_to_vector(
        slices, [](PCF::WriteSliceOp op) { return op.getMixedSizes(); });
    if (!target.isOpFusableWithProducerSlices(targetOperands, allOffsets,
                                              allSizes)) {
      return rewriter.notifyMatchFailure(
          target, "unsupported fusion for multiple producer slices");
    }
    if (leader != 0) {
      // Swap the most dominant slice to the beginning.
      std::swap(slices[leader], slices[0]);
      std::swap(targetOperands[leader], targetOperands[0]);
    }
  }
  return success();
}

/// Fuses tilable op |target| into the list of |slices|, one per operand.
/// For example, if |operands| was [0, 2, 4], then the 3 entries in |slices|
/// correspond to the inputs for operands 0, 2, and 4 respectively.
/// The most dominant slice (i.e. the insertion point for the tiled + fused op)
/// is always assumed to be slices[0]. |newResultDests| is the list of new
/// DPS destinations for the tiled op to write to.
static void fuseIntoWriteSlices(RewriterBase &rewriter, TilingInterface target,
                                ArrayRef<unsigned> operands,
                                MutableArrayRef<PCF::WriteSliceOp> slices,
                                ValueRange newResultDests) {
  assert(operands.size() == slices.size() &&
         "expected same number of operands and slices to fuse into");
  OpBuilder::InsertionGuard g(rewriter);
  Location loc = target.getLoc();

  // The contract with the matcher is that the first slice in the list is the
  // most dominant and thus the insertion point for the fused op.
  rewriter.setInsertionPoint(slices.front());

  // Clone the op and replace all operands being fused along with unrealized
  // conversion casts from the distributed producer tile to the undistributed
  // tile. We will forward the input to the unrealized conversion cast directly
  // to the tiled op once finished.
  auto clonedOp = cast<TilingInterface>(rewriter.clone(*target));
  SmallVector<UnrealizedConversionCastOp> unrealizedConversions;
  for (auto [operand, slice] : llvm::zip_equal(operands, slices)) {
    OpOperand &currOperand = clonedOp->getOpOperand(operand);
    Type undistributedType = currOperand.get().getType();
    auto conversion = UnrealizedConversionCastOp::create(
        rewriter, loc, undistributedType, slice.getSource());
    currOperand.assign(conversion.getResult(0));
    unrealizedConversions.push_back(conversion);
  }

  // Get the iteration domain in terms of the operand tiles. This is required
  // to fetch the result tile positions. This and all subsequent interface
  // queries must succeed per the matcher check.
  SmallVector<SmallVector<OpFoldResult>> allOffsets = llvm::map_to_vector(
      slices, [](PCF::WriteSliceOp op) { return op.getMixedOffsets(); });
  SmallVector<SmallVector<OpFoldResult>> allSizes = llvm::map_to_vector(
      slices, [](PCF::WriteSliceOp op) { return op.getMixedSizes(); });
  SmallVector<OpFoldResult> iterDomainOffsets, iterDomainSizes;
  [[maybe_unused]] LogicalResult res =
      clonedOp.getIterationDomainTileFromOperandTiles(
          rewriter, operands, allOffsets, allSizes, iterDomainOffsets,
          iterDomainSizes);
  assert(succeeded(res) && "unexpected iteration domain fetch failed");

  unsigned numResults = clonedOp->getNumResults();
  SmallVector<SmallVector<OpFoldResult>> resultOffsets(numResults);
  SmallVector<SmallVector<OpFoldResult>> resultSizes(numResults);
  for (auto [idx, v] : llvm::enumerate(clonedOp->getResults())) {
    [[maybe_unused]] LogicalResult res = clonedOp.getResultTilePosition(
        rewriter, idx, iterDomainOffsets, iterDomainSizes, resultOffsets[idx],
        resultSizes[idx]);
    assert(succeeded(res) && "Unexpected failure to get result tile position");
  }

  // Tile the cloned op based on the slice shapes.
  FailureOr<TilingResult> tiledResult =
      clonedOp.getTiledImplementationFromOperandTiles(rewriter, operands,
                                                      allOffsets, allSizes);
  assert(succeeded(tiledResult) && "unexpected tiling failure");

  // Create write_slice ops updating the destination for each result.
  OpFoldResult one = rewriter.getIndexAttr(1);
  for (auto [offsets, sizes, replacement, dest] :
       llvm::zip_equal(resultOffsets, resultSizes, tiledResult->tiledValues,
                       newResultDests)) {
    SmallVector<OpFoldResult> strides(offsets.size(), one);
    PCF::WriteSliceOp::create(rewriter, loc, replacement, dest, offsets, sizes,
                              strides);
  }

  // Finally forward the sources of the unrealized conversion casts past each
  // `tensor.extract_slice` consumer. If this fails for any reason we leave the
  // unrealized cast in and fail later for better diagnostics as it is
  // unrecoverable.
  for (auto unrealizedCast : unrealizedConversions) {
    SmallVector<Operation *> users(unrealizedCast->getUsers());
    for (Operation *user : users) {
      if (auto extract = dyn_cast<tensor::ExtractSliceOp>(user)) {
        if (extract.getResultType() ==
            unrealizedCast->getOperandTypes().front()) {
          rewriter.replaceOp(extract, unrealizedCast.getOperand(0));
        }
      }
    }
    if (unrealizedCast->use_empty()) {
      rewriter.eraseOp(unrealizedCast);
    }
  }
}

static void addSrefArguments(MLIRContext *context, Location loc,
                             int64_t newArgIndex, Block *entryBlock,
                             TypeRange resultTypes,
                             PCF::ScopeAttrInterface scope) {
  // Add the new region arguments with parent sync scope.
  Attribute syncScope = PCF::SyncOnReturnAttr::get(context);
  for (auto resultType : resultTypes) {
    auto tensorType = cast<RankedTensorType>(resultType);
    auto newSrefType =
        PCF::ShapedRefType::get(context, tensorType.getShape(),
                                tensorType.getElementType(), scope, syncScope);
    entryBlock->insertArgument(newArgIndex, newSrefType, loc);
    ++newArgIndex;
  }
}

static PCF::LoopOp addResults(RewriterBase &rewriter, PCF::LoopOp loopOp,
                              ArrayRef<bool> isTied, ArrayRef<Value> tiedArgs,
                              ArrayRef<Value> dynamicSizes,
                              TypeRange resultTypes) {

  // Append the parameters for the new results to the existing lists.
  SmallVector<Type> newResultTypes(loopOp->getResultTypes());
  newResultTypes.append(resultTypes.begin(), resultTypes.end());
  SmallVector<bool> newIsTied(loopOp.getIsTied());
  newIsTied.append(isTied.begin(), isTied.end());
  SmallVector<Value> newDynamicSizes(loopOp.getDynamicSizes());
  newDynamicSizes.append(dynamicSizes.begin(), dynamicSizes.end());
  SmallVector<Value> newTiedArgs(loopOp.getInits());
  newTiedArgs.append(tiedArgs.begin(), tiedArgs.end());

  int64_t numOriginalResults = loopOp->getNumResults();

  // Get the index of the last region ref arg before moving the body over.
  // + 1 because we want the new args to go at the end.
  int64_t newArgIndex = loopOp.getRegionRefArgs().back().getArgNumber() + 1;

  auto newLoopOp =
      PCF::LoopOp::create(rewriter, loopOp.getLoc(), newResultTypes,
                          loopOp.getScope(), loopOp.getCount(), newTiedArgs,
                          newDynamicSizes, newIsTied, loopOp.getSyncOnReturn());
  newLoopOp.getRegion().takeBody(loopOp.getRegion());

  // Add the new region arguments with parent sync scope.
  addSrefArguments(rewriter.getContext(), loopOp.getLoc(), newArgIndex,
                   newLoopOp.getBody(), resultTypes, loopOp.getScope());

  rewriter.replaceOp(loopOp,
                     newLoopOp->getResults().take_front(numOriginalResults));
  return newLoopOp;
}

static PCF::GenericOp
addResults(RewriterBase &rewriter, PCF::GenericOp genericOp,
           ArrayRef<bool> isTied, ArrayRef<Value> tiedArgs,
           ArrayRef<Value> dynamicSizes, TypeRange resultTypes) {

  // Append the parameters for the new results to the existing lists.
  SmallVector<Type> newResultTypes(genericOp->getResultTypes());
  newResultTypes.append(resultTypes.begin(), resultTypes.end());
  SmallVector<bool> newIsTied(genericOp.getIsTied());
  newIsTied.append(isTied.begin(), isTied.end());
  SmallVector<Value> newDynamicSizes(genericOp.getDynamicSizes());
  newDynamicSizes.append(dynamicSizes.begin(), dynamicSizes.end());
  SmallVector<Value> newTiedArgs(genericOp.getInits());
  newTiedArgs.append(tiedArgs.begin(), tiedArgs.end());

  int64_t numOriginalResults = genericOp->getNumResults();

  // Get the index of the last region ref arg before moving the body over.
  // + 1 because we want the new args to go at the end.
  int64_t newArgIndex = genericOp.getRegionRefArgs().back().getArgNumber() + 1;

  auto newGenericOp = PCF::GenericOp::create(
      rewriter, genericOp.getLoc(), newResultTypes, genericOp.getScope(),
      newTiedArgs, newDynamicSizes, newIsTied, genericOp.getNumIterators(),
      genericOp.getSyncOnReturn());
  newGenericOp.getRegion().takeBody(genericOp.getRegion());
  newGenericOp.getInitializer().takeBody(genericOp.getInitializer());
  newGenericOp.setNumLeadingArgs(genericOp.getNumLeadingArgs());

  // Add the new region arguments with parent sync scope.
  addSrefArguments(rewriter.getContext(), genericOp.getLoc(), newArgIndex,
                   &newGenericOp.getRegion().front(), resultTypes,
                   genericOp.getScope());

  rewriter.replaceOp(genericOp,
                     newGenericOp->getResults().take_front(numOriginalResults));
  return newGenericOp;
}

template <typename OpTy>
static void fuseTilableConsumerImpl(RewriterBase &rewriter, OpTy producerOp,
                                    TilingInterface target,
                                    const ConsumerFusionParams &params) {
  assert(!params.results.empty() && "unexpected empty number of results");

  Location loc = target.getLoc();

  // Step 1. To compute the set of new result shapes, we need to either reify
  // result shapes or get it from a destination a la DPS.
  SmallVector<bool> isTied;
  SmallVector<Value> tiedArgs;
  SmallVector<Value> dynamicSizes;
  SmallVector<Type> resultTypes(target->getResultTypes());

  auto getInitOrCreateEmpty = [&](int64_t resultNumber) -> Value {
    if (OpOperand *tiedInit = producerOp.getTiedInit(resultNumber)) {
      return tiedInit->get();
    }
    return mlir::tensor::EmptyOp::create(
        rewriter, loc, producerOp.getResultType(resultNumber),
        producerOp.getResultDims(resultNumber));
  };

  if (auto dpsOp = dyn_cast<DestinationStyleOpInterface>(*target)) {
    for (Value init : dpsOp.getDpsInits()) {
      if (init.getDefiningOp() == producerOp) {
        // There are two options if we are fusing along an init operand:
        //  1. Create a new empty init with the same shape.
        //  2. Use the init of the producer op.
        //
        // This opts for the latter because when fusing we'll replace the actual
        // operand with the thread-local version, so the code will still be
        // correct and it's the closest to the original intent of the
        // ops destination.
        auto result = cast<OpResult>(init);
        if (OpOperand *operand =
                producerOp.getTiedInit(result.getResultNumber())) {
          isTied.push_back(true);
          tiedArgs.push_back(operand->get());
        } else {
          // If there is no tied init, copy the dimensions over.
          isTied.push_back(false);
          ValueRange resultDims =
              producerOp.getResultDims(result.getResultNumber());
          dynamicSizes.append(resultDims.begin(), resultDims.end());
        }
      } else {
        // Otherwise we just use the init as the tied operand directly.
        isTied.push_back(true);
        tiedArgs.push_back(init);
      }
    }
  } else {
    // For reification ops, we need to construct the result dims in terms of
    // the producer's operands. To do this we replace all operands of |target|
    // coming from the producer with equivalently shaped inits/tensor.empty ops
    // and call reification on that. This is ostensibly a hack as there is no
    // formal guarantee that swapping out operands like this is valid per the
    // interface, however in practice this is valid for all known operations
    // that implement the interface today.

    SmallVector<Value> originalOperands;
    rewriter.setInsertionPoint(producerOp);
    for (unsigned operandIndex : params.operands) {
      Value operand = target->getOperand(operandIndex);
      originalOperands.push_back(operand);
      target->getOpOperand(operandIndex)
          .assign(
              getInitOrCreateEmpty(cast<OpResult>(operand).getResultNumber()));
    }

    SmallVector<SmallVector<OpFoldResult>> outputShapes;
    Operation *nextNode = target->getNextNode();
    Block *currBlock = target->getBlock();

    // Move the op immediately before the producer to get the SSA dominance
    // needed for the result shape dims.
    rewriter.moveOpBefore(target, producerOp);

    // If a fusable operation cannot reify its result shapes under any
    // circumstance, then it was not fusable and should not have been marked as
    // such.
    [[maybe_unused]] auto reifyOp =
        cast<ReifyRankedShapedTypeOpInterface>(*target);
    assert(succeeded(reifyOp.reifyResultShapes(rewriter, outputShapes)) &&
           "unexpected reify result shapes failed");
    if (nextNode) {
      rewriter.moveOpBefore(target, nextNode);
    } else {
      rewriter.moveOpAfter(target, &currBlock->back());
    }

    for (ArrayRef<OpFoldResult> outputShape : outputShapes) {
      dynamicSizes.append(
          llvm::map_to_vector(outputShape, [&](OpFoldResult ofr) {
            return getValueOrCreateConstantIndexOp(rewriter, loc, ofr);
          }));
    }
    isTied.append(outputShapes.size(), false);
  }

  OpTy newRegionOp = addResults(rewriter, producerOp, isTied, tiedArgs,
                                dynamicSizes, resultTypes);
  ValueRange newResultDests =
      newRegionOp.getRegionRefArgs().take_back(resultTypes.size());
  ValueRange replacements =
      newRegionOp.getResults().take_back(resultTypes.size());

  if (params.results.size() == 1) {
    // Single fusion vector means each slice is a different insertion point.
    for (PCF::WriteSliceOp slice : params.slices) {
      // Replicate the slice for each operand. Per the matcher the only
      // supported multi-operand case is if each operand refers to the same
      // value.
      SmallVector<PCF::WriteSliceOp> slices(params.operands.size(), slice);
      fuseIntoWriteSlices(rewriter, target, params.operands, slices,
                          newResultDests);
    }
  } else {
    fuseIntoWriteSlices(rewriter, target, params.operands, params.slices,
                        newResultDests);
  }

  // Finally replace the original fusion target with the newly created loop
  // results.
  rewriter.replaceOp(target, replacements);
}

//===---------------------------------------------------------------------===//
// Extract slice consumer fusion
//===---------------------------------------------------------------------===//

// Compute clamped offsets and sizes of a write_slice to fit within extract
// bounds. This creates affine.min ops to clamp the sizes.
static void computeClampedOffsetsAndSizes(
    RewriterBase &rewriter, Location loc, ArrayRef<OpFoldResult> sliceOffsets,
    ArrayRef<OpFoldResult> sliceSizes, ArrayRef<OpFoldResult> extractSizes,
    SmallVectorImpl<OpFoldResult> &clampedOffsets,
    SmallVectorImpl<OpFoldResult> &clampedSizes) {
  // Clamp sizes to fit within extract bounds.
  for (auto [sliceOffset, sliceSize, extractSize] :
       llvm::zip_equal(sliceOffsets, sliceSizes, extractSizes)) {
    // Compute min(sliceOffset + sliceSize, extractSize) - sliceOffset
    // = min(sliceSize, extractSize - sliceOffset)
    AffineExpr d0, d1, d2;
    bindDims(rewriter.getContext(), d0, d1, d2);
    // d0 = sliceSize, d1 = extractSize, d2 = sliceOffset
    // clampedSize = min(d0, d1 - d2)
    AffineMap minMap =
        AffineMap::get(3, 0, {d0, d1 - d2}, rewriter.getContext());
    OpFoldResult clampedSize = affine::makeComposedFoldedAffineMin(
        rewriter, loc, minMap, {sliceSize, extractSize, sliceOffset});
    clampedOffsets.push_back(sliceOffset);
    clampedSizes.push_back(clampedSize);
  }
}

template <typename OpTy>
static LogicalResult
fuseExtractSliceIntoProducerImpl(RewriterBase &rewriter, OpTy producerOp,
                                 tensor::ExtractSliceOp extractSliceOp) {
  OpResult producerResult = cast<OpResult>(extractSliceOp.getSource());
  if (!producerResult.hasOneUse()) {
    return rewriter.notifyMatchFailure(producerOp,
                                       "producer result has multiple uses");
  }

  // Only zero offset extract_slice ops are supported.
  if (!llvm::all_of(extractSliceOp.getMixedOffsets(), [](OpFoldResult ofr) {
        return isConstantIntValue(ofr, 0);
      })) {
    return rewriter.notifyMatchFailure(extractSliceOp,
                                       "extract_slice has non-zero offsets");
  }

  // Rank-reducing extract_slice is not yet supported.
  auto extractedType = extractSliceOp.getType();
  auto producerResultType = cast<RankedTensorType>(producerResult.getType());
  if (extractedType.getRank() != producerResultType.getRank()) {
    return rewriter.notifyMatchFailure(
        extractSliceOp, "rank-reducing extract_slice not yet supported");
  }

  // Get the write_slice ops for this result.
  unsigned resultIdx = producerResult.getResultNumber();
  SmallVector<PCF::WriteSliceOp> slices;
  if (failed(lookupProducerSlices<OpTy>(producerResult, slices))) {
    return rewriter.notifyMatchFailure(producerOp,
                                       "failed to lookup producer slices");
  }

  if (slices.empty()) {
    return rewriter.notifyMatchFailure(producerOp, "no write_slice producers");
  }

  // Verify all write_slices have unit stride.
  // Only zero-offset extract_slice is supported (already checked above).
  SmallVector<OpFoldResult> extractSizes = extractSliceOp.getMixedSizes();
  for (PCF::WriteSliceOp slice : slices) {
    if (!slice.hasUnitStride()) {
      return rewriter.notifyMatchFailure(slice,
                                         "write_slice has non-unit stride");
    }
  }

  // Get the tied init for this result if it exists.
  OpOperand *tiedInit = producerOp.getTiedInit(resultIdx);
  Value initValue;
  if (tiedInit) {
    // Extract from the tied init.
    rewriter.setInsertionPoint(producerOp);
    initValue = tensor::ExtractSliceOp::create(
        rewriter, producerOp.getLoc(), tiedInit->get(),
        extractSliceOp.getMixedOffsets(), extractSliceOp.getMixedSizes(),
        extractSliceOp.getMixedStrides());
  }

  // Compute new dynamic sizes for the result.
  SmallVector<Value> newDynamicSizes;
  int64_t dynamicDimIdx = 0;

  // First, copy dynamic sizes for results before this one.
  for (unsigned i = 0; i < resultIdx; ++i) {
    auto prevResultType =
        cast<RankedTensorType>(producerOp->getResult(i).getType());
    for (int64_t j = 0; j < prevResultType.getRank(); ++j) {
      if (prevResultType.isDynamicDim(j)) {
        newDynamicSizes.push_back(
            producerOp.getDynamicSizes()[dynamicDimIdx++]);
      }
    }
  }

  // Skip dynamic sizes for the current result (we'll add new ones).
  for (int64_t j = 0; j < producerResultType.getRank(); ++j) {
    if (producerResultType.isDynamicDim(j)) {
      dynamicDimIdx++;
    }
  }

  // Add new dynamic sizes from the extract_slice.
  rewriter.setInsertionPoint(producerOp);
  for (int64_t j = 0; j < extractedType.getRank(); ++j) {
    if (extractedType.isDynamicDim(j)) {
      OpFoldResult size = extractSliceOp.getMixedSizes()[j];
      newDynamicSizes.push_back(
          getValueOrCreateConstantIndexOp(rewriter, producerOp.getLoc(), size));
    }
  }

  // Copy remaining dynamic sizes.
  while (dynamicDimIdx <
         static_cast<int64_t>(producerOp.getDynamicSizes().size())) {
    newDynamicSizes.push_back(producerOp.getDynamicSizes()[dynamicDimIdx++]);
  }

  // Update tied init if present.
  SmallVector<Value> newInits(producerOp.getInits());
  if (tiedInit) {
    // Find the init index using the same logic as getTiedInit.
    int64_t initIdx =
        llvm::count(producerOp.getIsTied().take_front(resultIdx), true);
    newInits[initIdx] = initValue;
  }

  // Create the new result types.
  SmallVector<Type> newResultTypes;
  for (unsigned i = 0; i < producerOp->getNumResults(); ++i) {
    if (i == resultIdx) {
      newResultTypes.push_back(extractedType);
    } else {
      newResultTypes.push_back(producerOp->getResult(i).getType());
    }
  }

  // Clone the producer op with updated result types and dynamic sizes.
  OpTy newOp;
  if constexpr (std::is_same_v<OpTy, PCF::LoopOp>) {
    newOp = PCF::LoopOp::create(
        rewriter, producerOp.getLoc(), newResultTypes, producerOp.getScope(),
        producerOp.getCount(), newInits, newDynamicSizes,
        producerOp.getIsTied(), producerOp.getSyncOnReturn());
    newOp.getRegion().takeBody(producerOp.getRegion());
  } else {
    newOp = PCF::GenericOp::create(
        rewriter, producerOp.getLoc(), newResultTypes, producerOp.getScope(),
        newInits, newDynamicSizes, producerOp.getIsTied(),
        producerOp.getNumIterators(), producerOp.getSyncOnReturn());
    newOp.getRegion().takeBody(producerOp.getRegion());
    newOp.getInitializer().takeBody(producerOp.getInitializer());
    newOp.setNumLeadingArgs(producerOp.getNumLeadingArgs());
  }

  // Update the region ref arg type to match the new result size.
  Value newRefArg = newOp.getRegionRefArgs()[resultIdx];
  auto oldSrefType = cast<PCF::ShapedRefType>(newRefArg.getType());
  auto newSrefType = PCF::ShapedRefType::get(
      rewriter.getContext(), extractedType.getShape(),
      extractedType.getElementType(), producerOp.getScope(),
      oldSrefType.getSyncScope());
  newRefArg.setType(newSrefType);

  // Get the write_slices in the new op's region (they were moved with the
  // body).
  SmallVector<PCF::WriteSliceOp> newSlices;
  for (auto user : newRefArg.getUsers()) {
    if (auto writeSlice = dyn_cast<PCF::WriteSliceOp>(user)) {
      newSlices.push_back(writeSlice);
    }
  }

  // For each write_slice, clamp it to fit within the extracted bounds.
  for (PCF::WriteSliceOp slice : newSlices) {
    OpBuilder::InsertionGuard g(rewriter);
    rewriter.setInsertionPoint(slice);
    Location loc = slice.getLoc();

    // Compute clamped offsets and sizes.
    SmallVector<OpFoldResult> clampedOffsets, clampedSizes;
    computeClampedOffsetsAndSizes(rewriter, loc, slice.getMixedOffsets(),
                                  slice.getMixedSizes(), extractSizes,
                                  clampedOffsets, clampedSizes);

    Value source = slice.getSource();
    auto sourceType = cast<RankedTensorType>(source.getType());

    // Create extract_slice of source to get the clamped portion.
    SmallVector<OpFoldResult> sourceOffsets(sourceType.getRank(),
                                            rewriter.getIndexAttr(0));
    SmallVector<OpFoldResult> sourceStrides(sourceType.getRank(),
                                            rewriter.getIndexAttr(1));
    auto clampedSource = tensor::ExtractSliceOp::create(
        rewriter, loc, source, sourceOffsets, clampedSizes, sourceStrides);

    // Create the new write_slice with clamped offsets/sizes.
    SmallVector<OpFoldResult> strides(clampedOffsets.size(),
                                      rewriter.getIndexAttr(1));
    PCF::WriteSliceOp::create(rewriter, loc, clampedSource, slice.getDest(),
                              clampedOffsets, clampedSizes, strides);

    rewriter.eraseOp(slice);
  }

  // Replace the producer and extract_slice.
  SmallVector<Value> replacements(newOp->getResults());
  rewriter.replaceOp(producerOp, replacements);
  rewriter.replaceOp(extractSliceOp, newOp->getResult(resultIdx));

  return success();
}

//===---------------------------------------------------------------------===//
// Expand shape consumer fusion
//===---------------------------------------------------------------------===//

/// Classifies whether a collapsed offset/size pair is aligned to innerProduct.
enum class AlignmentStatus { Aligned, Unaligned, Dynamic };

/// Determines alignment status of a write_slice's offset and size
/// with respect to the innerProduct of a reassociation group.
static AlignmentStatus classifyAlignment(OpFoldResult offset, OpFoldResult size,
                                         int64_t innerProduct) {
  if (innerProduct == 1) {
    return AlignmentStatus::Aligned;
  }
  std::optional<int64_t> constOffset = getConstantIntValue(offset);
  std::optional<int64_t> constSize = getConstantIntValue(size);
  if (constOffset && constSize) {
    if (*constOffset % innerProduct == 0 && *constSize % innerProduct == 0) {
      return AlignmentStatus::Aligned;
    }
    return AlignmentStatus::Unaligned;
  }
  // If either is dynamic but the known one is statically unaligned, fail.
  if (constOffset && *constOffset % innerProduct != 0) {
    return AlignmentStatus::Unaligned;
  }
  if (constSize && *constSize % innerProduct != 0) {
    return AlignmentStatus::Unaligned;
  }
  return AlignmentStatus::Dynamic;
}

/// Computes the inner product for a multi-dim reassociation group.
static int64_t computeInnerProduct(const ReassociationIndices &group,
                                   ArrayRef<int64_t> expandedShape) {
  int64_t innerProduct = 1;
  for (size_t i = 1, e = group.size(); i < e; ++i) {
    innerProduct *= expandedShape[group[i]];
  }
  return innerProduct;
}

/// Computes expanded offsets and sizes for the aligned case. For each
/// reassociation group, the collapsed offset/size is de-linearized: the outer
/// dimension gets offset/innerProduct and size/innerProduct, while inner
/// dimensions get offset=0 and size=expandedDimSize.
static void computeExpandedOffsetsAndSizes(
    OpBuilder &builder, Location loc, ArrayRef<OpFoldResult> sliceOffsets,
    ArrayRef<OpFoldResult> sliceSizes, ArrayRef<int64_t> expandedShape,
    ArrayRef<ReassociationIndices> reassociation,
    SmallVectorImpl<OpFoldResult> &expandedOffsets,
    SmallVectorImpl<OpFoldResult> &expandedSizes) {
  for (const auto &[srcDim, group] : llvm::enumerate(reassociation)) {
    if (group.size() == 1) {
      // Singleton group: offset and size pass through.
      expandedOffsets.push_back(sliceOffsets[srcDim]);
      expandedSizes.push_back(sliceSizes[srcDim]);
      continue;
    }
    // Multi-dim group. Compute the product of inner dimension sizes.
    int64_t innerProduct = computeInnerProduct(group, expandedShape);

    // Outer offset = collapsed_offset / innerProduct.
    AffineExpr d0;
    bindDims(builder.getContext(), d0);
    AffineMap divMap =
        AffineMap::get(1, 0, d0.floorDiv(innerProduct), builder.getContext());
    OpFoldResult outerOffset = affine::makeComposedFoldedAffineApply(
        builder, loc, divMap, {sliceOffsets[srcDim]});
    expandedOffsets.push_back(outerOffset);

    // Inner offsets are all zero.
    for (size_t i = 1, e = group.size(); i < e; ++i) {
      expandedOffsets.push_back(builder.getIndexAttr(0));
    }

    // Outer size = collapsed_size / innerProduct.
    OpFoldResult outerSize = affine::makeComposedFoldedAffineApply(
        builder, loc, divMap, {sliceSizes[srcDim]});
    expandedSizes.push_back(outerSize);

    // Inner sizes are the full dimension sizes.
    for (size_t i = 1, e = group.size(); i < e; ++i) {
      expandedSizes.push_back(builder.getIndexAttr(expandedShape[group[i]]));
    }
  }
}

/// Emits a single expanded write_slice for the aligned case. The source tensor
/// is expanded with the same reassociation and written at de-linearized
/// offsets/sizes.
static void
emitAlignedWriteSlice(OpBuilder &builder, Location loc, Value source,
                      Value dest, ArrayRef<OpFoldResult> sliceOffsets,
                      ArrayRef<OpFoldResult> sliceSizes,
                      ArrayRef<int64_t> expandedShape,
                      ArrayRef<ReassociationIndices> reassociation) {
  RankedTensorType sourceType = cast<RankedTensorType>(source.getType());

  // Compute expanded offsets and sizes.
  SmallVector<OpFoldResult> expandedOffsets, expandedSizes;
  computeExpandedOffsetsAndSizes(builder, loc, sliceOffsets, sliceSizes,
                                 expandedShape, reassociation, expandedOffsets,
                                 expandedSizes);

  // Compute the expanded source type and output_shape.
  SmallVector<int64_t> expandedSourceShape;
  SmallVector<OpFoldResult> sourceOutputShape;
  for (const auto &[srcDim, group] : llvm::enumerate(reassociation)) {
    if (group.size() == 1) {
      int64_t dimSize = sourceType.getDimSize(srcDim);
      expandedSourceShape.push_back(dimSize);
      if (ShapedType::isDynamic(dimSize)) {
        Value dimVal = tensor::DimOp::create(
            builder, loc, source,
            arith::ConstantIndexOp::create(builder, loc, srcDim));
        sourceOutputShape.push_back(dimVal);
      } else {
        sourceOutputShape.push_back(builder.getIndexAttr(dimSize));
      }
      continue;
    }
    int64_t innerProduct = computeInnerProduct(group, expandedShape);

    // Outer dim of expanded source.
    int64_t srcDimSize = sourceType.getDimSize(srcDim);
    if (ShapedType::isDynamic(srcDimSize)) {
      expandedSourceShape.push_back(ShapedType::kDynamic);
      Value srcDimVal = tensor::DimOp::create(
          builder, loc, source,
          arith::ConstantIndexOp::create(builder, loc, srcDim));
      Value innerProdVal =
          arith::ConstantIndexOp::create(builder, loc, innerProduct);
      Value outerDimVal =
          arith::DivUIOp::create(builder, loc, srcDimVal, innerProdVal);
      sourceOutputShape.push_back(outerDimVal);
    } else {
      int64_t outerSize = srcDimSize / innerProduct;
      expandedSourceShape.push_back(outerSize);
      sourceOutputShape.push_back(builder.getIndexAttr(outerSize));
    }

    // Inner dims: full static sizes.
    for (size_t i = 1, e = group.size(); i < e; ++i) {
      expandedSourceShape.push_back(expandedShape[group[i]]);
      sourceOutputShape.push_back(
          builder.getIndexAttr(expandedShape[group[i]]));
    }
  }

  RankedTensorType expandedSourceType =
      RankedTensorType::get(expandedSourceShape, sourceType.getElementType());

  Value expandedSource =
      tensor::ExpandShapeOp::create(builder, loc, expandedSourceType, source,
                                    reassociation, sourceOutputShape);

  // Create the new write_slice with expanded offsets/sizes.
  SmallVector<OpFoldResult> strides(expandedOffsets.size(),
                                    builder.getIndexAttr(1));
  PCF::WriteSliceOp::create(builder, loc, expandedSource, dest, expandedOffsets,
                            expandedSizes, strides);
}

/// Emits an scf.for loop that iterates over sub-tiles of the collapsed
/// source tensor and writes each sub-tile to the correct position in the
/// expanded destination. Used when the collapsed tile is not aligned to the
/// innerProduct boundary, meaning it may span multiple "rows" in the outermost
/// expanded dimension.
///
/// For a 2-dim reassociation group [outer, inner] with innerProduct = N:
///   - The loop iterates from firstRow = off/N to ceil((off+sz)/N).
///   - Each iteration computes the chunk within that row, extracts it from
///     the source, reshapes to [1, chunk] and writes to [row, col].
static void emitSubTileLoop(OpBuilder &builder, Location loc, Value source,
                            Value dest, ArrayRef<OpFoldResult> sliceOffsets,
                            ArrayRef<OpFoldResult> sliceSizes,
                            ArrayRef<int64_t> expandedShape,
                            ArrayRef<ReassociationIndices> reassociation,
                            unsigned groupIdx, int64_t innerProduct) {
  RankedTensorType sourceType = cast<RankedTensorType>(source.getType());

  // Materialize offset and size as Values.
  Value off =
      getValueOrCreateConstantIndexOp(builder, loc, sliceOffsets[groupIdx]);
  Value sz =
      getValueOrCreateConstantIndexOp(builder, loc, sliceSizes[groupIdx]);
  Value innerProdVal =
      arith::ConstantIndexOp::create(builder, loc, innerProduct);
  Value c1 = arith::ConstantIndexOp::create(builder, loc, 1);

  // Loop bounds.
  Value firstRow = arith::DivUIOp::create(builder, loc, off, innerProdVal);
  Value end = arith::AddIOp::create(builder, loc, off, sz);
  Value upper = arith::CeilDivUIOp::create(builder, loc, end, innerProdVal);

  // Compute expanded offsets/sizes for non-iterated groups (used in all
  // iterations). For singleton groups, pass through. For other aligned
  // multi-dim groups, use the standard de-linearization.
  SmallVector<OpFoldResult> baseExpandedOffsets, baseExpandedSizes;
  computeExpandedOffsetsAndSizes(builder, loc, sliceOffsets, sliceSizes,
                                 expandedShape, reassociation,
                                 baseExpandedOffsets, baseExpandedSizes);

  // Precompute the expanded dim index where the iterated group starts.
  unsigned expandedGroupStart = 0;
  for (unsigned i = 0; i < groupIdx; ++i) {
    expandedGroupStart += reassociation[i].size();
  }

  scf::ForOp::create(
      builder, loc, firstRow, upper, c1, /*iterArgs=*/ValueRange{},
      [&](OpBuilder &b, Location l, Value row, ValueRange /*iterArgs*/) {
        // Compute per-iteration bounds.
        Value rowStart = arith::MulIOp::create(b, l, row, innerProdVal);
        Value tileStart = arith::MaxUIOp::create(b, l, off, rowStart);
        Value rowEnd = arith::AddIOp::create(b, l, rowStart, innerProdVal);
        Value tileEnd = arith::MinUIOp::create(b, l, end, rowEnd);
        Value colStart = arith::SubIOp::create(b, l, tileStart, rowStart);
        Value chunkSize = arith::SubIOp::create(b, l, tileEnd, tileStart);
        Value srcOffset = arith::SubIOp::create(b, l, tileStart, off);

        // Build extract_slice offsets/sizes for the source tensor.
        SmallVector<OpFoldResult> extractOffsets, extractSizes, extractStrides;
        SmallVector<int64_t> extractShape;
        for (unsigned i = 0, e = sourceType.getRank(); i < e; ++i) {
          if (i == groupIdx) {
            extractOffsets.push_back(srcOffset);
            extractSizes.push_back(chunkSize);
            extractShape.push_back(ShapedType::kDynamic);
          } else {
            extractOffsets.push_back(b.getIndexAttr(0));
            extractSizes.push_back(sliceSizes[i]);
            extractShape.push_back(sourceType.getDimSize(i));
          }
          extractStrides.push_back(b.getIndexAttr(1));
        }

        RankedTensorType extractType =
            RankedTensorType::get(extractShape, sourceType.getElementType());

        Value sub = tensor::ExtractSliceOp::create(b, l, extractType, source,
                                                   extractOffsets, extractSizes,
                                                   extractStrides);

        // Expand the sub-tile to match the expanded sref rank.
        // For the iterated group: [chunkSize] -> [1, chunkSize].
        SmallVector<int64_t> expandedSubShape;
        SmallVector<OpFoldResult> subOutputShape;
        for (const auto &[dim, group] : llvm::enumerate(reassociation)) {
          if (dim == groupIdx) {
            // Iterated group: outer dim = 1, inner dim = chunkSize.
            expandedSubShape.push_back(1);
            subOutputShape.push_back(b.getIndexAttr(1));
            expandedSubShape.push_back(ShapedType::kDynamic);
            subOutputShape.push_back(chunkSize);
            // For 3+ dim groups, remaining inner dims are full static sizes.
            for (size_t i = 2, e = group.size(); i < e; ++i) {
              expandedSubShape.push_back(expandedShape[group[i]]);
              subOutputShape.push_back(b.getIndexAttr(expandedShape[group[i]]));
            }
          } else if (group.size() == 1) {
            int64_t dimSize = extractShape[dim];
            expandedSubShape.push_back(dimSize);
            if (ShapedType::isDynamic(dimSize)) {
              Value dimVal = tensor::DimOp::create(
                  b, l, sub, arith::ConstantIndexOp::create(b, l, dim));
              subOutputShape.push_back(dimVal);
            } else {
              subOutputShape.push_back(b.getIndexAttr(dimSize));
            }
          } else {
            // Other multi-dim group (must be aligned). Expand like aligned
            // path.
            int64_t groupInnerProd = computeInnerProduct(group, expandedShape);
            int64_t srcDimSize = extractShape[dim];
            if (ShapedType::isDynamic(srcDimSize)) {
              expandedSubShape.push_back(ShapedType::kDynamic);
              Value srcDimVal = tensor::DimOp::create(
                  b, l, sub, arith::ConstantIndexOp::create(b, l, dim));
              Value ipVal =
                  arith::ConstantIndexOp::create(b, l, groupInnerProd);
              Value outerVal = arith::DivUIOp::create(b, l, srcDimVal, ipVal);
              subOutputShape.push_back(outerVal);
            } else {
              int64_t outerSize = srcDimSize / groupInnerProd;
              expandedSubShape.push_back(outerSize);
              subOutputShape.push_back(b.getIndexAttr(outerSize));
            }
            for (size_t i = 1, e = group.size(); i < e; ++i) {
              expandedSubShape.push_back(expandedShape[group[i]]);
              subOutputShape.push_back(b.getIndexAttr(expandedShape[group[i]]));
            }
          }
        }

        RankedTensorType expandedSubType = RankedTensorType::get(
            expandedSubShape, sourceType.getElementType());

        Value expandedSub = tensor::ExpandShapeOp::create(
            b, l, expandedSubType, sub, reassociation, subOutputShape);

        // Build expanded offsets/sizes for the write_slice. Override the
        // iterated group's entries.
        SmallVector<OpFoldResult> writeOffsets(baseExpandedOffsets);
        SmallVector<OpFoldResult> writeSizes(baseExpandedSizes);

        // Outer dim: offset = row, size = 1.
        writeOffsets[expandedGroupStart] = row;
        writeSizes[expandedGroupStart] = b.getIndexAttr(1);

        // First inner dim: offset = colStart, size = chunkSize.
        writeOffsets[expandedGroupStart + 1] = colStart;
        writeSizes[expandedGroupStart + 1] = chunkSize;

        // Remaining inner dims (if any): offset = 0, size = full (already set
        // by computeExpandedOffsetsAndSizes).

        SmallVector<OpFoldResult> strides(writeOffsets.size(),
                                          b.getIndexAttr(1));
        PCF::WriteSliceOp::create(b, l, expandedSub, dest, writeOffsets,
                                  writeSizes, strides);

        scf::YieldOp::create(b, l);
      });
}

template <typename OpTy>
LogicalResult fuseExpandShapeIntoProducerImpl(RewriterBase &rewriter,
                                              OpTy producerOp,
                                              tensor::ExpandShapeOp expandOp) {
  OpResult producerResult = cast<OpResult>(expandOp.getSrc());
  if (!producerResult.hasOneUse()) {
    return rewriter.notifyMatchFailure(producerOp,
                                       "producer result has multiple uses");
  }

  unsigned resultIdx = producerResult.getResultNumber();
  RankedTensorType producerResultType =
      cast<RankedTensorType>(producerResult.getType());
  RankedTensorType expandedType = expandOp.getResultType();

  SmallVector<ReassociationIndices> reassociation =
      expandOp.getReassociationIndices();
  ArrayRef<int64_t> expandedShape = expandedType.getShape();

  // For multi-dim reassociation groups, validate that inner dimensions have
  // static sizes (required for computing innerProduct). Also, for groups with
  // 3+ dims, we only support the aligned case so we defer checking those until
  // we know alignment per-slice.
  for (const auto &[srcDim, group] : llvm::enumerate(reassociation)) {
    if (group.size() <= 1) {
      continue;
    }
    for (size_t i = 1, e = group.size(); i < e; ++i) {
      if (ShapedType::isDynamic(expandedShape[group[i]])) {
        return rewriter.notifyMatchFailure(
            expandOp,
            "inner dimensions of multi-dim expand group must be static");
      }
    }
  }

  // Get the write_slice ops for this result.
  SmallVector<PCF::WriteSliceOp> slices;
  if (failed(lookupProducerSlices<OpTy>(producerResult, slices))) {
    return rewriter.notifyMatchFailure(producerOp,
                                       "failed to lookup producer slices");
  }

  if (slices.empty()) {
    return rewriter.notifyMatchFailure(producerOp, "no write_slice producers");
  }

  // Verify basic constraints on write_slices. Also check alignment for groups
  // with 3+ dims (those require static alignment since we cannot loop over
  // partial inner sub-tiles).
  for (PCF::WriteSliceOp slice : slices) {
    if (!slice.hasUnitStride()) {
      return rewriter.notifyMatchFailure(slice,
                                         "write_slice has non-unit stride");
    }
    SmallVector<OpFoldResult> offsets = slice.getMixedOffsets();
    SmallVector<OpFoldResult> sizes = slice.getMixedSizes();
    for (const auto &[srcDim, group] : llvm::enumerate(reassociation)) {
      if (group.size() <= 2) {
        continue;
      }
      // Groups with 3+ dims require static alignment.
      int64_t innerProduct = computeInnerProduct(group, expandedShape);
      AlignmentStatus status =
          classifyAlignment(offsets[srcDim], sizes[srcDim], innerProduct);
      if (status != AlignmentStatus::Aligned) {
        return rewriter.notifyMatchFailure(
            slice, "unaligned access for 3+ dim expand group not supported");
      }
    }
  }

  // Get the mixed output_shape from the original expand_shape op.
  SmallVector<OpFoldResult> origOutputShape = expandOp.getMixedOutputShape();

  // Get the tied init for this result if it exists.
  OpOperand *tiedInit = producerOp.getTiedInit(resultIdx);
  Value initValue;
  if (tiedInit) {
    rewriter.setInsertionPoint(producerOp);
    initValue = tensor::ExpandShapeOp::create(rewriter, producerOp.getLoc(),
                                              expandedType, tiedInit->get(),
                                              reassociation, origOutputShape);
  }

  // Compute new dynamic sizes.
  SmallVector<Value> newDynamicSizes;
  int64_t dynamicDimIdx = 0;

  // Copy dynamic sizes for results before this one.
  for (unsigned i = 0; i < resultIdx; ++i) {
    RankedTensorType prevResultType =
        cast<RankedTensorType>(producerOp->getResult(i).getType());
    for (int64_t j = 0, e = prevResultType.getRank(); j < e; ++j) {
      if (prevResultType.isDynamicDim(j)) {
        newDynamicSizes.push_back(
            producerOp.getDynamicSizes()[dynamicDimIdx++]);
      }
    }
  }

  // Skip dynamic sizes for the current result.
  for (int64_t j = 0, e = producerResultType.getRank(); j < e; ++j) {
    if (producerResultType.isDynamicDim(j)) {
      dynamicDimIdx++;
    }
  }

  // Add dynamic sizes for the expanded type, using the original expand_shape
  // op's output_shape values for dynamic dims.
  rewriter.setInsertionPoint(producerOp);
  for (int64_t j = 0, e = expandedType.getRank(); j < e; ++j) {
    if (expandedType.isDynamicDim(j)) {
      Value dimSize = getValueOrCreateConstantIndexOp(
          rewriter, producerOp.getLoc(), origOutputShape[j]);
      newDynamicSizes.push_back(dimSize);
    }
  }

  // Copy remaining dynamic sizes.
  llvm::append_range(
      newDynamicSizes,
      llvm::drop_begin(producerOp.getDynamicSizes(), dynamicDimIdx));

  // Update tied init if present.
  SmallVector<Value> newInits(producerOp.getInits());
  if (tiedInit) {
    int64_t initIdx =
        llvm::count(producerOp.getIsTied().take_front(resultIdx), true);
    newInits[initIdx] = initValue;
  }

  // Create the new result types with expanded type for this result.
  SmallVector<Type> newResultTypes;
  for (unsigned i = 0, e = producerOp->getNumResults(); i < e; ++i) {
    if (i == resultIdx) {
      newResultTypes.push_back(expandedType);
    } else {
      newResultTypes.push_back(producerOp->getResult(i).getType());
    }
  }

  // Clone the producer op with updated result type.
  OpTy newOp;
  if constexpr (std::is_same_v<OpTy, PCF::LoopOp>) {
    newOp = PCF::LoopOp::create(
        rewriter, producerOp.getLoc(), newResultTypes, producerOp.getScope(),
        producerOp.getCount(), newInits, newDynamicSizes,
        producerOp.getIsTied(), producerOp.getSyncOnReturn());
    newOp.getRegion().takeBody(producerOp.getRegion());
  } else {
    newOp = PCF::GenericOp::create(
        rewriter, producerOp.getLoc(), newResultTypes, producerOp.getScope(),
        newInits, newDynamicSizes, producerOp.getIsTied(),
        producerOp.getNumIterators(), producerOp.getSyncOnReturn());
    newOp.getRegion().takeBody(producerOp.getRegion());
    newOp.getInitializer().takeBody(producerOp.getInitializer());
    newOp.setNumLeadingArgs(producerOp.getNumLeadingArgs());
  }

  // Update the region ref arg type to match the expanded shape.
  Value newRefArg = newOp.getRegionRefArgs()[resultIdx];
  PCF::ShapedRefType oldSrefType =
      cast<PCF::ShapedRefType>(newRefArg.getType());
  PCF::ShapedRefType newSrefType = PCF::ShapedRefType::get(
      rewriter.getContext(), expandedType.getShape(),
      expandedType.getElementType(), producerOp.getScope(),
      oldSrefType.getSyncScope());
  newRefArg.setType(newSrefType);

  // Get the write_slices in the new op's region.
  SmallVector<PCF::WriteSliceOp> newSlices;
  for (Operation *user : newRefArg.getUsers()) {
    if (auto writeSlice = dyn_cast<PCF::WriteSliceOp>(user)) {
      newSlices.push_back(writeSlice);
    }
  }

  // Transform each write_slice to use expanded offsets/sizes.
  for (PCF::WriteSliceOp slice : newSlices) {
    OpBuilder::InsertionGuard g(rewriter);
    rewriter.setInsertionPoint(slice);
    Location loc = slice.getLoc();

    SmallVector<OpFoldResult> offsets = slice.getMixedOffsets();
    SmallVector<OpFoldResult> sizes = slice.getMixedSizes();
    Value source = slice.getSource();

    // Classify alignment for each 2-dim multi-dim group.
    AlignmentStatus overallStatus = AlignmentStatus::Aligned;
    unsigned dynamicGroupIdx = 0;
    int64_t dynamicGroupInnerProduct = 1;
    for (const auto &[srcDim, group] : llvm::enumerate(reassociation)) {
      if (group.size() != 2) {
        continue;
      }
      int64_t innerProduct = computeInnerProduct(group, expandedShape);
      AlignmentStatus status =
          classifyAlignment(offsets[srcDim], sizes[srcDim], innerProduct);
      if (status == AlignmentStatus::Unaligned ||
          status == AlignmentStatus::Dynamic) {
        overallStatus = status;
        dynamicGroupIdx = srcDim;
        dynamicGroupInnerProduct = innerProduct;
        break;
      }
    }

    if (overallStatus == AlignmentStatus::Aligned) {
      // All groups aligned: simple expansion.
      emitAlignedWriteSlice(rewriter, loc, source, slice.getDest(), offsets,
                            sizes, expandedShape, reassociation);
    } else if (overallStatus == AlignmentStatus::Unaligned) {
      // Statically unaligned: use loop directly.
      emitSubTileLoop(rewriter, loc, source, slice.getDest(), offsets, sizes,
                      expandedShape, reassociation, dynamicGroupIdx,
                      dynamicGroupInnerProduct);
    } else {
      // Dynamic alignment: generate scf.if. Only emit runtime checks for
      // the operands that are not statically known to be aligned.
      Value innerProdVal = arith::ConstantIndexOp::create(
          rewriter, loc, dynamicGroupInnerProduct);
      Value c0 = arith::ConstantIndexOp::create(rewriter, loc, 0);

      std::optional<int64_t> constOff =
          getConstantIntValue(offsets[dynamicGroupIdx]);
      std::optional<int64_t> constSz =
          getConstantIntValue(sizes[dynamicGroupIdx]);

      SmallVector<Value> conditions;
      if (!constOff) {
        Value off = getValueOrCreateConstantIndexOp(rewriter, loc,
                                                    offsets[dynamicGroupIdx]);
        Value offRem = arith::RemUIOp::create(rewriter, loc, off, innerProdVal);
        conditions.push_back(arith::CmpIOp::create(
            rewriter, loc, arith::CmpIPredicate::eq, offRem, c0));
      }
      if (!constSz) {
        Value sz = getValueOrCreateConstantIndexOp(rewriter, loc,
                                                   sizes[dynamicGroupIdx]);
        Value szRem = arith::RemUIOp::create(rewriter, loc, sz, innerProdVal);
        conditions.push_back(arith::CmpIOp::create(
            rewriter, loc, arith::CmpIPredicate::eq, szRem, c0));
      }

      // At least one condition must exist (otherwise we'd be in the Aligned
      // branch).
      Value aligned = conditions[0];
      for (size_t i = 1, e = conditions.size(); i < e; ++i) {
        aligned = arith::AndIOp::create(rewriter, loc, aligned, conditions[i]);
      }

      scf::IfOp::create(
          rewriter, loc, aligned,
          [&](OpBuilder &b, Location l) {
            emitAlignedWriteSlice(b, l, source, slice.getDest(), offsets, sizes,
                                  expandedShape, reassociation);
            scf::YieldOp::create(b, l);
          },
          [&](OpBuilder &b, Location l) {
            emitSubTileLoop(b, l, source, slice.getDest(), offsets, sizes,
                            expandedShape, reassociation, dynamicGroupIdx,
                            dynamicGroupInnerProduct);
            scf::YieldOp::create(b, l);
          });
    }

    rewriter.eraseOp(slice);
  }

  // Replace the original producer and expand_shape.
  SmallVector<Value> replacements(newOp->getResults());
  rewriter.replaceOp(producerOp, replacements);
  rewriter.replaceOp(expandOp, newOp->getResult(resultIdx));

  return success();
}

} // namespace

//===---------------------------------------------------------------------===//
// Public API Specializations
//===---------------------------------------------------------------------===//

LogicalResult
fuseExtractSliceIntoProducerLoop(RewriterBase &rewriter, PCF::LoopOp loopOp,
                                 tensor::ExtractSliceOp extractSliceOp) {
  return fuseExtractSliceIntoProducerImpl(rewriter, loopOp, extractSliceOp);
}

LogicalResult
fuseExtractSliceIntoProducerGeneric(RewriterBase &rewriter,
                                    PCF::GenericOp genericOp,
                                    tensor::ExtractSliceOp extractSliceOp) {
  return fuseExtractSliceIntoProducerImpl(rewriter, genericOp, extractSliceOp);
}

LogicalResult matchTilableConsumer(RewriterBase &rewriter,
                                   PCF::GenericOp producerOp,
                                   TilingInterface target,
                                   ConsumerFusionParams &params) {
  return matchTilableConsumerImpl(rewriter, producerOp, target, params);
}

LogicalResult matchTilableConsumer(RewriterBase &rewriter,
                                   PCF::LoopOp producerOp,
                                   TilingInterface target,
                                   ConsumerFusionParams &params) {
  return matchTilableConsumerImpl(rewriter, producerOp, target, params);
}

void fuseTilableConsumer(RewriterBase &rewriter, PCF::GenericOp producerOp,
                         TilingInterface target,
                         const ConsumerFusionParams &params) {
  return fuseTilableConsumerImpl(rewriter, producerOp, target, params);
}

void fuseTilableConsumer(RewriterBase &rewriter, PCF::LoopOp producerOp,
                         TilingInterface target,
                         const ConsumerFusionParams &params) {
  return fuseTilableConsumerImpl(rewriter, producerOp, target, params);
}

LogicalResult fuseExpandShapeIntoProducerLoop(RewriterBase &rewriter,
                                              PCF::LoopOp loopOp,
                                              tensor::ExpandShapeOp expandOp) {
  return fuseExpandShapeIntoProducerImpl(rewriter, loopOp, expandOp);
}

LogicalResult
fuseExpandShapeIntoProducerGeneric(RewriterBase &rewriter,
                                   PCF::GenericOp genericOp,
                                   tensor::ExpandShapeOp expandOp) {
  return fuseExpandShapeIntoProducerImpl(rewriter, genericOp, expandOp);
}

} // namespace mlir::iree_compiler::IREE::PCF
