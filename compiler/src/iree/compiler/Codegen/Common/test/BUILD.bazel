# Copyright 2019 The IREE Authors
#
# Licensed under the Apache License v2.0 with LLVM Exceptions.
# See https://llvm.org/LICENSE.txt for license information.
# SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception

# Tests for common transforms.

load("//build_tools/bazel:enforce_glob.bzl", "enforce_glob")
load("//build_tools/bazel:iree_lit_test.bzl", "iree_lit_test_suite")

package(
    features = ["layering_check"],
    licenses = ["notice"],  # Apache 2.0
)

iree_lit_test_suite(
    name = "lit",
    srcs = enforce_glob(
        [
            "add_fmfs.mlir",
            "affinemin_canonicalization.mlir",
            "batch_matmuls.mlir",
            "block_dynamic_dims.mlir",
            "bubble_up_ordinal_ops.mlir",
            "bufferize_copy_only_dispatches.mlir",
            "canonicalize_interface_load_store.mlir",
            "convert_accgemm_to_gemm.mlir",
            "convert_bf16_to_uint16_buffers.mlir",
            "convert_bf16_arith_to_f32.mlir",
            "convert_to_destination_passing_style.mlir",
            "convert_unsupported_float_arith.mlir",
            "convolution_to_igemm.mlir",
            "convolutions.mlir",
            "erase_dead_alloc_and_stores.mlir",
            "decompose_affine_ops.mlir",
            "decompose_boundary_pack_unpack_ops.mlir",
            "decompose_conv2d.mlir",
            "decompose_linalg_generic.mlir",
            "decompose_pack_unpack_ops.mlir",
            "decompose_softmax.mlir",
            "eliminate_empty_tensors.mlir",
            "emulate_narrow_type.mlir",
            "erase_hal_descriptor_type.mlir",
            "extract_address_computation.mlir",
            "flatten_memref_subspan.mlir",
            "fold_affine_min_in_distributed_loops.mlir",
            "fold_affine_min_of_block_id.mlir",
            "fold_tensor_extract_op.mlir",
            "forop_canonicalization.mlir",
            "generic_vectorization.mlir",
            "gpu_materialize_encoding_gfx1100.mlir",
            "gpu_materialize_encoding_gfx908.mlir",
            "gpu_materialize_encoding_gfx90a.mlir",
            "gpu_materialize_encoding_gfx942.mlir",
            "hoist_statically_bound_allocations.mlir",
            "hoist_unrolled_vector_extract_insert_slice.mlir",
            "iree_comprehensive_bufferize.mlir",
            "iree_expand_strided_metadata.mlir",
            "iree_loop_invariant_code_motion.mlir",
            "link_tuning_specs.mlir",
            "llvmcpu_materialize_encoding.mlir",
            "lower_ukernel_to_calls.mlir",
            "materialize_encoding_into_nop.mlir",
            "materialize_encoding_into_padding.mlir",
            "materialize_tuning_specs.mlir",
            "materialize_tuning_specs_default_missing.mlir",
            "materialize_tuning_specs_invalid_spec.mlir",
            "materialize_user_config_from_tuning_spec.mlir",
            "materialize_user_configs.mlir",
            "math_transform.mlir",
            "normalize_loop_bounds.mlir",
            "optimize_tensor_insert_extract_slices.mlir",
            "pad_dynamic_alloc.mlir",
            "propagate_dispatch_size_bounds.mlir",
            "propagate_reshapes_by_expansion.mlir",
            "reconcile_translation_info.mlir",
            "reductions.mlir",
            "rematerialize_parallel_ops.mlir",
            "remove_dead_allocs.mlir",
            "remove_trivial_loops.mlir",
            "repeated_matcher_use.mlir",
            "replace_slow_min_max_ops.mlir",
            "strip_compilation_info.mlir",
            "test_partitionable_loops_interface.mlir",
            "tile_and_distribute_to_workgroups.mlir",
            "tile_and_distribute_to_workgroups_func_scope.mlir",
            "tile_and_distribute_workgroups_using_forall.mlir",
            "tile_large_tensors.mlir",
            "transform_buffer_opt.mlir",
            "transform_copy_operand.mlir",
            "transform_flatten_forall.mlir",
            "transform_hoist_forall.mlir",
            "transform_match_partial_reduction.mlir",
            "transform_ops_invalid.mlir",
            "transpose_canonicalization.mlir",
            "type_propagation.mlir",
            "type_propagation_packing.mlir",
            "unroll_annotated_loops.mlir",
            "vector_layout_analysis.mlir",
            "vectorize_memref_copy.mlir",
            "vectorize_tensor_pad.mlir",
            "verify_tuning_specs.mlir",
            "verify_workgroup_distribution.mlir",
            "vmvx_materialize_encoding.mlir",
        ],
        include = ["*.mlir"],
        exclude = [
            "batch_matmul_match_spec.mlir",
            "convolution_match_spec.mlir",
            "reductions_codegen_spec.mlir",
            "reductions_match_spec.mlir",
            "tuning_spec.mlir",
            "tuning_spec_default.mlir",
        ],
    ),
    cfg = "//compiler:lit.cfg.py",
    # transform dialect spec files are MLIR files that specify a transformation,
    # they need to be included as data.
    data = [
        "batch_matmul_match_spec.mlir",
        "convolution_match_spec.mlir",
        "reductions_codegen_spec.mlir",
        "reductions_match_spec.mlir",
        "tuning_spec.mlir",
        "tuning_spec_default.mlir",
    ],
    tools = [
        "//tools:iree-opt",
        "@llvm-project//llvm:FileCheck",
    ],
)
