{
  "model": "nomic-ai/nomic-embed-text-v1.5",
  "description": "Nomic Embed Text v1.5 - WordPiece tokenizer (primary target)",
  "tests": [
    {
      "name": "simple_ascii",
      "input": "Hello, world!"
    },
    {
      "name": "unicode_accents",
      "input": "Héllo wörld! café résumé"
    },
    {
      "name": "unicode_cjk",
      "input": "Hello 你好世界 こんにちは"
    },
    {
      "name": "special_chars",
      "input": "Code: `x = 1` and $100"
    },
    {
      "name": "punctuation",
      "input": "Wait... Really?! Yes: it's true."
    },
    {
      "name": "numbers",
      "input": "The year 2026 has 365 days."
    },
    {
      "name": "empty_string",
      "input": ""
    },
    {
      "name": "whitespace_variations",
      "input": "hello   world\ttab\nnewline"
    },
    {
      "name": "no_special_tokens",
      "input": "hello world",
      "add_special_tokens": false
    },
    {
      "name": "search_query",
      "input": "search_query: What is machine learning?"
    },
    {
      "name": "search_document",
      "input": "search_document: Machine learning is a subset of artificial intelligence."
    },
    {
      "name": "long_text",
      "input": "The quick brown fox jumps over the lazy dog. This is a longer piece of text to test tokenization of multiple sentences and words."
    },
    {
      "name": "scientific",
      "input": "The formula is E=mc² where c is the speed of light (299,792,458 m/s)."
    }
  ]
}
