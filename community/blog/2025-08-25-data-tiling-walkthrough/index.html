
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://iree.dev/community/blog/2025-08-25-data-tiling-walkthrough/">
      
      
        <link rel="prev" href="../2024-01-29-iree-mlir-linalg-tutorial/">
      
      
      
      <link rel="icon" href="../../../assets/images/IREE_Logo_Icon_Color.svg">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.48">
    
    
      
        <title>Data-Tiling Walkthrough - IREE</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.6f8fc17f.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto:300,300i,400,400i,700,700i%7CNoto+Sans+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Noto";--md-code-font:"Noto Sans Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/extra.css">
    
      <link rel="stylesheet" href="../../../assets/stylesheets/iree.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#data-tiling-walkthrough" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="https://iree.dev/" title="IREE" class="md-header__button md-logo" aria-label="IREE" data-md-component="logo">
      
  <img src="../../../assets/images/IREE_Logo_Icon_Color.svg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            IREE
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Data-Tiling Walkthrough
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/iree-org/iree" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    iree-org/iree
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../.." class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../building-from-source/" class="md-tabs__link">
          
  
    
  
  Building from source

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../guides/" class="md-tabs__link">
          
  
    
  
  Guides

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../reference/" class="md-tabs__link">
          
  
    
  
  Reference

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../developers/" class="md-tabs__link">
          
  
    
  
  Developers

        </a>
      </li>
    
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../../" class="md-tabs__link">
          
  
    
  
  Community

        </a>
      </li>
    
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
                
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" hidden>
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="https://iree.dev/" title="IREE" class="md-nav__button md-logo" aria-label="IREE" data-md-component="logo">
      
  <img src="../../../assets/images/IREE_Logo_Icon_Color.svg" alt="logo">

    </a>
    IREE
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/iree-org/iree" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    iree-org/iree
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../building-from-source/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Building from source
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2" id="__nav_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Building from source
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../building-from-source/getting-started/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M3 2.75C3 1.784 3.784 1 4.75 1h6.5c.966 0 1.75.784 1.75 1.75v11.5a.75.75 0 0 1-1.227.579L8 11.722l-3.773 3.107A.751.751 0 0 1 3 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v9.91l3.023-2.489a.75.75 0 0 1 .954 0l3.023 2.49V2.75a.25.25 0 0 0-.25-.25Z"/></svg>
  
  <span class="md-ellipsis">
    Getting started
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../building-from-source/android/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18.44 5.559q-1.015 1.748-2.028 3.498-.055-.023-.111-.043a12.098 12.098 0 0 0-8.68.033C7.537 8.897 5.868 6.026 5.6 5.56a1 1 0 0 0-.141-.19 1.104 1.104 0 0 0-1.768 1.298c1.947 3.37-.096-.216 1.948 3.36.017.03-.495.263-1.393 1.017C2.9 12.176.452 14.772 0 18.99h24a11.7 11.7 0 0 0-.746-3.068 12.1 12.1 0 0 0-2.74-4.184 12 12 0 0 0-2.131-1.687c.66-1.122 1.312-2.256 1.965-3.385a1.11 1.11 0 0 0-.008-1.12 1.1 1.1 0 0 0-.852-.532c-.522-.054-.939.313-1.049.545m-.04 8.46c.395.593.324 1.331-.156 1.65-.48.32-1.188.1-1.582-.493s-.324-1.33.156-1.65c.473-.316 1.182-.11 1.582.494m-11.193-.492c.48.32.55 1.058.156 1.65-.394.593-1.103.815-1.584.495-.48-.32-.55-1.058-.156-1.65.4-.603 1.109-.811 1.584-.495"/></svg>
  
  <span class="md-ellipsis">
    Android cross-compilation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../building-from-source/ios/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12.152 6.896c-.948 0-2.415-1.078-3.96-1.04-2.04.027-3.91 1.183-4.961 3.014-2.117 3.675-.546 9.103 1.519 12.09 1.013 1.454 2.208 3.09 3.792 3.039 1.52-.065 2.09-.987 3.935-.987 1.831 0 2.35.987 3.96.948 1.637-.026 2.676-1.48 3.676-2.948 1.156-1.688 1.636-3.325 1.662-3.415-.039-.013-3.182-1.221-3.22-4.857-.026-3.04 2.48-4.494 2.597-4.559-1.429-2.09-3.623-2.324-4.39-2.376-2-.156-3.675 1.09-4.61 1.09zM15.53 3.83c.843-1.012 1.4-2.427 1.245-3.83-1.207.052-2.662.805-3.532 1.818-.78.896-1.454 2.338-1.273 3.714 1.338.104 2.715-.688 3.559-1.701"/></svg>
  
  <span class="md-ellipsis">
    iOS cross-compilation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../building-from-source/riscv/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M6.5.75V2h3V.75a.75.75 0 0 1 1.5 0V2h1.25c.966 0 1.75.784 1.75 1.75V5h1.25a.75.75 0 0 1 0 1.5H14v3h1.25a.75.75 0 0 1 0 1.5H14v1.25A1.75 1.75 0 0 1 12.25 14H11v1.25a.75.75 0 0 1-1.5 0V14h-3v1.25a.75.75 0 0 1-1.5 0V14H3.75A1.75 1.75 0 0 1 2 12.25V11H.75a.75.75 0 0 1 0-1.5H2v-3H.75a.75.75 0 0 1 0-1.5H2V3.75C2 2.784 2.784 2 3.75 2H5V.75a.75.75 0 0 1 1.5 0m5.75 11.75a.25.25 0 0 0 .25-.25v-8.5a.25.25 0 0 0-.25-.25h-8.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25ZM5.75 5h4.5a.75.75 0 0 1 .75.75v4.5a.75.75 0 0 1-.75.75h-4.5a.75.75 0 0 1-.75-.75v-4.5A.75.75 0 0 1 5.75 5m.75 4.5h3v-3h-3Z"/></svg>
  
  <span class="md-ellipsis">
    RISC-V cross-compilation
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../guides/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Guides
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3" id="__nav_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Guides
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../guides/ml-frameworks/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    ML frameworks
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3_2" id="__nav_3_2_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_2">
            <span class="md-nav__icon md-icon"></span>
            ML frameworks
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../guides/ml-frameworks/jax/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.25.18.9.2.73.26.59.3.45.32.34.34.25.34.16.33.1.3.04.26.02.2-.01.13V8.5l-.05.63-.13.55-.21.46-.26.38-.3.31-.33.25-.35.19-.35.14-.33.1-.3.07-.26.04-.21.02H8.77l-.69.05-.59.14-.5.22-.41.27-.33.32-.27.35-.2.36-.15.37-.1.35-.07.32-.04.27-.02.21v3.06H3.17l-.21-.03-.28-.07-.32-.12-.35-.18-.36-.26-.36-.36-.35-.46-.32-.59-.28-.73-.21-.88-.14-1.05-.05-1.23.06-1.22.16-1.04.24-.87.32-.71.36-.57.4-.44.42-.33.42-.24.4-.16.36-.1.32-.05.24-.01h.16l.06.01h8.16v-.83H6.18l-.01-2.75-.02-.37.05-.34.11-.31.17-.28.25-.26.31-.23.38-.2.44-.18.51-.15.58-.12.64-.1.71-.06.77-.04.84-.02 1.27.05zm-6.3 1.98-.23.33-.08.41.08.41.23.34.33.22.41.09.41-.09.33-.22.23-.34.08-.41-.08-.41-.23-.33-.33-.22-.41-.09-.41.09zm13.09 3.95.28.06.32.12.35.18.36.27.36.35.35.47.32.59.28.73.21.88.14 1.04.05 1.23-.06 1.23-.16 1.04-.24.86-.32.71-.36.57-.4.45-.42.33-.42.24-.4.16-.36.09-.32.05-.24.02-.16-.01h-8.22v.82h5.84l.01 2.76.02.36-.05.34-.11.31-.17.29-.25.25-.31.24-.38.2-.44.17-.51.15-.58.13-.64.09-.71.07-.77.04-.84.01-1.27-.04-1.07-.14-.9-.2-.73-.25-.59-.3-.45-.33-.34-.34-.25-.34-.16-.33-.1-.3-.04-.25-.02-.2.01-.13v-5.34l.05-.64.13-.54.21-.46.26-.38.3-.32.33-.24.35-.2.35-.14.33-.1.3-.06.26-.04.21-.02.13-.01h5.84l.69-.05.59-.14.5-.21.41-.28.33-.32.27-.35.2-.36.15-.36.1-.35.07-.32.04-.28.02-.21V6.07h2.09l.14.01zm-6.47 14.25-.23.33-.08.41.08.41.23.33.33.23.41.08.41-.08.33-.23.23-.33.08-.41-.08-.41-.23-.33-.33-.23-.41-.08-.41.08z"/></svg>
  
  <span class="md-ellipsis">
    JAX
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../guides/ml-frameworks/onnx/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M23.033 11.296c-.05 0-.101 0-.151.013L18.86 3.87a.968.968 0 0 0-1.558-1.118L9.286 1.156a.97.97 0 0 0-.968-.854.976.976 0 0 0-.967.967.93.93 0 0 0 .113.453L1.219 10.68a.8.8 0 0 0-.251-.038.968.968 0 0 0 0 1.935h.037l3.368 8.33a1.1 1.1 0 0 0-.088.403.968.968 0 0 0 1.671.666l10.115.993c.1.427.49.728.943.728.54 0 .967-.44.967-.967a1 1 0 0 0-.226-.628l5.114-8.872c.05.013.1.013.164.013.54 0 .967-.44.967-.968a.97.97 0 0 0-.967-.98zm-5.806-7.275a1 1 0 0 0 .453.327L16.147 15.92c-.1.025-.189.05-.277.1L7.451 8.708a.8.8 0 0 0 .038-.251c0-.063-.013-.126-.013-.189zm4.876 8.507-5.177 3.556a1 1 0 0 0-.126-.075l1.546-11.674h.012l3.946 7.288a.96.96 0 0 0-.201.905zM6.383 7.502a.98.98 0 0 0-.83.955v.062l-3.455 2.048 5.378-7.702zm.352 1.91a.9.9 0 0 0 .352-.164l8.356 7.263a1.1 1.1 0 0 0-.063.352v.05l-9.31 3.845a.97.97 0 0 0-.604-.402zm8.896 8.117a.92.92 0 0 0 .503.289l.465 4.046a1.05 1.05 0 0 0-.452.452l-9.814-.955zm1.144.213a.96.96 0 0 0 .54-.867.9.9 0 0 0-.038-.25l4.738-3.255-4.8 8.33zm.251-14.35-9.889 4.31-.113-.075 1.257-5.39h.037c.34 0 .641-.176.817-.44l7.891 1.57zM1.935 11.612c0-.063-.013-.126-.013-.189l3.908-2.3c.076.076.164.151.264.202L4.825 20.243l-3.204-7.904c.188-.176.314-.44.314-.728"/></svg>
  
  <span class="md-ellipsis">
    ONNX
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../guides/ml-frameworks/pytorch/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12.005 0 4.952 7.053a9.865 9.865 0 0 0 0 14.022 9.866 9.866 0 0 0 14.022 0c3.984-3.9 3.986-10.205.085-14.023l-1.744 1.743c2.904 2.905 2.904 7.634 0 10.538s-7.634 2.904-10.538 0-2.904-7.634 0-10.538l4.647-4.646.582-.665zm3.568 3.899a1.327 1.327 0 0 0-1.327 1.327 1.327 1.327 0 0 0 1.327 1.328A1.327 1.327 0 0 0 16.9 5.226 1.327 1.327 0 0 0 15.573 3.9z"/></svg>
  
  <span class="md-ellipsis">
    PyTorch
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../guides/ml-frameworks/tensorflow/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M1.292 5.856 11.54 0v24l-4.095-2.378V7.603l-6.168 3.564.015-5.31zm21.43 5.311-.014-5.31L12.46 0v24l4.095-2.378V14.87l3.092 1.788-.018-4.618-3.074-1.756V7.603z"/></svg>
  
  <span class="md-ellipsis">
    TensorFlow
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../guides/ml-frameworks/tflite/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M1.292 5.856 11.54 0v24l-4.095-2.378V7.603l-6.168 3.564.015-5.31zm21.43 5.311-.014-5.31L12.46 0v24l4.095-2.378V14.87l3.092 1.788-.018-4.618-3.074-1.756V7.603z"/></svg>
  
  <span class="md-ellipsis">
    TensorFlow Lite
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_3" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../guides/deployment-configurations/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Deployment configurations
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3_3" id="__nav_3_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_3">
            <span class="md-nav__icon md-icon"></span>
            Deployment configurations
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../guides/deployment-configurations/cpu/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M6.5.75V2h3V.75a.75.75 0 0 1 1.5 0V2h1.25c.966 0 1.75.784 1.75 1.75V5h1.25a.75.75 0 0 1 0 1.5H14v3h1.25a.75.75 0 0 1 0 1.5H14v1.25A1.75 1.75 0 0 1 12.25 14H11v1.25a.75.75 0 0 1-1.5 0V14h-3v1.25a.75.75 0 0 1-1.5 0V14H3.75A1.75 1.75 0 0 1 2 12.25V11H.75a.75.75 0 0 1 0-1.5H2v-3H.75a.75.75 0 0 1 0-1.5H2V3.75C2 2.784 2.784 2 3.75 2H5V.75a.75.75 0 0 1 1.5 0m5.75 11.75a.25.25 0 0 0 .25-.25v-8.5a.25.25 0 0 0-.25-.25h-8.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25ZM5.75 5h4.5a.75.75 0 0 1 .75.75v4.5a.75.75 0 0 1-.75.75h-4.5a.75.75 0 0 1-.75-.75v-4.5A.75.75 0 0 1 5.75 5m.75 4.5h3v-3h-3Z"/></svg>
  
  <span class="md-ellipsis">
    CPU
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../guides/deployment-configurations/bare-metal/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M6.5.75V2h3V.75a.75.75 0 0 1 1.5 0V2h1.25c.966 0 1.75.784 1.75 1.75V5h1.25a.75.75 0 0 1 0 1.5H14v3h1.25a.75.75 0 0 1 0 1.5H14v1.25A1.75 1.75 0 0 1 12.25 14H11v1.25a.75.75 0 0 1-1.5 0V14h-3v1.25a.75.75 0 0 1-1.5 0V14H3.75A1.75 1.75 0 0 1 2 12.25V11H.75a.75.75 0 0 1 0-1.5H2v-3H.75a.75.75 0 0 1 0-1.5H2V3.75C2 2.784 2.784 2 3.75 2H5V.75a.75.75 0 0 1 1.5 0m5.75 11.75a.25.25 0 0 0 .25-.25v-8.5a.25.25 0 0 0-.25-.25h-8.5a.25.25 0 0 0-.25.25v8.5c0 .138.112.25.25.25ZM5.75 5h4.5a.75.75 0 0 1 .75.75v4.5a.75.75 0 0 1-.75.75h-4.5a.75.75 0 0 1-.75-.75v-4.5A.75.75 0 0 1 5.75 5m.75 4.5h3v-3h-3Z"/></svg>
  
  <span class="md-ellipsis">
    CPU - Bare-Metal
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../guides/deployment-configurations/gpu-vulkan/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M1.75 1h12.5c.966 0 1.75.784 1.75 1.75v4c0 .372-.116.717-.314 1 .198.283.314.628.314 1v4a1.75 1.75 0 0 1-1.75 1.75H1.75A1.75 1.75 0 0 1 0 12.75v-4c0-.358.109-.707.314-1a1.74 1.74 0 0 1-.314-1v-4C0 1.784.784 1 1.75 1M1.5 2.75v4c0 .138.112.25.25.25h12.5a.25.25 0 0 0 .25-.25v-4a.25.25 0 0 0-.25-.25H1.75a.25.25 0 0 0-.25.25m.25 5.75a.25.25 0 0 0-.25.25v4c0 .138.112.25.25.25h12.5a.25.25 0 0 0 .25-.25v-4a.25.25 0 0 0-.25-.25ZM7 4.75A.75.75 0 0 1 7.75 4h4.5a.75.75 0 0 1 0 1.5h-4.5A.75.75 0 0 1 7 4.75M7.75 10h4.5a.75.75 0 0 1 0 1.5h-4.5a.75.75 0 0 1 0-1.5M3 4.75A.75.75 0 0 1 3.75 4h.5a.75.75 0 0 1 0 1.5h-.5A.75.75 0 0 1 3 4.75M3.75 10h.5a.75.75 0 0 1 0 1.5h-.5a.75.75 0 0 1 0-1.5"/></svg>
  
  <span class="md-ellipsis">
    GPU - Vulkan
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../guides/deployment-configurations/gpu-rocm/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m18.324 9.137 1.559 1.56h2.556v2.557L24 14.814V9.137zM2 9.52l-2 4.96h1.309l.37-.982H3.9l.408.982h1.338L3.432 9.52zm4.209 0v4.955h1.238v-3.092l1.338 1.562h.188l1.338-1.556v3.091h1.238V9.52H10.47l-1.592 1.845L7.287 9.52zm6.283 0v4.96h2.057c1.979 0 2.88-1.046 2.88-2.472 0-1.36-.937-2.488-2.747-2.488zm1.237.91h.792c1.17 0 1.63.711 1.63 1.57 0 .728-.372 1.572-1.616 1.572h-.806zm-10.985.273.791 1.932H2.008zm17.137.307-1.604 1.603v2.25h2.246l1.604-1.607h-2.246z"/></svg>
  
  <span class="md-ellipsis">
    GPU - ROCm
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../guides/deployment-configurations/gpu-cuda/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M8.948 8.798v-1.43a7 7 0 0 1 .424-.018c3.922-.124 6.493 3.374 6.493 3.374s-2.774 3.851-5.75 3.851a3.7 3.7 0 0 1-1.158-.185v-4.346c1.528.185 1.837.857 2.747 2.385l2.04-1.714s-1.492-1.952-4-1.952a6 6 0 0 0-.796.035m0-4.735v2.138l.424-.027c5.45-.185 9.01 4.47 9.01 4.47s-4.08 4.964-8.33 4.964a6.5 6.5 0 0 1-1.095-.097v1.325c.3.035.61.062.91.062 3.957 0 6.82-2.023 9.593-4.408.459.371 2.34 1.263 2.73 1.652-2.633 2.208-8.772 3.984-12.253 3.984-.335 0-.653-.018-.971-.053v1.864H24V4.063zm0 10.326v1.131c-3.657-.654-4.673-4.46-4.673-4.46s1.758-1.944 4.673-2.262v1.237H8.94c-1.528-.186-2.73 1.245-2.73 1.245s.68 2.412 2.739 3.11M2.456 10.9s2.164-3.197 6.5-3.533V6.201C4.153 6.59 0 10.653 0 10.653s2.35 6.802 8.948 7.42v-1.237c-4.84-.6-6.492-5.936-6.492-5.936"/></svg>
  
  <span class="md-ellipsis">
    GPU - CUDA
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../guides/deployment-configurations/gpu-metal/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12.152 6.896c-.948 0-2.415-1.078-3.96-1.04-2.04.027-3.91 1.183-4.961 3.014-2.117 3.675-.546 9.103 1.519 12.09 1.013 1.454 2.208 3.09 3.792 3.039 1.52-.065 2.09-.987 3.935-.987 1.831 0 2.35.987 3.96.948 1.637-.026 2.676-1.48 3.676-2.948 1.156-1.688 1.636-3.325 1.662-3.415-.039-.013-3.182-1.221-3.22-4.857-.026-3.04 2.48-4.494 2.597-4.559-1.429-2.09-3.623-2.324-4.39-2.376-2-.156-3.675 1.09-4.61 1.09zM15.53 3.83c.843-1.012 1.4-2.427 1.245-3.83-1.207.052-2.662.805-3.532 1.818-.78.896-1.454 2.338-1.273 3.714 1.338.104 2.715-.688 3.559-1.701"/></svg>
  
  <span class="md-ellipsis">
    GPU - Metal
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3_4" >
        
          
          <label class="md-nav__link" for="__nav_3_4" id="__nav_3_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    General topics
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_4">
            <span class="md-nav__icon md-icon"></span>
            General topics
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../guides/parameters/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M2 1.75C2 .784 2.784 0 3.75 0h5.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v8.586A1.75 1.75 0 0 1 12.25 15h-7a.75.75 0 0 1 0-1.5h7a.25.25 0 0 0 .25-.25V6H9.75A1.75 1.75 0 0 1 8 4.25V1.5H3.75a.25.25 0 0 0-.25.25V4.5a.75.75 0 0 1-1.5 0Zm-.5 10.487v1.013a.75.75 0 0 1-1.5 0v-1.012a3.75 3.75 0 0 1 3.77-3.749L4 8.49V6.573a.25.25 0 0 1 .42-.183l2.883 2.678a.25.25 0 0 1 0 .366L4.42 12.111a.25.25 0 0 1-.42-.183V9.99l-.238-.003a2.25 2.25 0 0 0-2.262 2.25m8-10.675V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914z"/></svg>
  
  <span class="md-ellipsis">
    Parameters
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../reference/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Reference
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4" id="__nav_4_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Reference
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4_2" >
        
          
          <label class="md-nav__link" for="__nav_4_2" id="__nav_4_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    General topics
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_2">
            <span class="md-nav__icon md-icon"></span>
            General topics
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference/glossary/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M0 1.75A.75.75 0 0 1 .75 1h4.253c1.227 0 2.317.59 3 1.501A3.74 3.74 0 0 1 11.006 1h4.245a.75.75 0 0 1 .75.75v10.5a.75.75 0 0 1-.75.75h-4.507a2.25 2.25 0 0 0-1.591.659l-.622.621a.75.75 0 0 1-1.06 0l-.622-.621A2.25 2.25 0 0 0 5.258 13H.75a.75.75 0 0 1-.75-.75Zm7.251 10.324.004-5.073-.002-2.253A2.25 2.25 0 0 0 5.003 2.5H1.5v9h3.757a3.75 3.75 0 0 1 1.994.574M8.755 4.75l-.004 7.322a3.75 3.75 0 0 1 1.992-.572H14.5v-9h-3.495a2.25 2.25 0 0 0-2.25 2.25"/></svg>
  
  <span class="md-ellipsis">
    Glossary
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference/optimization-options/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M14.064 0h.186C15.216 0 16 .784 16 1.75v.186a8.75 8.75 0 0 1-2.564 6.186l-.458.459q-.472.471-.979.904v3.207c0 .608-.315 1.172-.833 1.49l-2.774 1.707a.75.75 0 0 1-1.11-.418l-.954-3.102a1 1 0 0 1-.145-.125L3.754 9.816a1 1 0 0 1-.124-.145L.528 8.717a.75.75 0 0 1-.418-1.11l1.71-2.774A1.75 1.75 0 0 1 3.31 4h3.204q.433-.508.904-.979l.459-.458A8.75 8.75 0 0 1 14.064 0M8.938 3.623h-.002l-.458.458c-.76.76-1.437 1.598-2.02 2.5l-1.5 2.317 2.143 2.143 2.317-1.5c.902-.583 1.74-1.26 2.499-2.02l.459-.458a7.25 7.25 0 0 0 2.123-5.127V1.75a.25.25 0 0 0-.25-.25h-.186a7.25 7.25 0 0 0-5.125 2.123M3.56 14.56c-.732.732-2.334 1.045-3.005 1.148a.23.23 0 0 1-.201-.064.23.23 0 0 1-.064-.201c.103-.671.416-2.273 1.15-3.003a1.502 1.502 0 1 1 2.12 2.12m6.94-3.935q-.132.09-.266.175l-2.35 1.521.548 1.783 1.949-1.2a.25.25 0 0 0 .119-.213ZM3.678 8.116 5.2 5.766q.087-.135.176-.266H3.309a.25.25 0 0 0-.213.119l-1.2 1.95ZM12 5a1 1 0 1 1-2 0 1 1 0 0 1 2 0"/></svg>
  
  <span class="md-ellipsis">
    Optimization options
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference/tuning/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M8 1.5a6.5 6.5 0 1 0 6.016 4.035.75.75 0 0 1 1.388-.57 8 8 0 1 1-4.37-4.37.75.75 0 1 1-.569 1.389A6.5 6.5 0 0 0 8 1.5m6.28.22a.75.75 0 0 1 0 1.06l-4.063 4.064a2.5 2.5 0 1 1-1.06-1.06L13.22 1.72a.75.75 0 0 1 1.06 0M7 8a1 1 0 1 0 2 0 1 1 0 0 0-2 0"/></svg>
  
  <span class="md-ellipsis">
    Tuning
  </span>
  
    
  
  
    <span class="md-status md-status--new" title="Recently updated">
    </span>
  

  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference/extensions/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M8 0a8 8 0 0 1 .701.031C9.444.095 9.99.645 10.16 1.29l.288 1.107c.018.066.079.158.212.224q.347.171.668.386c.123.082.233.09.299.071l1.103-.303c.644-.176 1.392.021 1.82.63q.406.578.704 1.218c.315.675.111 1.422-.364 1.891l-.814.806c-.049.048-.098.147-.088.294q.024.386 0 .772c-.01.147.038.246.088.294l.814.806c.475.469.679 1.216.364 1.891a8 8 0 0 1-.704 1.217c-.428.61-1.176.807-1.82.63l-1.102-.302c-.067-.019-.177-.011-.3.071a6 6 0 0 1-.668.386c-.133.066-.194.158-.211.224l-.29 1.106c-.168.646-.715 1.196-1.458 1.26a8 8 0 0 1-1.402 0c-.743-.064-1.289-.614-1.458-1.26l-.289-1.106c-.018-.066-.079-.158-.212-.224a6 6 0 0 1-.668-.386c-.123-.082-.233-.09-.299-.071l-1.103.303c-.644.176-1.392-.021-1.82-.63a8 8 0 0 1-.704-1.218c-.315-.675-.111-1.422.363-1.891l.815-.806c.05-.048.098-.147.088-.294a6 6 0 0 1 0-.772c.01-.147-.038-.246-.088-.294l-.815-.806C.635 6.045.431 5.298.746 4.623a8 8 0 0 1 .704-1.217c.428-.61 1.176-.807 1.82-.63l1.102.302c.067.019.177.011.3-.071q.321-.215.668-.386c.133-.066.194-.158.211-.224l.29-1.106C6.009.645 6.556.095 7.299.03Q7.646 0 8 0m-.571 1.525c-.036.003-.108.036-.137.146l-.289 1.105c-.147.561-.549.967-.998 1.189q-.26.13-.5.29c-.417.278-.97.423-1.529.27l-1.103-.303c-.109-.03-.175.016-.195.045q-.33.47-.573.99c-.014.031-.021.11.059.19l.815.806c.411.406.562.957.53 1.456a5 5 0 0 0 0 .582c.032.499-.119 1.05-.53 1.456l-.815.806c-.081.08-.073.159-.059.19q.243.52.573.989c.02.03.085.076.195.046l1.102-.303c.56-.153 1.113-.008 1.53.27q.242.16.501.29c.447.222.85.629.997 1.189l.289 1.105c.029.109.101.143.137.146a6.6 6.6 0 0 0 1.142 0c.036-.003.108-.036.137-.146l.289-1.105c.147-.561.549-.967.998-1.189q.26-.13.5-.29c.417-.278.97-.423 1.529-.27l1.103.303c.109.029.175-.016.195-.045q.33-.47.573-.99c.014-.031.021-.11-.059-.19l-.815-.806c-.411-.406-.562-.957-.53-1.456a5 5 0 0 0 0-.582c-.032-.499.119-1.05.53-1.456l.815-.806c.081-.08.073-.159.059-.19a6.5 6.5 0 0 0-.573-.989c-.02-.03-.085-.076-.195-.046l-1.102.303c-.56.153-1.113.008-1.53-.27a4.4 4.4 0 0 0-.501-.29c-.447-.222-.85-.629-.997-1.189l-.289-1.105c-.029-.11-.101-.143-.137-.146a6.6 6.6 0 0 0-1.142 0M11 8a3 3 0 1 1-6 0 3 3 0 0 1 6 0M9.5 8a1.5 1.5 0 1 0-3.001.001A1.5 1.5 0 0 0 9.5 8"/></svg>
  
  <span class="md-ellipsis">
    Extensions
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4_3" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../reference/bindings/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    API bindings
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4_3" id="__nav_4_3_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_3">
            <span class="md-nav__icon md-icon"></span>
            API bindings
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference/bindings/c-api/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="m11.28 3.22 4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.275-.326.75.75 0 0 1 .215-.734L13.94 8l-3.72-3.72a.749.749 0 0 1 .326-1.275.75.75 0 0 1 .734.215m-6.56 0a.75.75 0 0 1 1.042.018.75.75 0 0 1 .018 1.042L2.06 8l3.72 3.72a.749.749 0 0 1-.326 1.275.75.75 0 0 1-.734-.215L.47 8.53a.75.75 0 0 1 0-1.06Z"/></svg>
  
  <span class="md-ellipsis">
    C API
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference/bindings/python/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.25.18.9.2.73.26.59.3.45.32.34.34.25.34.16.33.1.3.04.26.02.2-.01.13V8.5l-.05.63-.13.55-.21.46-.26.38-.3.31-.33.25-.35.19-.35.14-.33.1-.3.07-.26.04-.21.02H8.77l-.69.05-.59.14-.5.22-.41.27-.33.32-.27.35-.2.36-.15.37-.1.35-.07.32-.04.27-.02.21v3.06H3.17l-.21-.03-.28-.07-.32-.12-.35-.18-.36-.26-.36-.36-.35-.46-.32-.59-.28-.73-.21-.88-.14-1.05-.05-1.23.06-1.22.16-1.04.24-.87.32-.71.36-.57.4-.44.42-.33.42-.24.4-.16.36-.1.32-.05.24-.01h.16l.06.01h8.16v-.83H6.18l-.01-2.75-.02-.37.05-.34.11-.31.17-.28.25-.26.31-.23.38-.2.44-.18.51-.15.58-.12.64-.1.71-.06.77-.04.84-.02 1.27.05zm-6.3 1.98-.23.33-.08.41.08.41.23.34.33.22.41.09.41-.09.33-.22.23-.34.08-.41-.08-.41-.23-.33-.33-.22-.41-.09-.41.09zm13.09 3.95.28.06.32.12.35.18.36.27.36.35.35.47.32.59.28.73.21.88.14 1.04.05 1.23-.06 1.23-.16 1.04-.24.86-.32.71-.36.57-.4.45-.42.33-.42.24-.4.16-.36.09-.32.05-.24.02-.16-.01h-8.22v.82h5.84l.01 2.76.02.36-.05.34-.11.31-.17.29-.25.25-.31.24-.38.2-.44.17-.51.15-.58.13-.64.09-.71.07-.77.04-.84.01-1.27-.04-1.07-.14-.9-.2-.73-.25-.59-.3-.45-.33-.34-.34-.25-.34-.16-.33-.1-.3-.04-.25-.02-.2.01-.13v-5.34l.05-.64.13-.54.21-.46.26-.38.3-.32.33-.24.35-.2.35-.14.33-.1.3-.06.26-.04.21-.02.13-.01h5.84l.69-.05.59-.14.5-.21.41-.28.33-.32.27-.35.2-.36.15-.36.1-.35.07-.32.04-.28.02-.21V6.07h2.09l.14.01zm-6.47 14.25-.23.33-.08.41.08.41.23.33.33.23.41.08.41-.08.33-.23.23-.33.08-.41-.08-.41-.23-.33-.33-.23-.41-.08-.41.08z"/></svg>
  
  <span class="md-ellipsis">
    Python
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4_4" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../reference/mlir-dialects/" class="md-nav__link ">
              
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m20.83 2.978-.086.095a16 16 0 0 0-1.19 1.487 6 6 0 0 0-.446.719 3 3 0 0 0-.249.596.5.5 0 0 0-.033.177v.004a.3.3 0 0 0-.21.29.3.3 0 0 0 .187.284c.038.371.08 1.142.07 2.2l-.004.142a8 8 0 0 1-.434 2.327q-.024-.015-.04-.013c-.03.003-.11.12-.19.251-.058.09-.119.195-.154.291a.4.4 0 0 0-.03.14.3.3 0 0 0 .01.088c.01.037.022.058.022.058l-.003.007a.14.14 0 0 0-.028.067l-.012.029a7 7 0 0 1-.257.527l-.077.142-.07.115-.022-.014a.16.16 0 0 0-.113.024c-.047.035-.151.194-.498.368a1.4 1.4 0 0 1-.32.114 14 14 0 0 0 .248-2.07 5 5 0 0 0-.064-1.057q.004-.016.003-.017l-.005.01a4 4 0 0 0-.104-.458 3.55 3.55 0 0 0-.724-1.385c-.631-.754-1.496-1.14-2.256-1.165l-.125-.002q0-.012.002-.022c.02-.098.024-.127-.087-.032l-.057.054-.146.007a1 1 0 0 1-.003-.108c.004-.076.024-.127-.087-.032a.6.6 0 0 0-.142.167c-.05.008-.08.015-.08.015l.045-.002-.047.008c-.016-.042-.053-.105-.048-.16.01-.118.043-.14-.037-.065-.098.09-.202.226-.22.3l-.096.03c-.018-.019-.074-.07-.086-.179-.013-.11-.012-.166-.08-.05a1.1 1.1 0 0 0-.13.348q-.048.022-.093.046a.27.27 0 0 1-.057-.173c-.005-.144.04-.26-.067-.068a1.6 1.6 0 0 0-.146.406 2 2 0 0 0-.105.08 3 3 0 0 1-.008-.17c-.002-.143.021-.296-.067-.026a2 2 0 0 0-.07.321c-.404.385-.65.917-.644 1.572v.007a3 3 0 0 0 .014.33q.031.356.107.605c-.095.13-.103.689-.01.818.073.104.496.35.586.399a.4.4 0 0 1 .094.093c.115.188.115.567.027.762-.107.238.107.285.285.32s.415-.023.463-.118c.047-.095-.154-.31-.237-.748-.084-.439.13-.474.13-.474s.095.024.237.249c.11.175.227.313.336.413a.7.7 0 0 1-.201.172c.12.005.24-.051.304-.087a1 1 0 0 0 .07.045l-.05.05a.5.5 0 0 0 .109-.022.3.3 0 0 0 .084.022c.155.012.57-.368.57-.439q-.002-.028-.038-.063c-.042-.045-.12-.1-.207-.177a1 1 0 0 1-.11-.116.7.7 0 0 1-.141-.374v-.01l-.003-.031s.007-.007.016-.02v.004l.004-.01c.052-.08.15-.379-.47-1.078a3.05 3.05 0 0 0-.924-.706c-.042-.472.15-.913.626-1.13l-.005.005.008-.006c.227-.102.517-.155.877-.136.69.036 1.22.36 1.59.845.514.712.738 1.78.575 2.856-.068.065-.055.075-.013.077a5 5 0 0 1-.055.273l-.027.015c-.123.074-.071.073 0 .092l-.006.02a4 4 0 0 1-.066.193 1 1 0 0 0-.087.03c-.135.053-.08.06-.012.09l.044.023a6 6 0 0 1-.101.237 1 1 0 0 0-.08.017c-.142.036-.088.05-.024.09l.04.027a7 7 0 0 1-.107.214 1 1 0 0 0-.153.025c-.14.036-.087.05-.023.09q.05.03.08.059l-.094.165-.023.036a.6.6 0 0 0-.206.024c-.142.036-.088.05-.024.09a.7.7 0 0 1 .104.079l-.126.18a.5.5 0 0 0-.23-.005c-.144.02-.092.04-.033.086.068.053.1.099.118.118l-.062.084c-.044-.058-.15-.124-.246-.193a.9.9 0 0 0-.29-.13c-.048 0-.2.268-1.017.197-.819-.071-.87-.15-.942-.15a1 1 0 0 0-.228.059l-.034-.02a11 11 0 0 1-.972-.674c-.464-.37-.72-.647-.72-.647s.137-.125-.047-.284a3 3 0 0 0-.338-.277 2 2 0 0 0-.242-.166l-.088-.127a12 12 0 0 1-.363-.628 11 11 0 0 1-.25-.527c-.16-.36-.27-.682-.346-.964a5.6 5.6 0 0 1-.148-.923 2 2 0 0 1 .004-.242.41.41 0 0 0 .158-.323.41.41 0 0 0-.358-.407c-.204-.427-.982-1.477-3.881-3.68l-.127-.097.005.004-.036-.027C7.067 6.599 7.644 7.587 7.795 8l-.027.033-.018-.013c.018 0 .025-.005.025-.005s-.672-.546-1.787-1.23c-1.118-.687-1.748-.849-1.88-.877l-.026-.006s.206.19.174.285c-.01.032-.168.022-.421.028a4 4 0 0 0-.725.07 4.1 4.1 0 0 0-1.567.63C.238 7.785 0 8.401 0 8.401s.55-.768 1.58-1.305c-.014.337-.047 1.97.445 4.12.53 2.32 1.53 4.487 1.614 4.665.004.178.016.272.016.272s.148-1.79.756-3.647c.175.283.758 1.117 2.075 2.096 1.628 1.21 2.37 1.536 2.4 1.548.001.157.005.24.005.24s.005-.1.018-.263a4.7 4.7 0 0 1 .552-.67 3.6 3.6 0 0 1 .54-.435q.048.166.093.276-.029-.145-.052-.282c.107.01.538.066 1.206.393.343.168.609.395.798.595l-.014.006s.123.112.269.403a2.4 2.4 0 0 0-.73.084 3 3 0 0 0-.098-.19.5.5 0 0 0-.039-.134c-.027-.061-.095-.1-.164-.14a.4.4 0 0 0-.104-.073.2.2 0 0 1-.055-.073c-.084-.184-.798.012-.942.18-.175.204-.209.464-.14.608.021.045.07.082.138.11.002.22.137.75.404 1.133a5 5 0 0 1-.108-.666c-.009-.16 0-.274.015-.35.047.328.174.684.577 1.124-.248-.54-.22-.861-.195-1.143l.01-.044.005-.001c.036.263.142.534.482.963l-.014-.028.014.021a1.63 1.63 0 0 1-.167-1.03l.008-.002q.07.044.134.126c.128.172.188.349.212.47a.53.53 0 0 0 .067.383 18 18 0 0 1-.72.501c-.23.15-.49.313-.757.47q-.21.121-.414.23l-.135-.077h.002l-.008-.004c-.97-.559-1.69-.932-2.518-1.082-.93-.166-1.786.283-1.982 1.082a1.28 1.28 0 0 0 .552 1.38l.012.008q.02.014.04.026l.06.036h.002a2.1 2.1 0 0 0 .69.237l.028.005h.006a4 4 0 0 0 .412.044c.975.047 2.156-.408 3.323-.982q.15.08.306.166c2.547 1.403 4.098 1.585 6.154.728-.502.151-1.208.356-2.094.344a.1.1 0 0 0-.02-.006v.006a6 6 0 0 1-.647-.05l-.03-.004v-.003l-.001.002a6.3 6.3 0 0 1-1.556-.436 8 8 0 0 1-.745-.362 57 57 0 0 1-1.006-.569c.348-.178.692-.363 1.026-.545.355-.189.672-.362.918-.5l.009-.004h.007s.083-.019.16-.043c.17-.052.41-.149.695-.283.028.117.095.215.195.253.235.091.407.027.522-.102l.018-.01.047-.037c.05-.03.107-.067.156-.09l.053-.022q.06-.016.116-.037l.033-.01c-.145.297-.091.581-.091.581.043-.37.22-.608.392-.715q.096-.041.2-.067c.064 0 .116.023.144.07.07.12.217.194.364.226.024.15-.045.404-.4.866l.09-.062.004-.003.072-.053q.213-.162.334-.305a1 1 0 0 0 .19-.305c.013.2-.042.507-.31 1.036 0 0 .317-.276.514-.63.006.191-.01.443-.063.785.345-.673.325-1.085.239-1.326l-.01-.036a.4.4 0 0 0-.01-.065l.042-.057c.118-.166-.048-.344-.154-.414-.06-.04-.2-.154-.454-.157-.225-.27-.51-.15-.958.145a1.3 1.3 0 0 1-.166.092 1 1 0 0 0-.055-.116q.241-.145.494-.308c.317-.207.553-.416.728-.615.51-.517.69-1.02 1.21-1.446h-.013l.06-.031c.854-.458 1.306-.547 1.338-.553l-.003.128.018-.125a1.8 1.8 0 0 1 .481.344 2.1 2.1 0 0 1 .362.487l.044.3s0-.116-.01-.33c.153-.151 1.02-1.043 1.724-2.466.694-1.404.944-2.523 1.017-2.924a18 18 0 0 1 .665 2.466s-.002-.133-.03-.374c.096-.336.515-1.872.626-3.756.1-1.68-.065-2.78-.14-3.173.648.536.995 1.306.995 1.306s-.04-.163-.188-.437l.02.027s-.236-.455-.644-.904a7 7 0 0 0-.157-.172c-.432-.46-.854-.617-1.17-.672a1.6 1.6 0 0 0-.308-.03h-.019c-.125-.003-.2.002-.207-.026-.02-.095.11-.285.11-.285s-.177.046-.554.33c-.23.167-.52.41-.853.76a14 14 0 0 0-.89.994l-.075.095-.023-.017c.076-.33.362-1.117 1.788-3.111zM11.92 14.09l.012.006zm-.263 2.606q.133.064.303.194h-.005a.5.5 0 0 0-.155.07 1 1 0 0 1-.126-.224zm-4.855 1.57q.198-.002.432.047l.02.005.017.004q.165.041.337.102l.057.021q.287.11.611.248c.32.14.62.277.838.375l.183.088c-.22.106-.424.196-.577.261-1.014.416-1.83.536-2.338.391-.944-.269-.76-1.536.42-1.542"/></svg>
  
  <span class="md-ellipsis">
    MLIR dialects
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4_4" id="__nav_4_4_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_4">
            <span class="md-nav__icon md-icon"></span>
            MLIR dialects
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4_4_2" >
        
          
          <label class="md-nav__link" for="__nav_4_4_2" id="__nav_4_4_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Core
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_4_4_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_4_2">
            <span class="md-nav__icon md-icon"></span>
            Core
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference/mlir-dialects/Flow/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Flow
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference/mlir-dialects/HAL/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    HAL
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference/mlir-dialects/Stream/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Stream
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference/mlir-dialects/Util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference/mlir-dialects/VM/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    VM
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4_4_3" >
        
          
          <label class="md-nav__link" for="__nav_4_4_3" id="__nav_4_4_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    MLIR extensions
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_4_4_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_4_3">
            <span class="md-nav__icon md-icon"></span>
            MLIR extensions
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference/mlir-dialects/Encoding/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Encoding
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference/mlir-dialects/LinalgExt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    LinalgExt
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference/mlir-dialects/TensorExt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TensorExt
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4_4_4" >
        
          
          <label class="md-nav__link" for="__nav_4_4_4" id="__nav_4_4_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Codegen/target-specific
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_4_4_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_4_4">
            <span class="md-nav__icon md-icon"></span>
            Codegen/target-specific
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference/mlir-dialects/IREECodegen/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    IREECodegen
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference/mlir-dialects/IREEGPU/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    IREEGPU
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference/mlir-dialects/IREEVectorExt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    IREEVectorExt
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference/mlir-dialects/VMVX/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    VMVX
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4_4_5" >
        
          
          <label class="md-nav__link" for="__nav_4_4_5" id="__nav_4_4_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Optional modules
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_4_4_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_4_5">
            <span class="md-nav__icon md-icon"></span>
            Optional modules
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference/mlir-dialects/Check/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Check
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4_4_5_2" >
        
          
          <label class="md-nav__link" for="__nav_4_4_5_2" id="__nav_4_4_5_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    HAL
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_4_4_5_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_4_5_2">
            <span class="md-nav__icon md-icon"></span>
            HAL
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference/mlir-dialects/HALInline/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Inline
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference/mlir-dialects/HALLoader/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Loader
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4_4_5_3" >
        
          
          <label class="md-nav__link" for="__nav_4_4_5_3" id="__nav_4_4_5_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    IO
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_4_4_5_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_4_5_3">
            <span class="md-nav__icon md-icon"></span>
            IO
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference/mlir-dialects/IOParameters/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Parameters
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4_5" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../reference/mlir-passes/" class="md-nav__link ">
              
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m20.83 2.978-.086.095a16 16 0 0 0-1.19 1.487 6 6 0 0 0-.446.719 3 3 0 0 0-.249.596.5.5 0 0 0-.033.177v.004a.3.3 0 0 0-.21.29.3.3 0 0 0 .187.284c.038.371.08 1.142.07 2.2l-.004.142a8 8 0 0 1-.434 2.327q-.024-.015-.04-.013c-.03.003-.11.12-.19.251-.058.09-.119.195-.154.291a.4.4 0 0 0-.03.14.3.3 0 0 0 .01.088c.01.037.022.058.022.058l-.003.007a.14.14 0 0 0-.028.067l-.012.029a7 7 0 0 1-.257.527l-.077.142-.07.115-.022-.014a.16.16 0 0 0-.113.024c-.047.035-.151.194-.498.368a1.4 1.4 0 0 1-.32.114 14 14 0 0 0 .248-2.07 5 5 0 0 0-.064-1.057q.004-.016.003-.017l-.005.01a4 4 0 0 0-.104-.458 3.55 3.55 0 0 0-.724-1.385c-.631-.754-1.496-1.14-2.256-1.165l-.125-.002q0-.012.002-.022c.02-.098.024-.127-.087-.032l-.057.054-.146.007a1 1 0 0 1-.003-.108c.004-.076.024-.127-.087-.032a.6.6 0 0 0-.142.167c-.05.008-.08.015-.08.015l.045-.002-.047.008c-.016-.042-.053-.105-.048-.16.01-.118.043-.14-.037-.065-.098.09-.202.226-.22.3l-.096.03c-.018-.019-.074-.07-.086-.179-.013-.11-.012-.166-.08-.05a1.1 1.1 0 0 0-.13.348q-.048.022-.093.046a.27.27 0 0 1-.057-.173c-.005-.144.04-.26-.067-.068a1.6 1.6 0 0 0-.146.406 2 2 0 0 0-.105.08 3 3 0 0 1-.008-.17c-.002-.143.021-.296-.067-.026a2 2 0 0 0-.07.321c-.404.385-.65.917-.644 1.572v.007a3 3 0 0 0 .014.33q.031.356.107.605c-.095.13-.103.689-.01.818.073.104.496.35.586.399a.4.4 0 0 1 .094.093c.115.188.115.567.027.762-.107.238.107.285.285.32s.415-.023.463-.118c.047-.095-.154-.31-.237-.748-.084-.439.13-.474.13-.474s.095.024.237.249c.11.175.227.313.336.413a.7.7 0 0 1-.201.172c.12.005.24-.051.304-.087a1 1 0 0 0 .07.045l-.05.05a.5.5 0 0 0 .109-.022.3.3 0 0 0 .084.022c.155.012.57-.368.57-.439q-.002-.028-.038-.063c-.042-.045-.12-.1-.207-.177a1 1 0 0 1-.11-.116.7.7 0 0 1-.141-.374v-.01l-.003-.031s.007-.007.016-.02v.004l.004-.01c.052-.08.15-.379-.47-1.078a3.05 3.05 0 0 0-.924-.706c-.042-.472.15-.913.626-1.13l-.005.005.008-.006c.227-.102.517-.155.877-.136.69.036 1.22.36 1.59.845.514.712.738 1.78.575 2.856-.068.065-.055.075-.013.077a5 5 0 0 1-.055.273l-.027.015c-.123.074-.071.073 0 .092l-.006.02a4 4 0 0 1-.066.193 1 1 0 0 0-.087.03c-.135.053-.08.06-.012.09l.044.023a6 6 0 0 1-.101.237 1 1 0 0 0-.08.017c-.142.036-.088.05-.024.09l.04.027a7 7 0 0 1-.107.214 1 1 0 0 0-.153.025c-.14.036-.087.05-.023.09q.05.03.08.059l-.094.165-.023.036a.6.6 0 0 0-.206.024c-.142.036-.088.05-.024.09a.7.7 0 0 1 .104.079l-.126.18a.5.5 0 0 0-.23-.005c-.144.02-.092.04-.033.086.068.053.1.099.118.118l-.062.084c-.044-.058-.15-.124-.246-.193a.9.9 0 0 0-.29-.13c-.048 0-.2.268-1.017.197-.819-.071-.87-.15-.942-.15a1 1 0 0 0-.228.059l-.034-.02a11 11 0 0 1-.972-.674c-.464-.37-.72-.647-.72-.647s.137-.125-.047-.284a3 3 0 0 0-.338-.277 2 2 0 0 0-.242-.166l-.088-.127a12 12 0 0 1-.363-.628 11 11 0 0 1-.25-.527c-.16-.36-.27-.682-.346-.964a5.6 5.6 0 0 1-.148-.923 2 2 0 0 1 .004-.242.41.41 0 0 0 .158-.323.41.41 0 0 0-.358-.407c-.204-.427-.982-1.477-3.881-3.68l-.127-.097.005.004-.036-.027C7.067 6.599 7.644 7.587 7.795 8l-.027.033-.018-.013c.018 0 .025-.005.025-.005s-.672-.546-1.787-1.23c-1.118-.687-1.748-.849-1.88-.877l-.026-.006s.206.19.174.285c-.01.032-.168.022-.421.028a4 4 0 0 0-.725.07 4.1 4.1 0 0 0-1.567.63C.238 7.785 0 8.401 0 8.401s.55-.768 1.58-1.305c-.014.337-.047 1.97.445 4.12.53 2.32 1.53 4.487 1.614 4.665.004.178.016.272.016.272s.148-1.79.756-3.647c.175.283.758 1.117 2.075 2.096 1.628 1.21 2.37 1.536 2.4 1.548.001.157.005.24.005.24s.005-.1.018-.263a4.7 4.7 0 0 1 .552-.67 3.6 3.6 0 0 1 .54-.435q.048.166.093.276-.029-.145-.052-.282c.107.01.538.066 1.206.393.343.168.609.395.798.595l-.014.006s.123.112.269.403a2.4 2.4 0 0 0-.73.084 3 3 0 0 0-.098-.19.5.5 0 0 0-.039-.134c-.027-.061-.095-.1-.164-.14a.4.4 0 0 0-.104-.073.2.2 0 0 1-.055-.073c-.084-.184-.798.012-.942.18-.175.204-.209.464-.14.608.021.045.07.082.138.11.002.22.137.75.404 1.133a5 5 0 0 1-.108-.666c-.009-.16 0-.274.015-.35.047.328.174.684.577 1.124-.248-.54-.22-.861-.195-1.143l.01-.044.005-.001c.036.263.142.534.482.963l-.014-.028.014.021a1.63 1.63 0 0 1-.167-1.03l.008-.002q.07.044.134.126c.128.172.188.349.212.47a.53.53 0 0 0 .067.383 18 18 0 0 1-.72.501c-.23.15-.49.313-.757.47q-.21.121-.414.23l-.135-.077h.002l-.008-.004c-.97-.559-1.69-.932-2.518-1.082-.93-.166-1.786.283-1.982 1.082a1.28 1.28 0 0 0 .552 1.38l.012.008q.02.014.04.026l.06.036h.002a2.1 2.1 0 0 0 .69.237l.028.005h.006a4 4 0 0 0 .412.044c.975.047 2.156-.408 3.323-.982q.15.08.306.166c2.547 1.403 4.098 1.585 6.154.728-.502.151-1.208.356-2.094.344a.1.1 0 0 0-.02-.006v.006a6 6 0 0 1-.647-.05l-.03-.004v-.003l-.001.002a6.3 6.3 0 0 1-1.556-.436 8 8 0 0 1-.745-.362 57 57 0 0 1-1.006-.569c.348-.178.692-.363 1.026-.545.355-.189.672-.362.918-.5l.009-.004h.007s.083-.019.16-.043c.17-.052.41-.149.695-.283.028.117.095.215.195.253.235.091.407.027.522-.102l.018-.01.047-.037c.05-.03.107-.067.156-.09l.053-.022q.06-.016.116-.037l.033-.01c-.145.297-.091.581-.091.581.043-.37.22-.608.392-.715q.096-.041.2-.067c.064 0 .116.023.144.07.07.12.217.194.364.226.024.15-.045.404-.4.866l.09-.062.004-.003.072-.053q.213-.162.334-.305a1 1 0 0 0 .19-.305c.013.2-.042.507-.31 1.036 0 0 .317-.276.514-.63.006.191-.01.443-.063.785.345-.673.325-1.085.239-1.326l-.01-.036a.4.4 0 0 0-.01-.065l.042-.057c.118-.166-.048-.344-.154-.414-.06-.04-.2-.154-.454-.157-.225-.27-.51-.15-.958.145a1.3 1.3 0 0 1-.166.092 1 1 0 0 0-.055-.116q.241-.145.494-.308c.317-.207.553-.416.728-.615.51-.517.69-1.02 1.21-1.446h-.013l.06-.031c.854-.458 1.306-.547 1.338-.553l-.003.128.018-.125a1.8 1.8 0 0 1 .481.344 2.1 2.1 0 0 1 .362.487l.044.3s0-.116-.01-.33c.153-.151 1.02-1.043 1.724-2.466.694-1.404.944-2.523 1.017-2.924a18 18 0 0 1 .665 2.466s-.002-.133-.03-.374c.096-.336.515-1.872.626-3.756.1-1.68-.065-2.78-.14-3.173.648.536.995 1.306.995 1.306s-.04-.163-.188-.437l.02.027s-.236-.455-.644-.904a7 7 0 0 0-.157-.172c-.432-.46-.854-.617-1.17-.672a1.6 1.6 0 0 0-.308-.03h-.019c-.125-.003-.2.002-.207-.026-.02-.095.11-.285.11-.285s-.177.046-.554.33c-.23.167-.52.41-.853.76a14 14 0 0 0-.89.994l-.075.095-.023-.017c.076-.33.362-1.117 1.788-3.111zM11.92 14.09l.012.006zm-.263 2.606q.133.064.303.194h-.005a.5.5 0 0 0-.155.07 1 1 0 0 1-.126-.224zm-4.855 1.57q.198-.002.432.047l.02.005.017.004q.165.041.337.102l.057.021q.287.11.611.248c.32.14.62.277.838.375l.183.088c-.22.106-.424.196-.577.261-1.014.416-1.83.536-2.338.391-.944-.269-.76-1.536.42-1.542"/></svg>
  
  <span class="md-ellipsis">
    MLIR passes
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_4_5" id="__nav_4_5_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_5">
            <span class="md-nav__icon md-icon"></span>
            MLIR passes
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4_5_2" >
        
          
          <label class="md-nav__link" for="__nav_4_5_2" id="__nav_4_5_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Core dialects
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_4_5_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_5_2">
            <span class="md-nav__icon md-icon"></span>
            Core dialects
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference/mlir-passes/Flow/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Flow
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference/mlir-passes/HAL/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    HAL
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference/mlir-passes/Stream/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Stream
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference/mlir-passes/Util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Util
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference/mlir-passes/VM/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    VM
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4_5_3" >
        
          
          <label class="md-nav__link" for="__nav_4_5_3" id="__nav_4_5_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Pipelines
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_4_5_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_5_3">
            <span class="md-nav__icon md-icon"></span>
            Pipelines
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference/mlir-passes/ConstEval/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ConstEval
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference/mlir-passes/DispatchCreation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DispatchCreation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference/mlir-passes/GlobalOptimization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    GlobalOptimization
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference/mlir-passes/InputConversion/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    InputConversion
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference/mlir-passes/Preprocessing/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Preprocessing
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4_5_4" >
        
          
          <label class="md-nav__link" for="__nav_4_5_4" id="__nav_4_5_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Codegen
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_4_5_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_5_4">
            <span class="md-nav__icon md-icon"></span>
            Codegen
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference/mlir-passes/CodegenCommon/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Common
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference/mlir-passes/CodegenCommonCPU/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Common/CPU
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference/mlir-passes/CodegenCommonGPU/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Common/GPU
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference/mlir-passes/CodegenDialectGPU/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Dialect/GPU
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference/mlir-passes/CodegenDialectVectorExt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Dialect/VectorExt
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference/mlir-passes/CodegenLLVMCPU/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    LLVMCPU
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference/mlir-passes/CodegenLLVMGPU/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    LLVMGPU
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference/mlir-passes/CodegenSPIRV/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    SPIRV
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../reference/mlir-passes/CodegenVMVX/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    VMVX
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../developers/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Developers
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_5" id="__nav_5_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            Developers
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5_2" >
        
          
          <label class="md-nav__link" for="__nav_5_2" id="__nav_5_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    General development topics
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_2">
            <span class="md-nav__icon md-icon"></span>
            General development topics
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../developers/general/contributing/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M1.75 1h12.5c.966 0 1.75.784 1.75 1.75v8.5A1.75 1.75 0 0 1 14.25 13H8.061l-2.574 2.573A1.458 1.458 0 0 1 3 14.543V13H1.75A1.75 1.75 0 0 1 0 11.25v-8.5C0 1.784.784 1 1.75 1M1.5 2.75v8.5c0 .138.112.25.25.25h2a.75.75 0 0 1 .75.75v2.19l2.72-2.72a.75.75 0 0 1 .53-.22h6.5a.25.25 0 0 0 .25-.25v-8.5a.25.25 0 0 0-.25-.25H1.75a.25.25 0 0 0-.25.25m5.28 1.72a.75.75 0 0 1 0 1.06L5.31 7l1.47 1.47a.75.75 0 0 1-.018 1.042.75.75 0 0 1-1.042.018l-2-2a.75.75 0 0 1 0-1.06l2-2a.75.75 0 0 1 1.06 0m2.44 0a.75.75 0 0 1 1.06 0l2 2a.75.75 0 0 1 0 1.06l-2 2a.75.75 0 0 1-1.042-.018.75.75 0 0 1-.018-1.042L10.69 7 9.22 5.53a.75.75 0 0 1 0-1.06"/></svg>
  
  <span class="md-ellipsis">
    Contributing to IREE
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../developers/general/developer-overview/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M0 1.75A.75.75 0 0 1 .75 1h4.253c1.227 0 2.317.59 3 1.501A3.74 3.74 0 0 1 11.006 1h4.245a.75.75 0 0 1 .75.75v10.5a.75.75 0 0 1-.75.75h-4.507a2.25 2.25 0 0 0-1.591.659l-.622.621a.75.75 0 0 1-1.06 0l-.622-.621A2.25 2.25 0 0 0 5.258 13H.75a.75.75 0 0 1-.75-.75Zm7.251 10.324.004-5.073-.002-2.253A2.25 2.25 0 0 0 5.003 2.5H1.5v9h3.757a3.75 3.75 0 0 1 1.994.574M8.755 4.75l-.004 7.322a3.75 3.75 0 0 1 1.992-.572H14.5v-9h-3.495a2.25 2.25 0 0 0-2.25 2.25"/></svg>
  
  <span class="md-ellipsis">
    Developer overview
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../developers/general/developer-tips/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 6a6 6 0 0 1 6 6c0 2.22-1.21 4.16-3 5.2V19a1 1 0 0 1-1 1h-4a1 1 0 0 1-1-1v-1.8c-1.79-1.04-3-2.98-3-5.2a6 6 0 0 1 6-6m2 15v1a1 1 0 0 1-1 1h-2a1 1 0 0 1-1-1v-1zm6-10h3v2h-3zM1 11h3v2H1zM13 1v3h-2V1zM4.92 3.5l2.13 2.14-1.42 1.41L3.5 4.93zm12.03 2.13 2.12-2.13 1.43 1.43-2.13 2.12z"/></svg>
  
  <span class="md-ellipsis">
    Developer tips and tricks
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../developers/general/testing-guide/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="m11.28 3.22 4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.275-.326.75.75 0 0 1 .215-.734L13.94 8l-3.72-3.72a.749.749 0 0 1 .326-1.275.75.75 0 0 1 .734.215m-6.56 0a.75.75 0 0 1 1.042.018.75.75 0 0 1 .018 1.042L2.06 8l3.72 3.72a.749.749 0 0 1-.326 1.275.75.75 0 0 1-.734-.215L.47 8.53a.75.75 0 0 1 0-1.06Z"/></svg>
  
  <span class="md-ellipsis">
    Testing guide
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../developers/general/github-actions/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M0 8a8 8 0 1 1 16 0A8 8 0 0 1 0 8m1.5 0a6.5 6.5 0 1 0 13 0 6.5 6.5 0 0 0-13 0m10.28-1.72-4.5 4.5a.75.75 0 0 1-1.06 0l-2-2a.75.75 0 0 1 .018-1.042.75.75 0 0 1 1.042-.018l1.47 1.47 3.97-3.97a.75.75 0 0 1 1.042.018.75.75 0 0 1 .018 1.042"/></svg>
  
  <span class="md-ellipsis">
    GitHub Actions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../developers/general/release-management/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="m8.878.392 5.25 3.045c.54.314.872.89.872 1.514v6.098a1.75 1.75 0 0 1-.872 1.514l-5.25 3.045a1.75 1.75 0 0 1-1.756 0l-5.25-3.045A1.75 1.75 0 0 1 1 11.049V4.951c0-.624.332-1.201.872-1.514L7.122.392a1.75 1.75 0 0 1 1.756 0M7.875 1.69l-4.63 2.685L8 7.133l4.755-2.758-4.63-2.685a.25.25 0 0 0-.25 0M2.5 5.677v5.372c0 .09.047.171.125.216l4.625 2.683V8.432Zm6.25 8.271 4.625-2.683a.25.25 0 0 0 .125-.216V5.677L8.75 8.432Z"/></svg>
  
  <span class="md-ellipsis">
    Release management
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../developers/general/versioning-scheme/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M7.75 14A1.75 1.75 0 0 1 6 12.25v-8.5C6 2.784 6.784 2 7.75 2h6.5c.966 0 1.75.784 1.75 1.75v8.5A1.75 1.75 0 0 1 14.25 14Zm-.25-1.75c0 .138.112.25.25.25h6.5a.25.25 0 0 0 .25-.25v-8.5a.25.25 0 0 0-.25-.25h-6.5a.25.25 0 0 0-.25.25ZM4.9 3.508a.75.75 0 0 1-.274 1.025.25.25 0 0 0-.126.217v6.5c0 .09.048.173.126.217a.75.75 0 0 1-.752 1.298A1.75 1.75 0 0 1 3 11.25v-6.5c0-.649.353-1.214.874-1.516a.75.75 0 0 1 1.025.274ZM1.625 5.533za.25.25 0 0 0-.126.217v4.5c0 .09.048.173.126.217a.75.75 0 0 1-.752 1.298A1.75 1.75 0 0 1 0 10.25v-4.5a1.75 1.75 0 0 1 .873-1.516.75.75 0 1 1 .752 1.299"/></svg>
  
  <span class="md-ellipsis">
    Versioning scheme
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5_3" >
        
          
          <label class="md-nav__link" for="__nav_5_3" id="__nav_5_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Building
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_3">
            <span class="md-nav__icon md-icon"></span>
            Building
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../developers/building/bazel/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M15 2.75a.75.75 0 0 1-.75.75h-4a.75.75 0 0 1 0-1.5h4a.75.75 0 0 1 .75.75m-8.5.75v1.25a.75.75 0 0 0 1.5 0v-4a.75.75 0 0 0-1.5 0V2H1.75a.75.75 0 0 0 0 1.5zm1.25 5.25a.75.75 0 0 0 0-1.5h-6a.75.75 0 0 0 0 1.5zM15 8a.75.75 0 0 1-.75.75H11.5V10a.75.75 0 1 1-1.5 0V6a.75.75 0 0 1 1.5 0v1.25h2.75A.75.75 0 0 1 15 8m-9 5.25v-2a.75.75 0 0 0-1.5 0v1.25H1.75a.75.75 0 0 0 0 1.5H4.5v1.25a.75.75 0 0 0 1.5 0zm9 0a.75.75 0 0 1-.75.75h-6a.75.75 0 0 1 0-1.5h6a.75.75 0 0 1 .75.75"/></svg>
  
  <span class="md-ellipsis">
    Building with Bazel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../developers/building/emscripten/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M14.745 0v.129a2.752 2.752 0 1 1-5.504 0V0H0v24h24V0zm-3.291 21.431-1.169-5.783h-.02l-1.264 5.783H7.39l-1.824-8.497h1.59l1.088 5.783h.02l1.311-5.783h1.487l1.177 5.854h.02l1.242-5.854h1.561l-2.027 8.497zm8.755 0-.542-1.891h-2.861l-.417 1.891h-1.59l2.056-8.497h2.509l2.5 8.497zm-2.397-6.403-.694 3.118h2.159l-.796-3.118z"/></svg>
  
  <span class="md-ellipsis">
    Building with Emscripten
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../developers/building/cmake-options/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M11.769.066.067 23.206l12.76-10.843zm11.438 23.868L7.471 17.587 0 23.934zm.793-.198L12.298.463l1.719 19.24zM12.893 12.959l-5.025 4.298 5.62 2.248z"/></svg>
  
  <span class="md-ellipsis">
    CMake options
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../developers/building/cmake-with-ccache/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M11.769.066.067 23.206l12.76-10.843zm11.438 23.868L7.471 17.587 0 23.934zm.793-.198L12.298.463l1.719 19.24zM12.893 12.959l-5.025 4.298 5.62 2.248z"/></svg>
  
  <span class="md-ellipsis">
    CMake with ccache
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5_4" >
        
          
          <label class="md-nav__link" for="__nav_5_4" id="__nav_5_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Debugging
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_4">
            <span class="md-nav__icon md-icon"></span>
            Debugging
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../developers/debugging/android-with-lldb/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18.44 5.559q-1.015 1.748-2.028 3.498-.055-.023-.111-.043a12.098 12.098 0 0 0-8.68.033C7.537 8.897 5.868 6.026 5.6 5.56a1 1 0 0 0-.141-.19 1.104 1.104 0 0 0-1.768 1.298c1.947 3.37-.096-.216 1.948 3.36.017.03-.495.263-1.393 1.017C2.9 12.176.452 14.772 0 18.99h24a11.7 11.7 0 0 0-.746-3.068 12.1 12.1 0 0 0-2.74-4.184 12 12 0 0 0-2.131-1.687c.66-1.122 1.312-2.256 1.965-3.385a1.11 1.11 0 0 0-.008-1.12 1.1 1.1 0 0 0-.852-.532c-.522-.054-.939.313-1.049.545m-.04 8.46c.395.593.324 1.331-.156 1.65-.48.32-1.188.1-1.582-.493s-.324-1.33.156-1.65c.473-.316 1.182-.11 1.582.494m-11.193-.492c.48.32.55 1.058.156 1.65-.394.593-1.103.815-1.584.495-.48-.32-.55-1.058-.156-1.65.4-.603 1.109-.811 1.584-.495"/></svg>
  
  <span class="md-ellipsis">
    Android LLDB debugging
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../developers/debugging/compile-time-regressions/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M4.72.22a.75.75 0 0 1 1.06 0l1 .999a3.5 3.5 0 0 1 2.441 0l.999-1a.748.748 0 0 1 1.265.332.75.75 0 0 1-.205.729l-.775.776c.616.63.995 1.493.995 2.444v.327q0 .15-.025.292c.408.14.764.392 1.029.722l1.968-.787a.75.75 0 0 1 .556 1.392L13 7.258V9h2.25a.75.75 0 0 1 0 1.5H13v.5q-.002.615-.141 1.186l2.17.868a.75.75 0 0 1-.557 1.392l-2.184-.873A5 5 0 0 1 8 16a5 5 0 0 1-4.288-2.427l-2.183.873a.75.75 0 0 1-.558-1.392l2.17-.868A5 5 0 0 1 3 11v-.5H.75a.75.75 0 0 1 0-1.5H3V7.258L.971 6.446a.75.75 0 0 1 .558-1.392l1.967.787c.265-.33.62-.583 1.03-.722a1.7 1.7 0 0 1-.026-.292V4.5c0-.951.38-1.814.995-2.444L4.72 1.28a.75.75 0 0 1 0-1.06m.53 6.28a.75.75 0 0 0-.75.75V11a3.5 3.5 0 1 0 7 0V7.25a.75.75 0 0 0-.75-.75ZM6.173 5h3.654A.17.17 0 0 0 10 4.827V4.5a2 2 0 1 0-4 0v.327c0 .096.077.173.173.173"/></svg>
  
  <span class="md-ellipsis">
    Compile time regression debugging
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../developers/debugging/gpu/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M4.72.22a.75.75 0 0 1 1.06 0l1 .999a3.5 3.5 0 0 1 2.441 0l.999-1a.748.748 0 0 1 1.265.332.75.75 0 0 1-.205.729l-.775.776c.616.63.995 1.493.995 2.444v.327q0 .15-.025.292c.408.14.764.392 1.029.722l1.968-.787a.75.75 0 0 1 .556 1.392L13 7.258V9h2.25a.75.75 0 0 1 0 1.5H13v.5q-.002.615-.141 1.186l2.17.868a.75.75 0 0 1-.557 1.392l-2.184-.873A5 5 0 0 1 8 16a5 5 0 0 1-4.288-2.427l-2.183.873a.75.75 0 0 1-.558-1.392l2.17-.868A5 5 0 0 1 3 11v-.5H.75a.75.75 0 0 1 0-1.5H3V7.258L.971 6.446a.75.75 0 0 1 .558-1.392l1.967.787c.265-.33.62-.583 1.03-.722a1.7 1.7 0 0 1-.026-.292V4.5c0-.951.38-1.814.995-2.444L4.72 1.28a.75.75 0 0 1 0-1.06m.53 6.28a.75.75 0 0 0-.75.75V11a3.5 3.5 0 1 0 7 0V7.25a.75.75 0 0 0-.75-.75ZM6.173 5h3.654A.17.17 0 0 0 10 4.827V4.5a2 2 0 1 0-4 0v.327c0 .096.077.173.173.173"/></svg>
  
  <span class="md-ellipsis">
    GPU debugging playbook
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../developers/debugging/llvm/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M4.72.22a.75.75 0 0 1 1.06 0l1 .999a3.5 3.5 0 0 1 2.441 0l.999-1a.748.748 0 0 1 1.265.332.75.75 0 0 1-.205.729l-.775.776c.616.63.995 1.493.995 2.444v.327q0 .15-.025.292c.408.14.764.392 1.029.722l1.968-.787a.75.75 0 0 1 .556 1.392L13 7.258V9h2.25a.75.75 0 0 1 0 1.5H13v.5q-.002.615-.141 1.186l2.17.868a.75.75 0 0 1-.557 1.392l-2.184-.873A5 5 0 0 1 8 16a5 5 0 0 1-4.288-2.427l-2.183.873a.75.75 0 0 1-.558-1.392l2.17-.868A5 5 0 0 1 3 11v-.5H.75a.75.75 0 0 1 0-1.5H3V7.258L.971 6.446a.75.75 0 0 1 .558-1.392l1.967.787c.265-.33.62-.583 1.03-.722a1.7 1.7 0 0 1-.026-.292V4.5c0-.951.38-1.814.995-2.444L4.72 1.28a.75.75 0 0 1 0-1.06m.53 6.28a.75.75 0 0 0-.75.75V11a3.5 3.5 0 1 0 7 0V7.25a.75.75 0 0 0-.75-.75ZM6.173 5h3.654A.17.17 0 0 0 10 4.827V4.5a2 2 0 1 0-4 0v.327c0 .096.077.173.173.173"/></svg>
  
  <span class="md-ellipsis">
    LLVM debugging playbook
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../developers/debugging/integration-tests/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M4.72.22a.75.75 0 0 1 1.06 0l1 .999a3.5 3.5 0 0 1 2.441 0l.999-1a.748.748 0 0 1 1.265.332.75.75 0 0 1-.205.729l-.775.776c.616.63.995 1.493.995 2.444v.327q0 .15-.025.292c.408.14.764.392 1.029.722l1.968-.787a.75.75 0 0 1 .556 1.392L13 7.258V9h2.25a.75.75 0 0 1 0 1.5H13v.5q-.002.615-.141 1.186l2.17.868a.75.75 0 0 1-.557 1.392l-2.184-.873A5 5 0 0 1 8 16a5 5 0 0 1-4.288-2.427l-2.183.873a.75.75 0 0 1-.558-1.392l2.17-.868A5 5 0 0 1 3 11v-.5H.75a.75.75 0 0 1 0-1.5H3V7.258L.971 6.446a.75.75 0 0 1 .558-1.392l1.967.787c.265-.33.62-.583 1.03-.722a1.7 1.7 0 0 1-.026-.292V4.5c0-.951.38-1.814.995-2.444L4.72 1.28a.75.75 0 0 1 0-1.06m.53 6.28a.75.75 0 0 0-.75.75V11a3.5 3.5 0 1 0 7 0V7.25a.75.75 0 0 0-.75-.75ZM6.173 5h3.654A.17.17 0 0 0 10 4.827V4.5a2 2 0 1 0-4 0v.327c0 .096.077.173.173.173"/></svg>
  
  <span class="md-ellipsis">
    Integration test debugging
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../developers/debugging/model-development/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M4.72.22a.75.75 0 0 1 1.06 0l1 .999a3.5 3.5 0 0 1 2.441 0l.999-1a.748.748 0 0 1 1.265.332.75.75 0 0 1-.205.729l-.775.776c.616.63.995 1.493.995 2.444v.327q0 .15-.025.292c.408.14.764.392 1.029.722l1.968-.787a.75.75 0 0 1 .556 1.392L13 7.258V9h2.25a.75.75 0 0 1 0 1.5H13v.5q-.002.615-.141 1.186l2.17.868a.75.75 0 0 1-.557 1.392l-2.184-.873A5 5 0 0 1 8 16a5 5 0 0 1-4.288-2.427l-2.183.873a.75.75 0 0 1-.558-1.392l2.17-.868A5 5 0 0 1 3 11v-.5H.75a.75.75 0 0 1 0-1.5H3V7.258L.971 6.446a.75.75 0 0 1 .558-1.392l1.967.787c.265-.33.62-.583 1.03-.722a1.7 1.7 0 0 1-.026-.292V4.5c0-.951.38-1.814.995-2.444L4.72 1.28a.75.75 0 0 1 0-1.06m.53 6.28a.75.75 0 0 0-.75.75V11a3.5 3.5 0 1 0 7 0V7.25a.75.75 0 0 0-.75-.75ZM6.173 5h3.654A.17.17 0 0 0 10 4.827V4.5a2 2 0 1 0-4 0v.327c0 .096.077.173.173.173"/></svg>
  
  <span class="md-ellipsis">
    Model development debugging
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../developers/debugging/releases/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="m8.878.392 5.25 3.045c.54.314.872.89.872 1.514v6.098a1.75 1.75 0 0 1-.872 1.514l-5.25 3.045a1.75 1.75 0 0 1-1.756 0l-5.25-3.045A1.75 1.75 0 0 1 1 11.049V4.951c0-.624.332-1.201.872-1.514L7.122.392a1.75 1.75 0 0 1 1.756 0M7.875 1.69l-4.63 2.685L8 7.133l4.755-2.758-4.63-2.685a.25.25 0 0 0-.25 0M2.5 5.677v5.372c0 .09.047.171.125.216l4.625 2.683V8.432Zm6.25 8.271 4.625-2.683a.25.25 0 0 0 .125-.216V5.677L8.75 8.432Z"/></svg>
  
  <span class="md-ellipsis">
    Release debugging playbook
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../developers/debugging/sanitizers/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m19.36 2.72 1.42 1.42-5.72 5.71c1.07 1.54 1.22 3.39.32 4.59L9.06 8.12c1.2-.9 3.05-.75 4.59.32zM5.93 17.57c-2.01-2.01-3.24-4.41-3.58-6.65l4.88-2.09 7.44 7.44-2.09 4.88c-2.24-.34-4.64-1.57-6.65-3.58"/></svg>
  
  <span class="md-ellipsis">
    Sanitizers (ASan/MSan/TSan)
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5_5" >
        
          
          <label class="md-nav__link" for="__nav_5_5" id="__nav_5_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Performance
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_5">
            <span class="md-nav__icon md-icon"></span>
            Performance
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../developers/performance/benchmarking/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m11.628 16.186-2.047-2.14 6.791-5.953 1.21 1.302zm8.837 6.047c2.14-2.14 3.535-5.117 3.535-8.466 0-6.604-5.395-12-12-12s-12 5.396-12 12c0 3.35 1.302 6.326 3.535 8.466l1.674-1.675c-1.767-1.767-2.79-4.093-2.79-6.79A9.57 9.57 0 0 1 12 4.185a9.57 9.57 0 0 1 9.581 9.581c0 2.605-1.116 5.024-2.79 6.791Z"/></svg>
  
  <span class="md-ellipsis">
    Benchmarking
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../developers/performance/profiling/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m16 11.78 4.24-7.33 1.73 1-5.23 9.05-6.51-3.75L5.46 19H22v2H2V3h2v14.54L9.5 8z"/></svg>
  
  <span class="md-ellipsis">
    Profiling overview
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../developers/performance/profiling-cpu-events/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m16 11.78 4.24-7.33 1.73 1-5.23 9.05-6.51-3.75L5.46 19H22v2H2V3h2v14.54L9.5 8z"/></svg>
  
  <span class="md-ellipsis">
    Profiling CPUs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../developers/performance/profiling-gpu-vulkan/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m16 11.78 4.24-7.33 1.73 1-5.23 9.05-6.51-3.75L5.46 19H22v2H2V3h2v14.54L9.5 8z"/></svg>
  
  <span class="md-ellipsis">
    Profiling GPUs using Vulkan
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../developers/performance/profiling-with-tracy/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m16 11.78 4.24-7.33 1.73 1-5.23 9.05-6.51-3.75L5.46 19H22v2H2V3h2v14.54L9.5 8z"/></svg>
  
  <span class="md-ellipsis">
    Profiling with Tracy
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5_6" >
        
          
          <label class="md-nav__link" for="__nav_5_6" id="__nav_5_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Design docs
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_6">
            <span class="md-nav__icon md-icon"></span>
            Design docs
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../developers/design-docs/design-roadmap/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Design roadmap
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../developers/design-docs/function-abi/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Function ABI
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../developers/design-docs/invocation-execution-model/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Invocation execution model
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../developers/design-docs/cuda-hal-driver/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    CUDA HAL driver
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../developers/design-docs/hip-hal-driver/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    HIP HAL driver
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../developers/design-docs/metal-hal-driver/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Metal HAL driver
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../developers/design-docs/vm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Virtual machine (VM)
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5_7" >
        
          
          <label class="md-nav__link" for="__nav_5_7" id="__nav_5_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Other topics
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_7">
            <span class="md-nav__icon md-icon"></span>
            Other topics
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../developers/usage-best-practices/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 6a6 6 0 0 1 6 6c0 2.22-1.21 4.16-3 5.2V19a1 1 0 0 1-1 1h-4a1 1 0 0 1-1-1v-1.8c-1.79-1.04-3-2.98-3-5.2a6 6 0 0 1 6-6m2 15v1a1 1 0 0 1-1 1h-2a1 1 0 0 1-1-1v-1zm6-10h3v2h-3zM1 11h3v2H1zM13 1v3h-2V1zM4.92 3.5l2.13 2.14-1.42 1.41L3.5 4.93zm12.03 2.13 2.12-2.13 1.43 1.43-2.13 2.12z"/></svg>
  
  <span class="md-ellipsis">
    Usage best practices
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../developers/update-sdxl-golden-outputs/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 6a6 6 0 0 1 6 6c0 2.22-1.21 4.16-3 5.2V19a1 1 0 0 1-1 1h-4a1 1 0 0 1-1-1v-1.8c-1.79-1.04-3-2.98-3-5.2a6 6 0 0 1 6-6m2 15v1a1 1 0 0 1-1 1h-2a1 1 0 0 1-1-1v-1zm6-10h3v2h-3zM1 11h3v2H1zM13 1v3h-2V1zM4.92 3.5l2.13 2.14-1.42 1.41L3.5 4.93zm12.03 2.13 2.12-2.13 1.43 1.43-2.13 2.12z"/></svg>
  
  <span class="md-ellipsis">
    Updating SDXL Golden Outputs for IREE CI
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../developers/vulkan-environment-setup/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M1.75 1h12.5c.966 0 1.75.784 1.75 1.75v4c0 .372-.116.717-.314 1 .198.283.314.628.314 1v4a1.75 1.75 0 0 1-1.75 1.75H1.75A1.75 1.75 0 0 1 0 12.75v-4c0-.358.109-.707.314-1a1.74 1.74 0 0 1-.314-1v-4C0 1.784.784 1 1.75 1M1.5 2.75v4c0 .138.112.25.25.25h12.5a.25.25 0 0 0 .25-.25v-4a.25.25 0 0 0-.25-.25H1.75a.25.25 0 0 0-.25.25m.25 5.75a.25.25 0 0 0-.25.25v4c0 .138.112.25.25.25h12.5a.25.25 0 0 0 .25-.25v-4a.25.25 0 0 0-.25-.25ZM7 4.75A.75.75 0 0 1 7.75 4h4.5a.75.75 0 0 1 0 1.5h-4.5A.75.75 0 0 1 7 4.75M7.75 10h4.5a.75.75 0 0 1 0 1.5h-4.5a.75.75 0 0 1 0-1.5M3 4.75A.75.75 0 0 1 3.75 4h.5a.75.75 0 0 1 0 1.5h-.5A.75.75 0 0 1 3 4.75M3.75 10h.5a.75.75 0 0 1 0 1.5h-.5a.75.75 0 0 1 0-1.5"/></svg>
  
  <span class="md-ellipsis">
    Vulkan environment setup
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Community
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_6" id="__nav_6_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            Community
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6_2" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../" class="md-nav__link ">
              
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M0 1.75A.75.75 0 0 1 .75 1h4.253c1.227 0 2.317.59 3 1.501A3.74 3.74 0 0 1 11.006 1h4.245a.75.75 0 0 1 .75.75v10.5a.75.75 0 0 1-.75.75h-4.507a2.25 2.25 0 0 0-1.591.659l-.622.621a.75.75 0 0 1-1.06 0l-.622-.621A2.25 2.25 0 0 0 5.258 13H.75a.75.75 0 0 1-.75-.75Zm7.251 10.324.004-5.073-.002-2.253A2.25 2.25 0 0 0 5.003 2.5H1.5v9h3.757a3.75 3.75 0 0 1 1.994.574M8.755 4.75l-.004 7.322a3.75 3.75 0 0 1 1.992-.572H14.5v-9h-3.495a2.25 2.25 0 0 0-2.25 2.25"/></svg>
  
  <span class="md-ellipsis">
    Blog
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_6_2" id="__nav_6_2_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_6_2">
            <span class="md-nav__icon md-icon"></span>
            Blog
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_6_2_2" >
        
          
          <label class="md-nav__link" for="__nav_6_2_2" id="__nav_6_2_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Archive
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_6_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_2_2">
            <span class="md-nav__icon md-icon"></span>
            Archive
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../archive/2025/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2025
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../archive/2024/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2024
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../archive/2021/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2021
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_6_2_3" >
        
          
          <label class="md-nav__link" for="__nav_6_2_3" id="__nav_6_2_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Categories
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_6_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_2_3">
            <span class="md-nav__icon md-icon"></span>
            Categories
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../category/frontends/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Frontends
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../category/performance/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Performance
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../category/platforms/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Platforms
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tags/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M1 7.775V2.75C1 1.784 1.784 1 2.75 1h5.025c.464 0 .91.184 1.238.513l6.25 6.25a1.75 1.75 0 0 1 0 2.474l-5.026 5.026a1.75 1.75 0 0 1-2.474 0l-6.25-6.25A1.75 1.75 0 0 1 1 7.775m1.5 0c0 .066.026.13.073.177l6.25 6.25a.25.25 0 0 0 .354 0l5.025-5.025a.25.25 0 0 0 0-.354l-6.25-6.25a.25.25 0 0 0-.177-.073H2.75a.25.25 0 0 0-.25.25ZM6 5a1 1 0 1 1 0 2 1 1 0 0 1 0-2"/></svg>
  
  <span class="md-ellipsis">
    Tags
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
                
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#prior-reading" class="md-nav__link">
    <span class="md-ellipsis">
      Prior Reading
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#setup" class="md-nav__link">
    <span class="md-ellipsis">
      Setup
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#target-independent-optimizations" class="md-nav__link">
    <span class="md-ellipsis">
      Target-Independent Optimizations
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Target-Independent Optimizations">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#introduction-of-encoding-dialect" class="md-nav__link">
    <span class="md-ellipsis">
      Introduction of Encoding Dialect
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#annotatedatatilinghintspass-dispatchcreation" class="md-nav__link">
    <span class="md-ellipsis">
      AnnotateDataTilingHintsPass (DispatchCreation)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#setencodingpass-dispatchcreation" class="md-nav__link">
    <span class="md-ellipsis">
      SetEncodingPass (DispatchCreation)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hoistencodingopspass-dispatchcreation" class="md-nav__link">
    <span class="md-ellipsis">
      HoistEncodingOpsPass (DispatchCreation)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#propagateencodingspass-dispatchcreation" class="md-nav__link">
    <span class="md-ellipsis">
      PropagateEncodingsPass (DispatchCreation)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#fuseencodingopsintodispatchregionspass-dispatchcreation" class="md-nav__link">
    <span class="md-ellipsis">
      FuseEncodingOpsIntoDispatchRegionsPass (DispatchCreation)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#convertencodingtoflowpass-dispatchcreation" class="md-nav__link">
    <span class="md-ellipsis">
      ConvertEncodingToFlowPass (DispatchCreation)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hoistintoglobalspass-dispatchcreation" class="md-nav__link">
    <span class="md-ellipsis">
      HoistIntoGlobalsPass (DispatchCreation)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#converttostreampass" class="md-nav__link">
    <span class="md-ellipsis">
      ConvertToStreamPass
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#specializeencodingspass-stream" class="md-nav__link">
    <span class="md-ellipsis">
      SpecializeEncodingsPass (Stream)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#encodehosttensorspass-stream" class="md-nav__link">
    <span class="md-ellipsis">
      EncodeHostTensorsPass (Stream)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#materializeencodingspass-stream" class="md-nav__link">
    <span class="md-ellipsis">
      MaterializeEncodingsPass (Stream)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#code-generation-target-dependent" class="md-nav__link">
    <span class="md-ellipsis">
      Code Generation (Target-Dependent)
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Code Generation (Target-Dependent)">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#materializedeviceencodingpass" class="md-nav__link">
    <span class="md-ellipsis">
      MaterializeDeviceEncodingPass
    </span>
  </a>
  
    <nav class="md-nav" aria-label="MaterializeDeviceEncodingPass">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#ir-dump" class="md-nav__link">
    <span class="md-ellipsis">
      IR Dump
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#challenge-code-generation-for-index-remapping" class="md-nav__link">
    <span class="md-ellipsis">
      Challenge: Code Generation for Index Remapping
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#bufferizedispatchtensorloadstorepass" class="md-nav__link">
    <span class="md-ellipsis">
      BufferizeDispatchTensorLoadStorePass
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gpucombinelayouttransformationpass" class="md-nav__link">
    <span class="md-ellipsis">
      GPUCombineLayoutTransformationPass
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#build-your-own-encoding-attributes-and-resolver" class="md-nav__link">
    <span class="md-ellipsis">
      Build Your Own Encoding Attributes and Resolver
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
  <div class="md-content md-content--post" data-md-component="content">
    <div class="md-sidebar md-sidebar--post" data-md-component="sidebar" data-md-type="navigation">
      <div class="md-sidebar__scrollwrap">
        <div class="md-sidebar__inner md-post">
          <nav class="md-nav md-nav--primary">
            <div class="md-post__back">
              <div class="md-nav__title md-nav__container">
                <a href="../" class="md-nav__link">
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
                  <span class="md-ellipsis">
                    Back to index
                  </span>
                </a>
              </div>
            </div>
            
              <div class="md-post__authors md-typeset">
                
                  <div class="md-profile md-post__profile">
                    <span class="md-author md-author--long">
                      <img src="https://github.com/hanhanW.png" alt="Han-Chung Wang">
                    </span>
                    <span class="md-profile__description">
                      <strong>
                        
                          <a href="https://github.com/hanhanW">Han-Chung Wang</a>
                        
                      </strong>
                      <br>
                      Software Engineer
                    </span>
                  </div>
                
              </div>
            
            <ul class="md-post__meta md-nav__list">
              <li class="md-nav__item md-nav__item--section">
                <div class="md-post__title">
                  <span class="md-ellipsis">
                    Metadata
                  </span>
                </div>
                <nav class="md-nav">
                  <ul class="md-nav__list">
                    <li class="md-nav__item">
                      <div class="md-nav__link">
                        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 19H5V8h14m-3-7v2H8V1H6v2H5c-1.11 0-2 .89-2 2v14a2 2 0 0 0 2 2h14a2 2 0 0 0 2-2V5a2 2 0 0 0-2-2h-1V1m-1 11h-5v5h5z"/></svg>
                        <time datetime="2025-08-25 00:00:00+00:00" class="md-ellipsis">August 25, 2025</time>
                      </div>
                    </li>
                    
                    
                      <li class="md-nav__item">
                        <div class="md-nav__link">
                          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9 3v15h3V3zm3 2 4 13 3-1-4-13zM5 5v13h3V5zM3 19v2h18v-2z"/></svg>
                          <span class="md-ellipsis">
                            in
                            
                              <a href="../category/performance/">Performance</a></span>
                        </div>
                      </li>
                    
                    
                      
                      <li class="md-nav__item">
                        <div class="md-nav__link">
                          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 20a8 8 0 0 0 8-8 8 8 0 0 0-8-8 8 8 0 0 0-8 8 8 8 0 0 0 8 8m0-18a10 10 0 0 1 10 10 10 10 0 0 1-10 10C6.47 22 2 17.5 2 12A10 10 0 0 1 12 2m.5 5v5.25l4.5 2.67-.75 1.23L11 13V7z"/></svg>
                          <span class="md-ellipsis">
                            
                              30 min read
                            
                          </span>
                        </div>
                      </li>
                    
                  </ul>
                </nav>
              </li>
            </ul>
          </nav>
          
        </div>
      </div>
    </div>
    <article class="md-content__inner md-typeset">
      
        
  
  

<nav class="md-tags" >
  
    
    
    
      <a href="../../tags/#data-tiling" class="md-tag">Data-Tiling</a>
    
  
    
    
    
      <a href="../../tags/#gpu" class="md-tag">GPU</a>
    
  
</nav>


  
    <a href="https://github.com/iree-org/iree/blob/main/docs/website/docs/community/blog/posts/data-tiling-walkthrough.md" title="Edit this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg>
    </a>
  
  


<h1 id="data-tiling-walkthrough">Data-Tiling Walkthrough<a class="headerlink" href="#data-tiling-walkthrough" title="Permanent link">link</a></h1>
<p>Data-tiling is the modification of data layout of operands of certain
operations, such as matrix multiplication, that prefer specific layouts. These
layout preferences depend on the operations and the target hardware. For
example, matrix multiplications may need to use hardware matrix multiplication
instructions that perform optimally with a specific matrix data layout.</p>
<p>Layout changes may also be motivated by memory access performance, as
data-tiling can result in improved locality of memory accesses, fewer cache
lines being accessed, and generally simpler memory access patterns that are more
likely to be handled performantly by the memory system.</p>
<p>These layout changes can be propagated as far as possible across the workload,
so the entire workload can use the updated layouts, as opposed to having to
perform layout transformations at runtime. This may involve fusions or
constant-evaluation that can amortize or remove layout-transformation overheads.</p>
<p>The main conceptual difficulty in modeling this in tensor-level MLIR is that
tensors don't have layouts: tensors are higher-level, abstract arrays. This is
addressed by the concept of tensor encodings, which this document will explain.</p>
<!-- more -->

<h2 id="prior-reading">Prior Reading<a class="headerlink" href="#prior-reading" title="Permanent link">link</a></h2>
<p>Introducing layout transformations is not hard in itself. What is hard is making
that fit in the progressive-lowerings design of a retargetable compiler. The
solution we have in IREE is using tensor encodings, which represents virtual
layout. The below talk walks through how IREE uses the Encoding dialect in
host/device programming model. [<a href="https://llvm.org/devmtg/2025-06/slides/technical-talk/wang-data-tilling.pdf">Link to the slides</a>]</p>
<p>Recording:
<a href="https://www.youtube.com/watch?v=iANJWUL_SOo">Data-Tiling in IREE: Achieving High Performance Through Compiler Design (AsiaLLVM)</a></p>
<h2 id="setup">Setup<a class="headerlink" href="#setup" title="Permanent link">link</a></h2>
<p>Compilation command, that targets gfx942 AMDGPU:</p>
<div class="highlight"><pre><span></span><code>iree-compile<span class="w"> </span>matmul.mlir<span class="w"> </span>-o<span class="w"> </span>/tmp/matmul.mlir<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--iree-hal-target-device<span class="o">=</span>hip<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--iree-hip-target<span class="o">=</span>gfx942<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--iree-dispatch-creation-data-tiling
</code></pre></div>
<p>Test source program, matmul.mlir:</p>
<div class="highlight"><pre><span></span><code>func.func @matmul_f32f32f32(%arg0: tensor&lt;?x?xf32&gt;, %arg1: tensor&lt;?x?xf32&gt;) -&gt; tensor&lt;?x?xf32&gt; {
  %c0 = arith.constant 0 : index
  %c1 = arith.constant 1 : index
  %dim = tensor.dim %arg0, %c0 : tensor&lt;?x?xf32&gt;
  %dim_0 = tensor.dim %arg1, %c1 : tensor&lt;?x?xf32&gt;
  %cst = arith.constant 0.000000e+00 : f32
  %0 = tensor.empty(%dim, %dim_0) : tensor&lt;?x?xf32&gt;
  %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor&lt;?x?xf32&gt;) -&gt; tensor&lt;?x?xf32&gt;
  %2 = linalg.matmul
    ins(%arg0, %arg1 : tensor&lt;?x?xf32&gt;, tensor&lt;?x?xf32&gt;)
    outs(%1 : tensor&lt;?x?xf32&gt;) -&gt; tensor&lt;?x?xf32&gt;
  return %2 : tensor&lt;?x?xf32&gt;
}
</code></pre></div>
<!-- markdownlint-disable -->
<details><summary>Compilation command that targets host CPU</summary>

Below is the compilation command that targets your host CPU. The IR dumps are
different from what the post shows, but they follow the same mechanism.

<div class="highlight"><pre><span></span><code>iree-compile<span class="w"> </span>matmul.mlir<span class="w"> </span>-o<span class="w"> </span>/tmp/matmul.mlir<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--iree-hal-target-device<span class="o">=</span><span class="nb">local</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--iree-hal-local-target-device-backends<span class="o">=</span>llvm-cpu<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--iree-llvmcpu-target-cpu-features<span class="o">=</span>host<span class="w"> </span><span class="se">\</span>
<span class="w">  </span>--iree-dispatch-creation-data-tiling
</code></pre></div>

</details>
<!-- markdownlint-restore -->

<h2 id="target-independent-optimizations">Target-Independent Optimizations<a class="headerlink" href="#target-independent-optimizations" title="Permanent link">link</a></h2>
<p>Data-tiling can start from either GlobalOptimization phase or DispatchCreation
phase. The former one is the current default, and the latter one is mainly
designed for data-tiling fusion. In this post, we focus on the data-tiling
fusion path, thus it happens in DispatchCreation phase.</p>
<p><img alt="overview" src="../data-tiling-walkthrough_overview.png" /></p>
<h3 id="introduction-of-encoding-dialect">Introduction of Encoding Dialect<a class="headerlink" href="#introduction-of-encoding-dialect" title="Permanent link">link</a></h3>
<p>The encoding dialect defines IREE tensor encoding attributes and related
ops. These encoding hints enable optimization of compute-heavy operations
like matmul. E.g., IREE implements data-tiling using the encoding dialect,
by introducing encodings on matmul ops and fuse encoding ops with producers.</p>
<p>There are two core operations in this dialect, and they are very simple:</p>
<ul>
<li>SetEncodingOp: Adds an encoding attribute to a tensor value.</li>
<li>UnsetEncodingOp: Removes the encoding attribute from a tensor value.</li>
</ul>
<p>Encoding attributes fall into two categories:</p>
<ul>
<li>Encoding type attribute: An encoding type attribute is expected to be attached
  on tensor types.</li>
<li>Encoding resolver: An attribute that transforms encoding type attribute
  between the states.</li>
</ul>
<p>An encoding type attribute typically goes through three states in the lowering.</p>
<div class="highlight"><pre><span></span><code>+------------------+    +---------------------+    +--------------------+
| Verbose Encoding | -&gt; | Serialized Encoding | -&gt; | Physical Ops/Types |
+------------------+    +---------------------+    +--------------------+
</code></pre></div>
<p>Encoding resolvers are responsible for transforming the encodings between
states. Each backend can define its own resolver to interpret encodings
based on target-specific details.</p>
<p>To support encoding transformations better, IREE defines three encoding
interfaces:</p>
<ul>
<li><a href="https://github.com/iree-org/iree/blob/e6fb1e180438c4f78a1ea2bafd9a653fbe7a064b/compiler/src/iree/compiler/Dialect/Encoding/IR/EncodingInterfaces.td#L17-L74">LayoutResolverAttr</a>:
  Converts verbose encodings into serialized ones, based on target-specific
  information.</li>
<li><a href="https://github.com/iree-org/iree/blob/e6fb1e180438c4f78a1ea2bafd9a653fbe7a064b/compiler/src/iree/compiler/Dialect/Encoding/IR/EncodingInterfaces.td#L76-L206">SerializableAttr</a>:
  Represents serialized encoding formats with enough detail for host-side
  compilation.</li>
<li><a href="https://github.com/iree-org/iree/blob/e6fb1e180438c4f78a1ea2bafd9a653fbe7a064b/compiler/src/iree/compiler/Dialect/Encoding/IR/EncodingInterfaces.td#L208-L281">LayoutMaterializerAttr</a>:
  Lowers encodings into physical operations and types.</li>
</ul>
<p>An encoding resolver must implement <code>LayoutResolverAttr</code>, as it needs to
convert verbose encodings into serialized encodings with target specifics.</p>
<p>Sometimes, an encoding resolver also implements <code>SerializableAttr</code> because
the layout can be customized format, e.g., packing, etc. Only the resolver
itself knows how to interpret the layout.</p>
<p>An encoding resolver must implement <code>LayoutMaterializerAttr</code>, because only the
resolver itself knows what the final operations and types are.</p>
<h3 id="annotatedatatilinghintspass-dispatchcreation">AnnotateDataTilingHintsPass (DispatchCreation)<a class="headerlink" href="#annotatedatatilinghintspass-dispatchcreation" title="Permanent link">link</a></h3>
<p>Data-tiling is an optional technique. It is hard to enable data-tiling for all
the matmuls unconditionally, especially if an user wants to apply different
strategies on specific matmuls.</p>
<p>A design idea of the pass is providing a mechanism to users that can selectively
enable data-tiling for matmuls. There are two modes:</p>
<ul>
<li>Attach the data-tiling hint attribute to all the matmuls, if the hint does not
  exist in any operation.</li>
<li>Skip the pass, if any operation already has the data-tiling hint attribute.</li>
</ul>
<p>It allows users to set the attribute in preprocessing phase or the model.</p>
<!-- markdownlint-disable -->
<details><summary>IR dump before the pass</summary>

<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span></pre></div></td><td class="code"><div><pre><span></span><code>util.func public @matmul_f32f32f32(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -&gt; !hal.buffer_view {
  %0 = hal.buffer_view.dim&lt;%arg0 : !hal.buffer_view&gt;[0] : index
  %1 = hal.buffer_view.dim&lt;%arg0 : !hal.buffer_view&gt;[1] : index
  %2 = hal.tensor.import %arg0 &quot;input0&quot; : !hal.buffer_view -&gt; tensor&lt;?x?xf32&gt;{%0, %1}
  %3 = hal.buffer_view.dim&lt;%arg1 : !hal.buffer_view&gt;[0] : index
  %4 = hal.buffer_view.dim&lt;%arg1 : !hal.buffer_view&gt;[1] : index
  %5 = hal.tensor.import %arg1 &quot;input1&quot; : !hal.buffer_view -&gt; tensor&lt;?x?xf32&gt;{%3, %4}
  %6 = flow.dispatch.region -&gt; (tensor&lt;?x?xf32&gt;{%0, %4}) {
    %8 = tensor.empty(%0, %4) : tensor&lt;?x?xf32&gt;
    %cst = arith.constant 0.000000e+00 : f32
    %9 = linalg.fill ins(%cst : f32) outs(%8 : tensor&lt;?x?xf32&gt;) -&gt; tensor&lt;?x?xf32&gt;
<span class="hll">    %10 = linalg.matmul
</span><span class="hll">      ins(%2, %5 : tensor&lt;?x?xf32&gt;, tensor&lt;?x?xf32&gt;)
</span><span class="hll">      outs(%9 : tensor&lt;?x?xf32&gt;) -&gt; tensor&lt;?x?xf32&gt;
</span>    flow.return %10 : tensor&lt;?x?xf32&gt;
  }
  %7 = hal.tensor.export %6 &quot;output0&quot; : tensor&lt;?x?xf32&gt;{%0, %4} -&gt; !hal.buffer_view
  util.return %7 : !hal.buffer_view
}
</code></pre></div></td></tr></table></div>

</details>

<details><summary>IR dump after the pass</summary>

<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span></pre></div></td><td class="code"><div><pre><span></span><code>util.func public @matmul_f32f32f32(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -&gt; !hal.buffer_view {
  %0 = hal.buffer_view.dim&lt;%arg0 : !hal.buffer_view&gt;[0] : index
  %1 = hal.buffer_view.dim&lt;%arg0 : !hal.buffer_view&gt;[1] : index
  %2 = hal.tensor.import %arg0 &quot;input0&quot; : !hal.buffer_view -&gt; tensor&lt;?x?xf32&gt;{%0, %1}
  %3 = hal.buffer_view.dim&lt;%arg1 : !hal.buffer_view&gt;[0] : index
  %4 = hal.buffer_view.dim&lt;%arg1 : !hal.buffer_view&gt;[1] : index
  %5 = hal.tensor.import %arg1 &quot;input1&quot; : !hal.buffer_view -&gt; tensor&lt;?x?xf32&gt;{%3, %4}
  %6 = flow.dispatch.region -&gt; (tensor&lt;?x?xf32&gt;{%0, %4}) {
    %8 = tensor.empty(%0, %4) : tensor&lt;?x?xf32&gt;
    %cst = arith.constant 0.000000e+00 : f32
    %9 = linalg.fill ins(%cst : f32) outs(%8 : tensor&lt;?x?xf32&gt;) -&gt; tensor&lt;?x?xf32&gt;
<span class="hll">    %10 = linalg.matmul {iree.opt.data_tiling}
</span><span class="hll">      ins(%2, %5 : tensor&lt;?x?xf32&gt;, tensor&lt;?x?xf32&gt;)
</span><span class="hll">      outs(%9 : tensor&lt;?x?xf32&gt;) -&gt; tensor&lt;?x?xf32&gt;
</span>    flow.return %10 : tensor&lt;?x?xf32&gt;
  }
  %7 = hal.tensor.export %6 &quot;output0&quot; : tensor&lt;?x?xf32&gt;{%0, %4} -&gt; !hal.buffer_view
  util.return %7 : !hal.buffer_view
}
</code></pre></div></td></tr></table></div>

</details>
<!-- markdownlint-restore -->

<h3 id="setencodingpass-dispatchcreation">SetEncodingPass (DispatchCreation)<a class="headerlink" href="#setencodingpass-dispatchcreation" title="Permanent link">link</a></h3>
<p>The pass sets the encodings on matmul operands, and it propagates the encodings
through the <code>linalg.fill</code> op. You can encode whatever static information in the
encodings, as long as they provide values to backend that helps code-generation
decision.</p>
<p>The trade-off is that verbose encodings are harder to lower, especially for host
compilation. E.g., the compiler is not able to CSE the return values from a
dispatch region, if they have different encodings but result in identical
results in the later lowering. I.e., it can result in additional memory
footprint, that IREE definitely wants to avoid as many as possible. It also
makes encoding propagation harder, as the compiler needs to track all the
information in relevant fields.</p>
<p>What is encoded in IREE are:</p>
<ul>
<li>Operation type. E.g., <code>matmul</code>.</li>
<li>Operand index. E.g., <code>lhs</code>, <code>rhs</code>, etc.</li>
<li>Element type of each operand. E.g., <code>[f32, f32, f32]</code>.</li>
<li>Indexing map of each operand.</li>
<li>Iteration sizes.</li>
</ul>
<p>The <code>iteration_sizes</code> field can be optional in terms of functionality. They are
useful for skinny matmul like matvec, vecmat, etc.</p>
<p>Note: it looks dumb in the IR dump, because it does not provide any information
to the local dispatch. However, it is very useful in the later lowering because
IREE can fuse <code>iree_encoding.set_encoding</code> ops with producers that provide the
information across dispatches.</p>
<!-- markdownlint-disable -->
<details><summary>IR dump after the pass</summary>

<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span></pre></div></td><td class="code"><div><pre><span></span><code>#map = affine_map&lt;(d0, d1, d2) -&gt; (d0, d2)&gt;
#map1 = affine_map&lt;(d0, d1, d2) -&gt; (d2, d1)&gt;
#map2 = affine_map&lt;(d0, d1, d2) -&gt; (d0, d1)&gt;
<span class="hll">#encoding = #iree_encoding.encoding&lt;operand_index = 0 : index, op_type =  matmul,
</span><span class="hll">                                    element_types = [f32, f32, f32],
</span><span class="hll">                                    user_indexing_maps = [#map, #map1, #map2],
</span><span class="hll">                                    iteration_sizes = [?, ?, ?]&gt;
</span><span class="hll">#encoding1 = #iree_encoding.encoding&lt;operand_index = 1 : index, op_type =  matmul,
</span><span class="hll">                                     element_types = [f32, f32, f32],
</span><span class="hll">                                     user_indexing_maps = [#map, #map1, #map2],
</span><span class="hll">                                     iteration_sizes = [?, ?, ?]&gt;
</span><span class="hll">#encoding2 = #iree_encoding.encoding&lt;operand_index = 2 : index, op_type =  matmul,
</span><span class="hll">                                     element_types = [f32, f32, f32],
</span><span class="hll">                                     user_indexing_maps = [#map, #map1, #map2],
</span><span class="hll">                                     iteration_sizes = [?, ?, ?]&gt;
</span>util.func public @matmul_f32f32f32(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -&gt; !hal.buffer_view {
  %0 = hal.buffer_view.dim&lt;%arg0 : !hal.buffer_view&gt;[0] : index
  %1 = hal.buffer_view.dim&lt;%arg0 : !hal.buffer_view&gt;[1] : index
  %2 = hal.tensor.import %arg0 &quot;input0&quot; : !hal.buffer_view -&gt; tensor&lt;?x?xf32&gt;{%0, %1}
  %3 = hal.buffer_view.dim&lt;%arg1 : !hal.buffer_view&gt;[0] : index
  %4 = hal.buffer_view.dim&lt;%arg1 : !hal.buffer_view&gt;[1] : index
  %5 = hal.tensor.import %arg1 &quot;input1&quot; : !hal.buffer_view -&gt; tensor&lt;?x?xf32&gt;{%3, %4}
  %6 = flow.dispatch.region -&gt; (tensor&lt;?x?xf32&gt;{%0, %4}) {
    %cst = arith.constant 0.000000e+00 : f32
<span class="hll">    %8 = iree_encoding.set_encoding %2 : tensor&lt;?x?xf32&gt; -&gt; tensor&lt;?x?xf32, #encoding&gt;
</span><span class="hll">    %9 = iree_encoding.set_encoding %5 : tensor&lt;?x?xf32&gt; -&gt; tensor&lt;?x?xf32, #encoding1&gt;
</span>    %10 = tensor.empty(%0, %4) : tensor&lt;?x?xf32, #encoding2&gt;
    %11 = linalg.fill ins(%cst : f32) outs(%10 : tensor&lt;?x?xf32, #encoding2&gt;) -&gt; tensor&lt;?x?xf32, #encoding2&gt;
    %12 = linalg.matmul
      ins(%8, %9 : tensor&lt;?x?xf32, #encoding&gt;, tensor&lt;?x?xf32, #encoding1&gt;)
      outs(%11 : tensor&lt;?x?xf32, #encoding2&gt;) -&gt; tensor&lt;?x?xf32, #encoding2&gt;
<span class="hll">    %13 = iree_encoding.unset_encoding %12 : tensor&lt;?x?xf32, #encoding2&gt; -&gt; tensor&lt;?x?xf32&gt;{%0, %4}
</span>    flow.return %13 : tensor&lt;?x?xf32&gt;
  }
  %7 = hal.tensor.export %6 &quot;output0&quot; : tensor&lt;?x?xf32&gt;{%0, %4} -&gt; !hal.buffer_view
  util.return %7 : !hal.buffer_view
}
</code></pre></div></td></tr></table></div>

</details>
<!-- markdownlint-restore -->

<h3 id="hoistencodingopspass-dispatchcreation">HoistEncodingOpsPass (DispatchCreation)<a class="headerlink" href="#hoistencodingopspass-dispatchcreation" title="Permanent link">link</a></h3>
<p>The pass runs local propagation locally and hoists tensor encoding ops outside
Flow dispatch regions, so the <code>iree_encoding.set_encoding</code> ops can be fused
within producers later on.</p>
<!-- markdownlint-disable -->
<details><summary>IR dump after the pass</summary>

<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span></pre></div></td><td class="code"><div><pre><span></span><code>#map = affine_map&lt;(d0, d1, d2) -&gt; (d0, d2)&gt;
#map1 = affine_map&lt;(d0, d1, d2) -&gt; (d2, d1)&gt;
#map2 = affine_map&lt;(d0, d1, d2) -&gt; (d0, d1)&gt;
#encoding = #iree_encoding.encoding&lt;operand_index = 0 : index, op_type =  matmul,
                                    element_types = [f32, f32, f32],
                                    user_indexing_maps = [#map, #map1, #map2],
                                    iteration_sizes = [?, ?, ?]&gt;
#encoding1 = #iree_encoding.encoding&lt;operand_index = 1 : index, op_type =  matmul,
                                     element_types = [f32, f32, f32],
                                     user_indexing_maps = [#map, #map1, #map2],
                                     iteration_sizes = [?, ?, ?]&gt;
#encoding2 = #iree_encoding.encoding&lt;operand_index = 2 : index, op_type =  matmul,
                                     element_types = [f32, f32, f32],
                                     user_indexing_maps = [#map, #map1, #map2],
                                     iteration_sizes = [?, ?, ?]&gt;
util.func public @matmul_f32f32f32(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -&gt; !hal.buffer_view {
  %0 = hal.buffer_view.dim&lt;%arg0 : !hal.buffer_view&gt;[0] : index
  %1 = hal.buffer_view.dim&lt;%arg0 : !hal.buffer_view&gt;[1] : index
  %2 = hal.tensor.import %arg0 &quot;input0&quot; : !hal.buffer_view -&gt; tensor&lt;?x?xf32&gt;{%0, %1}
  %3 = hal.buffer_view.dim&lt;%arg1 : !hal.buffer_view&gt;[0] : index
  %4 = hal.buffer_view.dim&lt;%arg1 : !hal.buffer_view&gt;[1] : index
  %5 = hal.tensor.import %arg1 &quot;input1&quot; : !hal.buffer_view -&gt; tensor&lt;?x?xf32&gt;{%3, %4}
<span class="hll">  %6 = iree_encoding.set_encoding %2 : tensor&lt;?x?xf32&gt; -&gt; tensor&lt;?x?xf32, #encoding&gt;
</span><span class="hll">  %7 = iree_encoding.set_encoding %5 : tensor&lt;?x?xf32&gt; -&gt; tensor&lt;?x?xf32, #encoding1&gt;
</span>  %8 = flow.dispatch.region -&gt; (tensor&lt;?x?xf32&gt;{%0, %4}) {
    %cst = arith.constant 0.000000e+00 : f32
    %10 = tensor.empty(%0, %4) : tensor&lt;?x?xf32, #encoding2&gt;
    %11 = linalg.fill ins(%cst : f32) outs(%10 : tensor&lt;?x?xf32, #encoding2&gt;) -&gt; tensor&lt;?x?xf32, #encoding2&gt;
    %12 = linalg.matmul
      ins(%6, %7 : tensor&lt;?x?xf32, #encoding&gt;, tensor&lt;?x?xf32, #encoding1&gt;)
      outs(%11 : tensor&lt;?x?xf32, #encoding2&gt;) -&gt; tensor&lt;?x?xf32, #encoding2&gt;
    %13 = iree_encoding.unset_encoding %12 : tensor&lt;?x?xf32, #encoding2&gt; -&gt; tensor&lt;?x?xf32&gt;{%0, %4}
    flow.return %13 : tensor&lt;?x?xf32&gt;
  }
  %9 = hal.tensor.export %8 &quot;output0&quot; : tensor&lt;?x?xf32&gt;{%0, %4} -&gt; !hal.buffer_view
  util.return %9 : !hal.buffer_view
}
</code></pre></div></td></tr></table></div>

</details>
<!-- markdownlint-restore -->

<details><summary>Example with local propagation</summary>

There is an elementwise operation followed by the `linalg.matmul` op, and the
second input operand has an encoding after propagation. Thus, there are three
`iree_encoding.set_encoding` ops in total outside dispatch regions. A new
`#encoding3` is generated because of the broadcasting map.

<br/>

IR dump before the pass:

<!-- markdownlint-disable -->
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span></pre></div></td><td class="code"><div><pre><span></span><code>#map = affine_map&lt;(d0, d1, d2) -&gt; (d0, d2)&gt;
#map1 = affine_map&lt;(d0, d1, d2) -&gt; (d2, d1)&gt;
#map2 = affine_map&lt;(d0, d1, d2) -&gt; (d0, d1)&gt;
#map3 = affine_map&lt;(d0, d1) -&gt; (d0, d1)&gt;
#map4 = affine_map&lt;(d0, d1) -&gt; (d1)&gt;
#encoding = #iree_encoding.encoding&lt;operand_index = 0 : index, op_type =  matmul,
                                    element_types = [f32, f32, f32],
                                    user_indexing_maps = [#map, #map1, #map2],
                                    iteration_sizes = [255, 1023, 513]&gt;
#encoding1 = #iree_encoding.encoding&lt;operand_index = 1 : index, op_type =  matmul,
                                     element_types = [f32, f32, f32],
                                     user_indexing_maps = [#map, #map1, #map2],
                                     iteration_sizes = [255, 1023, 513]&gt;
#encoding2 = #iree_encoding.encoding&lt;operand_index = 2 : index, op_type =  matmul,
                                     element_types = [f32, f32, f32],
                                     user_indexing_maps = [#map, #map1, #map2],
                                     iteration_sizes = [255, 1023, 513]&gt;
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -&gt; !hal.buffer_view {
  %0 = hal.tensor.import %arg0 &quot;input0&quot; : !hal.buffer_view -&gt; tensor&lt;255x513xf32&gt;
  %1 = hal.tensor.import %arg1 &quot;input1&quot; : !hal.buffer_view -&gt; tensor&lt;1023xf32&gt;
  %2 = flow.dispatch.region -&gt; (tensor&lt;255x1023xf32&gt;) {
    %4 = tensor.empty() : tensor&lt;255x1023xf32&gt;
    %cst = arith.constant 0.000000e+00 : f32
    %cst_0 = arith.constant dense&lt;1.000000e+00&gt; : tensor&lt;513x1023xf32&gt;
    %5 = iree_encoding.set_encoding %0 : tensor&lt;255x513xf32&gt; -&gt; tensor&lt;255x513xf32, #encoding&gt;
    %6 = iree_encoding.set_encoding %cst_0 : tensor&lt;513x1023xf32&gt; -&gt; tensor&lt;513x1023xf32, #encoding1&gt;
    %7 = tensor.empty() : tensor&lt;255x1023xf32, #encoding2&gt;
    %8 = linalg.fill ins(%cst : f32) outs(%7 : tensor&lt;255x1023xf32, #encoding2&gt;) -&gt; tensor&lt;255x1023xf32, #encoding2&gt;
    %9 = linalg.matmul
      ins(%5, %6 : tensor&lt;255x513xf32, #encoding&gt;, tensor&lt;513x1023xf32, #encoding1&gt;)
      outs(%8 : tensor&lt;255x1023xf32, #encoding2&gt;) -&gt; tensor&lt;255x1023xf32, #encoding2&gt;
    %10 = iree_encoding.unset_encoding %9 : tensor&lt;255x1023xf32, #encoding2&gt; -&gt; tensor&lt;255x1023xf32&gt;
<span class="hll">    %11 = linalg.generic {indexing_maps = [#map3, #map4, #map3], iterator_types = [&quot;parallel&quot;, &quot;parallel&quot;]}
</span><span class="hll">      ins(%10, %1 : tensor&lt;255x1023xf32&gt;, tensor&lt;1023xf32&gt;)
</span><span class="hll">      outs(%4 : tensor&lt;255x1023xf32&gt;) {
</span><span class="hll">    ^bb0(%in: f32, %in_1: f32, %out: f32):
</span><span class="hll">      %12 = arith.mulf %in, %in_1 : f32
</span><span class="hll">      linalg.yield %12 : f32
</span><span class="hll">    } -&gt; tensor&lt;255x1023xf32&gt;
</span>    flow.return %11 : tensor&lt;255x1023xf32&gt;
  }
  %3 = hal.tensor.export %2 &quot;output0&quot; : tensor&lt;255x1023xf32&gt; -&gt; !hal.buffer_view
  util.return %3 : !hal.buffer_view
}
</code></pre></div></td></tr></table></div>

IR dump after the pass:

<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span></pre></div></td><td class="code"><div><pre><span></span><code>#map = affine_map&lt;(d0, d1, d2) -&gt; (d0, d2)&gt;
#map1 = affine_map&lt;(d0, d1, d2) -&gt; (d2, d1)&gt;
#map2 = affine_map&lt;(d0, d1, d2) -&gt; (d0, d1)&gt;
#map3 = affine_map&lt;(d0, d1) -&gt; (d1)&gt;
#map4 = affine_map&lt;(d0, d1) -&gt; (d0, d1)&gt;
#encoding = #iree_encoding.encoding&lt;operand_index = 0 : index, op_type =  matmul,
                                    element_types = [f32, f32, f32],
                                    user_indexing_maps = [#map, #map1, #map2],
                                    iteration_sizes = [255, 1023, 513]&gt;
#encoding1 = #iree_encoding.encoding&lt;operand_index = 1 : index, op_type =  matmul,
                                     element_types = [f32, f32, f32],
                                     user_indexing_maps = [#map, #map1, #map2],
                                     iteration_sizes = [255, 1023, 513]&gt;
#encoding2 = #iree_encoding.encoding&lt;operand_index = 2 : index, op_type =  matmul,
                                     element_types = [f32, f32, f32],
                                     user_indexing_maps = [#map, #map1, #map2],
                                     iteration_sizes = [255, 1023, 513]&gt;
<span class="hll">#encoding3 = #iree_encoding.encoding&lt;operand_index = 2 : index, op_type =  matmul,
</span><span class="hll">                                     element_types = [f32, f32, f32],
</span><span class="hll">                                     user_indexing_maps = [#map, #map1, [#map2, #map3]],
</span><span class="hll">                                     iteration_sizes = [255, 1023, 513]&gt;
</span>util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -&gt; !hal.buffer_view {
  %0 = hal.tensor.import %arg0 &quot;input0&quot; : !hal.buffer_view -&gt; tensor&lt;255x513xf32&gt;
  %1 = hal.tensor.import %arg1 &quot;input1&quot; : !hal.buffer_view -&gt; tensor&lt;1023xf32&gt;
  %2 = iree_encoding.set_encoding %0 : tensor&lt;255x513xf32&gt; -&gt; tensor&lt;255x513xf32, #encoding&gt;
  %cst = arith.constant dense&lt;1.000000e+00&gt; : tensor&lt;513x1023xf32&gt;
  %3 = iree_encoding.set_encoding %cst : tensor&lt;513x1023xf32&gt; -&gt; tensor&lt;513x1023xf32, #encoding1&gt;
<span class="hll">  %4 = iree_encoding.set_encoding %1 : tensor&lt;1023xf32&gt; -&gt; tensor&lt;1023xf32, #encoding3&gt;
</span>  %5 = flow.dispatch.region -&gt; (tensor&lt;255x1023xf32&gt;) {
    %7 = tensor.empty() : tensor&lt;255x1023xf32, #encoding2&gt;
    %cst_0 = arith.constant 0.000000e+00 : f32
    %8 = tensor.empty() : tensor&lt;255x1023xf32, #encoding2&gt;
    %9 = linalg.fill ins(%cst_0 : f32) outs(%8 : tensor&lt;255x1023xf32, #encoding2&gt;) -&gt; tensor&lt;255x1023xf32, #encoding2&gt;
    %10 = linalg.matmul
      ins(%2, %3 : tensor&lt;255x513xf32, #encoding&gt;, tensor&lt;513x1023xf32, #encoding1&gt;)
      outs(%9 : tensor&lt;255x1023xf32, #encoding2&gt;) -&gt; tensor&lt;255x1023xf32, #encoding2&gt;
    %11 = linalg.generic {indexing_maps = [#map4, #map3, #map4], iterator_types = [&quot;parallel&quot;, &quot;parallel&quot;]}
      ins(%10, %4 : tensor&lt;255x1023xf32, #encoding2&gt;, tensor&lt;1023xf32, #encoding3&gt;)
      outs(%7 : tensor&lt;255x1023xf32, #encoding2&gt;) {
    ^bb0(%in: f32, %in_1: f32, %out: f32):
      %13 = arith.mulf %in, %in_1 : f32
      linalg.yield %13 : f32
    } -&gt; tensor&lt;255x1023xf32, #encoding2&gt;
<span class="hll">    %12 = iree_encoding.unset_encoding %11 : tensor&lt;255x1023xf32, #encoding2&gt; -&gt; tensor&lt;255x1023xf32&gt;
</span>    flow.return %12 : tensor&lt;255x1023xf32&gt;
  }
  %6 = hal.tensor.export %5 &quot;output0&quot; : tensor&lt;255x1023xf32&gt; -&gt; !hal.buffer_view
  util.return %6 : !hal.buffer_view
}
</code></pre></div></td></tr></table></div>
<!-- markdownlint-restore -->

</details>

<h3 id="propagateencodingspass-dispatchcreation">PropagateEncodingsPass (DispatchCreation)<a class="headerlink" href="#propagateencodingspass-dispatchcreation" title="Permanent link">link</a></h3>
<p>This is a placeholder for propagating encodings globally, i.e., outside
<code>flow.dispatch.region</code> ops. However, the pass does not perform anything because
the design and the implementation are not done yet.</p>
<h3 id="fuseencodingopsintodispatchregionspass-dispatchcreation">FuseEncodingOpsIntoDispatchRegionsPass (DispatchCreation)<a class="headerlink" href="#fuseencodingopsintodispatchregionspass-dispatchcreation" title="Permanent link">link</a></h3>
<p>The pass fuses <code>iree_encoding.set_encoding</code> ops, that are outside dispatch
regions, into producer, if the source is a <code>flow.dispatch.region</code> op.</p>
<p>The result IR is the same in the example. You can go to <a href="https://github.com/iree-org/iree/blob/main/compiler/src/iree/compiler/DispatchCreation/test/fuse_encoding_ops_into_dispatch_regions.mlir">the lit
tests</a>
for examples.</p>
<h3 id="convertencodingtoflowpass-dispatchcreation">ConvertEncodingToFlowPass (DispatchCreation)<a class="headerlink" href="#convertencodingtoflowpass-dispatchcreation" title="Permanent link">link</a></h3>
<p>The pass replaces <code>iree_encoding.set_encoding</code> ops with <code>flow.tensor.encode</code>
ops, if they are outside dispatch regions. The design idea is mainly for
folding. Otherwise, it results in an executable that performs copy if the
relayout is not needed.</p>
<p>IREE specializes the encodings in a later pass (i.e., SpecializeEncodingsPass)
that converts verbose encodings to serialized encodings. The
<code>[flow|stream].tensor.encode</code> ops can be folded away, if the source tensor type
is identical to the result tensor type.</p>
<details><summary>IR dump after the pass</summary>

Note: the `canonicalize` is run after the pass in this example, because it makes
IR clear. Otherwise, there are `arith.constant` ops and `tensor.dim` ops around
`flow.tensor.encode` ops.

<!-- markdownlint-disable -->
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span></pre></div></td><td class="code"><div><pre><span></span><code>#map = affine_map&lt;(d0, d1, d2) -&gt; (d0, d2)&gt;
#map1 = affine_map&lt;(d0, d1, d2) -&gt; (d2, d1)&gt;
#map2 = affine_map&lt;(d0, d1, d2) -&gt; (d0, d1)&gt;
#encoding = #iree_encoding.encoding&lt;operand_index = 0 : index, op_type =  matmul,
                                    element_types = [f32, f32, f32],
                                    user_indexing_maps = [#map, #map1, #map2],
                                    iteration_sizes = [?, ?, ?]&gt;
#encoding1 = #iree_encoding.encoding&lt;operand_index = 1 : index, op_type =  matmul,
                                     element_types = [f32, f32, f32],
                                     user_indexing_maps = [#map, #map1, #map2],
                                     iteration_sizes = [?, ?, ?]&gt;
#encoding2 = #iree_encoding.encoding&lt;operand_index = 2 : index, op_type =  matmul,
                                     element_types = [f32, f32, f32],
                                     user_indexing_maps = [#map, #map1, #map2],
                                     iteration_sizes = [?, ?, ?]&gt;
module {
  util.func public @matmul_f32f32f32(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -&gt; !hal.buffer_view {
    %cst = arith.constant 0.000000e+00 : f32
    %0 = hal.buffer_view.dim&lt;%arg0 : !hal.buffer_view&gt;[0] : index
    %1 = hal.buffer_view.dim&lt;%arg0 : !hal.buffer_view&gt;[1] : index
    %2 = hal.tensor.import %arg0 &quot;input0&quot; : !hal.buffer_view -&gt; tensor&lt;?x?xf32&gt;{%0, %1}
    %3 = hal.buffer_view.dim&lt;%arg1 : !hal.buffer_view&gt;[0] : index
    %4 = hal.buffer_view.dim&lt;%arg1 : !hal.buffer_view&gt;[1] : index
    %5 = hal.tensor.import %arg1 &quot;input1&quot; : !hal.buffer_view -&gt; tensor&lt;?x?xf32&gt;{%3, %4}
<span class="hll">    %6 = flow.tensor.encode %2 : tensor&lt;?x?xf32&gt;{%0, %1} -&gt; tensor&lt;?x?xf32, #encoding&gt;{%0, %1}
</span><span class="hll">    %7 = flow.tensor.encode %5 : tensor&lt;?x?xf32&gt;{%3, %4} -&gt; tensor&lt;?x?xf32, #encoding1&gt;{%3, %4}
</span>    %8 = flow.dispatch.region -&gt; (tensor&lt;?x?xf32&gt;{%0, %4}) {
      %10 = tensor.empty(%0, %4) : tensor&lt;?x?xf32, #encoding2&gt;
      %11 = linalg.fill ins(%cst : f32) outs(%10 : tensor&lt;?x?xf32, #encoding2&gt;) -&gt; tensor&lt;?x?xf32, #encoding2&gt;
      %12 = linalg.matmul
        ins(%6, %7 : tensor&lt;?x?xf32, #encoding&gt;, tensor&lt;?x?xf32, #encoding1&gt;)
        outs(%11 : tensor&lt;?x?xf32, #encoding2&gt;) -&gt; tensor&lt;?x?xf32, #encoding2&gt;
      %13 = iree_encoding.unset_encoding %12 : tensor&lt;?x?xf32, #encoding2&gt; -&gt; tensor&lt;?x?xf32&gt;{%0, %4}
      flow.return %13 : tensor&lt;?x?xf32&gt;
    }
    %9 = hal.tensor.export %8 &quot;output0&quot; : tensor&lt;?x?xf32&gt;{%0, %4} -&gt; !hal.buffer_view
    util.return %9 : !hal.buffer_view
  }
}
</code></pre></div></td></tr></table></div>
<!-- markdownlint-restore -->

</details>

<h3 id="hoistintoglobalspass-dispatchcreation">HoistIntoGlobalsPass (DispatchCreation)<a class="headerlink" href="#hoistintoglobalspass-dispatchcreation" title="Permanent link">link</a></h3>
<p>This is where IREE hoists relayout ops that perform on weights and constants to
initializers. IREE performs <a href="https://github.com/iree-org/iree/blob/main/compiler/src/iree/compiler/Dialect/Util/Analysis/Constant/ConstExpr.h">ConstExprAnalysis</a>
and hoists the constant expressions to <code>util.initializer</code> modules. They will be
executed either during compile-time or initialization phase. I.e., it is not
part of the actual execution.</p>
<p>It creates a global variable for each expression and stores the result to new
variables. On the program side, all the hoisted computation is replaced with
<code>util.global.load</code> ops.</p>
<p>The result IR is the same in the example. The below example demonstrates the
hoisting result if the source is weight.</p>
<p>Note: const-evaluation is not yet supported after global optimization phase, so
they can only be executed in initialization phase today.</p>
<details><summary>Example with hoisting to initializers</summary>

IR dump before the pass:

<!-- markdownlint-disable -->
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span></pre></div></td><td class="code"><div><pre><span></span><code>#map = affine_map&lt;(d0, d1, d2) -&gt; (d0, d2)&gt;
#map1 = affine_map&lt;(d0, d1, d2) -&gt; (d2, d1)&gt;
#map2 = affine_map&lt;(d0, d1, d2) -&gt; (d0, d1)&gt;
#map3 = affine_map&lt;(d0, d1) -&gt; (d1)&gt;
#map4 = affine_map&lt;(d0, d1) -&gt; (d0, d1)&gt;
#encoding = #iree_encoding.encoding&lt;operand_index = 0 : index, op_type =  matmul,
                                    element_types = [f32, f32, f32],
                                    user_indexing_maps = [#map, #map1, #map2],
                                    iteration_sizes = [255, 1023, 513]&gt;
#encoding1 = #iree_encoding.encoding&lt;operand_index = 1 : index, op_type =  matmul,
                                     element_types = [f32, f32, f32],
                                     user_indexing_maps = [#map, #map1, #map2],
                                     iteration_sizes = [255, 1023, 513]&gt;
#encoding2 = #iree_encoding.encoding&lt;operand_index = 2 : index, op_type =  matmul,
                                     element_types = [f32, f32, f32],
                                     user_indexing_maps = [#map, #map1, #map2],
                                     iteration_sizes = [255, 1023, 513]&gt;
#encoding3 = #iree_encoding.encoding&lt;operand_index = 2 : index, op_type =  matmul,
                                     element_types = [f32, f32, f32],
                                     user_indexing_maps = [#map, #map1, [#map2, #map3]],
                                     iteration_sizes = [255, 1023, 513]&gt;
util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -&gt; !hal.buffer_view {
  %0 = hal.tensor.import %arg0 &quot;input0&quot; : !hal.buffer_view -&gt; tensor&lt;255x513xf32&gt;
  %1 = hal.tensor.import %arg1 &quot;input1&quot; : !hal.buffer_view -&gt; tensor&lt;1023xf32&gt;
  %2 = flow.tensor.encode %0 : tensor&lt;255x513xf32&gt; -&gt; tensor&lt;255x513xf32, #encoding&gt;
<span class="hll">  %cst = arith.constant dense&lt;1.000000e+00&gt; : tensor&lt;513x1023xf32&gt;
</span><span class="hll">  %3 = flow.tensor.encode %cst : tensor&lt;513x1023xf32&gt; -&gt; tensor&lt;513x1023xf32, #encoding1&gt;
</span>  %4 = flow.tensor.encode %1 : tensor&lt;1023xf32&gt; -&gt; tensor&lt;1023xf32, #encoding3&gt;
  %5 = flow.dispatch.region -&gt; (tensor&lt;255x1023xf32&gt;) {
    %7 = tensor.empty() : tensor&lt;255x1023xf32, #encoding2&gt;
    %cst_0 = arith.constant 0.000000e+00 : f32
    %8 = linalg.fill ins(%cst_0 : f32) outs(%7 : tensor&lt;255x1023xf32, #encoding2&gt;) -&gt; tensor&lt;255x1023xf32, #encoding2&gt;
    %9 = linalg.matmul
      ins(%2, %3 : tensor&lt;255x513xf32, #encoding&gt;, tensor&lt;513x1023xf32, #encoding1&gt;)
      outs(%8 : tensor&lt;255x1023xf32, #encoding2&gt;) -&gt; tensor&lt;255x1023xf32, #encoding2&gt;
    %10 = linalg.generic {indexing_maps = [#map4, #map3, #map4], iterator_types = [&quot;parallel&quot;, &quot;parallel&quot;]}
      ins(%9, %4 : tensor&lt;255x1023xf32, #encoding2&gt;, tensor&lt;1023xf32, #encoding3&gt;)
      outs(%7 : tensor&lt;255x1023xf32, #encoding2&gt;) {
    ^bb0(%in: f32, %in_1: f32, %out: f32):
      %12 = arith.mulf %in, %in_1 : f32
      linalg.yield %12 : f32
    } -&gt; tensor&lt;255x1023xf32, #encoding2&gt;
    %11 = iree_encoding.unset_encoding %10 : tensor&lt;255x1023xf32, #encoding2&gt; -&gt; tensor&lt;255x1023xf32&gt;
    flow.return %11 : tensor&lt;255x1023xf32&gt;
  }
  %6 = hal.tensor.export %5 &quot;output0&quot; : tensor&lt;255x1023xf32&gt; -&gt; !hal.buffer_view
  util.return %6 : !hal.buffer_view
}
</code></pre></div></td></tr></table></div>
<!-- markdownlint-restore -->

IR dump after the pass:

<!-- markdownlint-disable -->
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span></pre></div></td><td class="code"><div><pre><span></span><code>#executable_target_rocm_hsaco_fb = #hal.executable.target&lt;&quot;rocm&quot;, &quot;rocm-hsaco-fb&quot;, {abi = &quot;hip&quot;, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver&lt;&gt;, iree_codegen.target_info = #iree_gpu.target&lt;arch = &quot;gfx942&quot;, features = &quot;&quot;, wgp = &lt;compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [&lt;MFMA_F32_16x16x16_BF16&gt;, &lt;MFMA_F32_32x32x8_BF16&gt;, &lt;MFMA_F32_16x16x32_F8E5M2FNUZ&gt;, &lt;MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ&gt;, &lt;MFMA_F32_16x16x32_F8E4M3FNUZ&gt;, &lt;MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ&gt;, &lt;MFMA_F32_32x32x16_F8E5M2FNUZ&gt;, &lt;MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ&gt;, &lt;MFMA_F32_32x32x16_F8E4M3FNUZ&gt;, &lt;MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ&gt;, &lt;MFMA_I32_16x16x32_I8&gt;, &lt;MFMA_I32_32x32x16_I8&gt;, &lt;MFMA_F64_16x16x4_F64&gt;, &lt;MFMA_F32_16x16x4_F32&gt;, &lt;MFMA_F32_16x16x16_F16&gt;, &lt;MFMA_F32_32x32x8_F16&gt;], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384&gt;&gt;, ukernels = &quot;none&quot;}&gt;
#map = affine_map&lt;(d0, d1, d2) -&gt; (d0, d2)&gt;
#map1 = affine_map&lt;(d0, d1, d2) -&gt; (d2, d1)&gt;
#map2 = affine_map&lt;(d0, d1, d2) -&gt; (d0, d1)&gt;
#map3 = affine_map&lt;(d0, d1) -&gt; (d1)&gt;
#map4 = affine_map&lt;(d0, d1) -&gt; (d0, d1)&gt;
#device_target_hip = #hal.device.target&lt;&quot;hip&quot;, [#executable_target_rocm_hsaco_fb]&gt; : !hal.device
#encoding = #iree_encoding.encoding&lt;operand_index = 1 : index, op_type =  matmul,
                                    element_types = [f32, f32, f32],
                                    user_indexing_maps = [#map, #map1, #map2],
                                    iteration_sizes = [255, 1023, 513]&gt;
#encoding1 = #iree_encoding.encoding&lt;operand_index = 0 : index, op_type =  matmul,
                                     element_types = [f32, f32, f32],
                                     user_indexing_maps = [#map, #map1, #map2],
                                     iteration_sizes = [255, 1023, 513]&gt;
#encoding2 = #iree_encoding.encoding&lt;operand_index = 2 : index, op_type =  matmul,
                                     element_types = [f32, f32, f32],
                                     user_indexing_maps = [#map, #map1, #map2],
                                     iteration_sizes = [255, 1023, 513]&gt;
#encoding3 = #iree_encoding.encoding&lt;operand_index = 2 : index, op_type =  matmul,
                                     element_types = [f32, f32, f32],
                                     user_indexing_maps = [#map, #map1, [#map2, #map3]],
                                     iteration_sizes = [255, 1023, 513]&gt;
module attributes {stream.affinity.default = #hal.device.affinity&lt;@__device_0&gt;} {
  util.global private @__device_0 = #device_target_hip
  util.global private @__hoisted_tensor_513x1023xf32__encoded {stream.affinity.default = #hal.device.affinity&lt;@__device_0&gt;} : tensor&lt;513x1023xf32, #encoding&gt;
<span class="hll">  util.initializer attributes {stream.affinity.default = #hal.device.affinity&lt;@__device_0&gt;} {
</span><span class="hll">    %cst = arith.constant dense&lt;1.000000e+00&gt; : tensor&lt;513x1023xf32&gt;
</span><span class="hll">    %0 = flow.tensor.encode %cst : tensor&lt;513x1023xf32&gt; -&gt; tensor&lt;513x1023xf32, #encoding&gt;
</span><span class="hll">    util.global.store %0, @__hoisted_tensor_513x1023xf32__encoded : tensor&lt;513x1023xf32, #encoding&gt;
</span><span class="hll">    util.return
</span><span class="hll">  }
</span>  util.func public @foo(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -&gt; !hal.buffer_view {
    %0 = hal.tensor.import %arg0 &quot;input0&quot; : !hal.buffer_view -&gt; tensor&lt;255x513xf32&gt;
    %1 = hal.tensor.import %arg1 &quot;input1&quot; : !hal.buffer_view -&gt; tensor&lt;1023xf32&gt;
    %2 = flow.tensor.encode %0 : tensor&lt;255x513xf32&gt; -&gt; tensor&lt;255x513xf32, #encoding1&gt;
<span class="hll">    %__hoisted_tensor_513x1023xf32__encoded = util.global.load immutable @__hoisted_tensor_513x1023xf32__encoded : tensor&lt;513x1023xf32, #encoding&gt;
</span>    %3 = flow.tensor.encode %1 : tensor&lt;1023xf32&gt; -&gt; tensor&lt;1023xf32, #encoding3&gt;
    %4 = flow.dispatch.region -&gt; (tensor&lt;255x1023xf32&gt;) {
      %6 = tensor.empty() : tensor&lt;255x1023xf32, #encoding2&gt;
      %cst = arith.constant 0.000000e+00 : f32
      %7 = linalg.fill ins(%cst : f32) outs(%6 : tensor&lt;255x1023xf32, #encoding2&gt;) -&gt; tensor&lt;255x1023xf32, #encoding2&gt;
      %8 = linalg.matmul
        ins(%2, %__hoisted_tensor_513x1023xf32__encoded : tensor&lt;255x513xf32, #encoding1&gt;, tensor&lt;513x1023xf32, #encoding&gt;)
        outs(%7 : tensor&lt;255x1023xf32, #encoding2&gt;) -&gt; tensor&lt;255x1023xf32, #encoding2&gt;
      %9 = linalg.generic {indexing_maps = [#map4, #map3, #map4], iterator_types = [&quot;parallel&quot;, &quot;parallel&quot;]}
        ins(%8, %3 : tensor&lt;255x1023xf32, #encoding2&gt;, tensor&lt;1023xf32, #encoding3&gt;)
        outs(%6 : tensor&lt;255x1023xf32, #encoding2&gt;) {
      ^bb0(%in: f32, %in_0: f32, %out: f32):
        %11 = arith.mulf %in, %in_0 : f32
        linalg.yield %11 : f32
      } -&gt; tensor&lt;255x1023xf32, #encoding2&gt;
      %10 = iree_encoding.unset_encoding %9 : tensor&lt;255x1023xf32, #encoding2&gt; -&gt; tensor&lt;255x1023xf32&gt;
      flow.return %10 : tensor&lt;255x1023xf32&gt;
    }
    %5 = hal.tensor.export %4 &quot;output0&quot; : tensor&lt;255x1023xf32&gt; -&gt; !hal.buffer_view
    util.return %5 : !hal.buffer_view
  }
}
</code></pre></div></td></tr></table></div>
<!-- markdownlint-restore -->

</details>

<h3 id="converttostreampass">ConvertToStreamPass<a class="headerlink" href="#converttostreampass" title="Permanent link">link</a></h3>
<p>IREE then converts dispatch regions to workgroup ops, outlines them to
executables, and convert flow ops to stream ops. It is not data-tiling
specifics, but the IR dump before and after the pass is showed for better
picture.</p>
<p>After the conversion, the flow executables all become stream executables, and
the function arguments become opaque types (i.e., <code>stream.binding</code> types).</p>
<p>The host code is mostly composed of <code>stream.tensor.sizeof</code> and
<code>stream.tensor.dispatch</code> ops.</p>
<ul>
<li>The <code>sizeof</code> op takes a tensor type with an optional encoding and indicates
  the storage buffer size that will be used to issue the allocation later on.</li>
<li>The <code>dispatch</code> op describes how we call the functions in the program.</li>
</ul>
<!-- markdownlint-disable -->
<details><summary>IR dump before the pass</summary>

<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span></pre></div></td><td class="code"><div><pre><span></span><code>#executable_target_rocm_hsaco_fb = #hal.executable.target&lt;&quot;rocm&quot;, &quot;rocm-hsaco-fb&quot;, {abi = &quot;hip&quot;, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver&lt;&gt;, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module&lt;&quot;iree_default_tuning_spec_gfx942.mlir&quot;&gt;, iree_codegen.target_info = #iree_gpu.target&lt;arch = &quot;gfx942&quot;, features = &quot;&quot;, wgp = &lt;compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [&lt;MFMA_F32_16x16x16_BF16&gt;, &lt;MFMA_F32_32x32x8_BF16&gt;, &lt;MFMA_F32_16x16x32_F8E5M2FNUZ&gt;, &lt;MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ&gt;, &lt;MFMA_F32_16x16x32_F8E4M3FNUZ&gt;, &lt;MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ&gt;, &lt;MFMA_F32_32x32x16_F8E5M2FNUZ&gt;, &lt;MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ&gt;, &lt;MFMA_F32_32x32x16_F8E4M3FNUZ&gt;, &lt;MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ&gt;, &lt;MFMA_I32_16x16x32_I8&gt;, &lt;MFMA_I32_32x32x16_I8&gt;, &lt;MFMA_F64_16x16x4_F64&gt;, &lt;MFMA_F32_16x16x4_F32&gt;, &lt;MFMA_F32_16x16x16_F16&gt;, &lt;MFMA_F32_32x32x8_F16&gt;], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384&gt;&gt;, ukernels = &quot;none&quot;}&gt;
#map = affine_map&lt;(d0, d1, d2) -&gt; (d0, d2)&gt;
#map1 = affine_map&lt;(d0, d1, d2) -&gt; (d2, d1)&gt;
#map2 = affine_map&lt;(d0, d1, d2) -&gt; (d0, d1)&gt;
#device_target_hip = #hal.device.target&lt;&quot;hip&quot;, [#executable_target_rocm_hsaco_fb]&gt; : !hal.device
#encoding = #iree_encoding.encoding&lt;operand_index = 0 : index, op_type =  matmul, element_types = [f32, f32, f32], user_indexing_maps = [#map, #map1, #map2], iteration_sizes = [?, ?, ?]&gt;
#encoding1 = #iree_encoding.encoding&lt;operand_index = 1 : index, op_type =  matmul, element_types = [f32, f32, f32], user_indexing_maps = [#map, #map1, #map2], iteration_sizes = [?, ?, ?]&gt;
#encoding2 = #iree_encoding.encoding&lt;operand_index = 2 : index, op_type =  matmul, element_types = [f32, f32, f32], user_indexing_maps = [#map, #map1, #map2], iteration_sizes = [?, ?, ?]&gt;
module attributes {stream.affinity.default = #hal.device.affinity&lt;@__device_0&gt;} {
  util.global private @__device_0 = #device_target_hip
  flow.executable private @matmul_f32f32f32_dispatch_0 {
    flow.executable.export public @matmul_f32f32f32_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index, %arg2: index, %arg3: index) -&gt; (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice(%arg0, %arg1, %arg2, %arg3)
      flow.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_f32f32f32_dispatch_0_matmul_DxDxD_f32(%arg0: !iree_tensor_ext.dispatch.tensor&lt;readonly:tensor&lt;?x?xf32, #encoding&gt;&gt;, %arg1: !iree_tensor_ext.dispatch.tensor&lt;readonly:tensor&lt;?x?xf32, #encoding1&gt;&gt;, %arg2: index, %arg3: index, %arg4: index, %arg5: index, %arg6: !iree_tensor_ext.dispatch.tensor&lt;writeonly:tensor&lt;?x?xf32&gt;&gt;) {
        %cst = arith.constant 0.000000e+00 : f32
        %0 = iree_tensor_ext.dispatch.workload.ordinal %arg2, 0 : index
        %1 = iree_tensor_ext.dispatch.workload.ordinal %arg3, 1 : index
        %2 = iree_tensor_ext.dispatch.workload.ordinal %arg4, 2 : index
        %3 = iree_tensor_ext.dispatch.workload.ordinal %arg5, 3 : index
        %4 = flow.dispatch.tie_shape %arg0 : !iree_tensor_ext.dispatch.tensor&lt;readonly:tensor&lt;?x?xf32, #encoding&gt;&gt;{%0, %1}
        %5 = flow.dispatch.tie_shape %arg1 : !iree_tensor_ext.dispatch.tensor&lt;readonly:tensor&lt;?x?xf32, #encoding1&gt;&gt;{%2, %3}
        %6 = flow.dispatch.tie_shape %arg6 : !iree_tensor_ext.dispatch.tensor&lt;writeonly:tensor&lt;?x?xf32&gt;&gt;{%0, %3}
        %7 = iree_tensor_ext.dispatch.tensor.load %4, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor&lt;readonly:tensor&lt;?x?xf32, #encoding&gt;&gt;{%0, %1} -&gt; tensor&lt;?x?xf32, #encoding&gt;
        %8 = iree_tensor_ext.dispatch.tensor.load %5, offsets = [0, 0], sizes = [%2, %3], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor&lt;readonly:tensor&lt;?x?xf32, #encoding1&gt;&gt;{%2, %3} -&gt; tensor&lt;?x?xf32, #encoding1&gt;
        %9 = tensor.empty(%0, %3) : tensor&lt;?x?xf32, #encoding2&gt;
        %10 = linalg.fill ins(%cst : f32) outs(%9 : tensor&lt;?x?xf32, #encoding2&gt;) -&gt; tensor&lt;?x?xf32, #encoding2&gt;
        %11 = linalg.matmul ins(%7, %8 : tensor&lt;?x?xf32, #encoding&gt;, tensor&lt;?x?xf32, #encoding1&gt;) outs(%10 : tensor&lt;?x?xf32, #encoding2&gt;) -&gt; tensor&lt;?x?xf32, #encoding2&gt;
        %12 = iree_encoding.unset_encoding %11 : tensor&lt;?x?xf32, #encoding2&gt; -&gt; tensor&lt;?x?xf32&gt;{%0, %3}
        iree_tensor_ext.dispatch.tensor.store %12, %6, offsets = [0, 0], sizes = [%0, %3], strides = [1, 1] : tensor&lt;?x?xf32&gt; -&gt; !iree_tensor_ext.dispatch.tensor&lt;writeonly:tensor&lt;?x?xf32&gt;&gt;{%0, %3}
        return
      }
    }
  }
  util.func public @matmul_f32f32f32(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -&gt; !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = &quot;sync func @matmul_f32f32f32(%input0: tensor&lt;?x?xf32&gt;, %input1: tensor&lt;?x?xf32&gt;) -&gt; (%output0: tensor&lt;?x?xf32&gt;)&quot;}} {
    %0 = hal.buffer_view.dim&lt;%arg0 : !hal.buffer_view&gt;[0] : index
    %1 = hal.buffer_view.dim&lt;%arg0 : !hal.buffer_view&gt;[1] : index
    %2 = hal.tensor.import %arg0 &quot;input0&quot; : !hal.buffer_view -&gt; tensor&lt;?x?xf32&gt;{%0, %1}
    %3 = hal.buffer_view.dim&lt;%arg1 : !hal.buffer_view&gt;[0] : index
    %4 = hal.buffer_view.dim&lt;%arg1 : !hal.buffer_view&gt;[1] : index
    %5 = hal.tensor.import %arg1 &quot;input1&quot; : !hal.buffer_view -&gt; tensor&lt;?x?xf32&gt;{%3, %4}
    %6 = flow.tensor.encode %2 : tensor&lt;?x?xf32&gt;{%0, %1} -&gt; tensor&lt;?x?xf32, #encoding&gt;{%0, %1}
    %7 = flow.tensor.encode %5 : tensor&lt;?x?xf32&gt;{%3, %4} -&gt; tensor&lt;?x?xf32, #encoding1&gt;{%3, %4}
    %8 = flow.dispatch @matmul_f32f32f32_dispatch_0::@matmul_f32f32f32_dispatch_0_matmul_DxDxD_f32[%0, %1, %3, %4](%6, %7, %0, %1, %3, %4) : (tensor&lt;?x?xf32, #encoding&gt;{%0, %1}, tensor&lt;?x?xf32, #encoding1&gt;{%3, %4}, index, index, index, index) -&gt; tensor&lt;?x?xf32&gt;{%0, %4}
    %9 = hal.tensor.export %8 &quot;output0&quot; : tensor&lt;?x?xf32&gt;{%0, %4} -&gt; !hal.buffer_view
    util.return %9 : !hal.buffer_view
  }
}
</code></pre></div></td></tr></table></div>

</details>
<!-- markdownlint-restore -->

<!-- markdownlint-disable -->
<details><summary>IR dump after the pass</summary>

<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span></pre></div></td><td class="code"><div><pre><span></span><code>#executable_target_rocm_hsaco_fb = #hal.executable.target&lt;&quot;rocm&quot;, &quot;rocm-hsaco-fb&quot;, {abi = &quot;hip&quot;, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver&lt;&gt;, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module&lt;&quot;iree_default_tuning_spec_gfx942.mlir&quot;&gt;, iree_codegen.target_info = #iree_gpu.target&lt;arch = &quot;gfx942&quot;, features = &quot;&quot;, wgp = &lt;compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [&lt;MFMA_F32_16x16x16_BF16&gt;, &lt;MFMA_F32_32x32x8_BF16&gt;, &lt;MFMA_F32_16x16x32_F8E5M2FNUZ&gt;, &lt;MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ&gt;, &lt;MFMA_F32_16x16x32_F8E4M3FNUZ&gt;, &lt;MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ&gt;, &lt;MFMA_F32_32x32x16_F8E5M2FNUZ&gt;, &lt;MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ&gt;, &lt;MFMA_F32_32x32x16_F8E4M3FNUZ&gt;, &lt;MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ&gt;, &lt;MFMA_I32_16x16x32_I8&gt;, &lt;MFMA_I32_32x32x16_I8&gt;, &lt;MFMA_F64_16x16x4_F64&gt;, &lt;MFMA_F32_16x16x4_F32&gt;, &lt;MFMA_F32_16x16x16_F16&gt;, &lt;MFMA_F32_32x32x8_F16&gt;], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384&gt;&gt;, ukernels = &quot;none&quot;}&gt;
#map = affine_map&lt;(d0, d1, d2) -&gt; (d0, d2)&gt;
#map1 = affine_map&lt;(d0, d1, d2) -&gt; (d2, d1)&gt;
#map2 = affine_map&lt;(d0, d1, d2) -&gt; (d0, d1)&gt;
#device_target_hip = #hal.device.target&lt;&quot;hip&quot;, [#executable_target_rocm_hsaco_fb]&gt; : !hal.device
#encoding = #iree_encoding.encoding&lt;operand_index = 0 : index, op_type =  matmul, element_types = [f32, f32, f32], user_indexing_maps = [#map, #map1, #map2], iteration_sizes = [?, ?, ?]&gt;
#encoding1 = #iree_encoding.encoding&lt;operand_index = 1 : index, op_type =  matmul, element_types = [f32, f32, f32], user_indexing_maps = [#map, #map1, #map2], iteration_sizes = [?, ?, ?]&gt;
#encoding2 = #iree_encoding.encoding&lt;operand_index = 2 : index, op_type =  matmul, element_types = [f32, f32, f32], user_indexing_maps = [#map, #map1, #map2], iteration_sizes = [?, ?, ?]&gt;
module attributes {stream.affinity.default = #hal.device.affinity&lt;@__device_0&gt;} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @matmul_f32f32f32_dispatch_0 {
    stream.executable.export public @matmul_f32f32f32_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index, %arg2: index, %arg3: index) -&gt; (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice(%arg0, %arg1, %arg2, %arg3)
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_f32f32f32_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: index, %arg3: index, %arg4: index, %arg5: index, %arg6: !stream.binding) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = iree_tensor_ext.dispatch.workload.ordinal %arg2, 0 : index
        %1 = iree_tensor_ext.dispatch.workload.ordinal %arg3, 1 : index
        %2 = iree_tensor_ext.dispatch.workload.ordinal %arg4, 2 : index
        %3 = iree_tensor_ext.dispatch.workload.ordinal %arg5, 3 : index
        %4 = stream.binding.subspan %arg0[%c0] : !stream.binding -&gt; !iree_tensor_ext.dispatch.tensor&lt;readonly:tensor&lt;?x?xf32, #encoding&gt;&gt;{%0, %1}
        %5 = stream.binding.subspan %arg1[%c0] : !stream.binding -&gt; !iree_tensor_ext.dispatch.tensor&lt;readonly:tensor&lt;?x?xf32, #encoding1&gt;&gt;{%2, %3}
        %6 = stream.binding.subspan %arg6[%c0] : !stream.binding -&gt; !iree_tensor_ext.dispatch.tensor&lt;writeonly:tensor&lt;?x?xf32&gt;&gt;{%0, %3}
        %7 = iree_tensor_ext.dispatch.tensor.load %4, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor&lt;readonly:tensor&lt;?x?xf32, #encoding&gt;&gt;{%0, %1} -&gt; tensor&lt;?x?xf32, #encoding&gt;
        %8 = iree_tensor_ext.dispatch.tensor.load %5, offsets = [0, 0], sizes = [%2, %3], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor&lt;readonly:tensor&lt;?x?xf32, #encoding1&gt;&gt;{%2, %3} -&gt; tensor&lt;?x?xf32, #encoding1&gt;
        %9 = tensor.empty(%0, %3) : tensor&lt;?x?xf32, #encoding2&gt;
        %10 = linalg.fill ins(%cst : f32) outs(%9 : tensor&lt;?x?xf32, #encoding2&gt;) -&gt; tensor&lt;?x?xf32, #encoding2&gt;
        %11 = linalg.matmul ins(%7, %8 : tensor&lt;?x?xf32, #encoding&gt;, tensor&lt;?x?xf32, #encoding1&gt;) outs(%10 : tensor&lt;?x?xf32, #encoding2&gt;) -&gt; tensor&lt;?x?xf32, #encoding2&gt;
        %12 = iree_encoding.unset_encoding %11 : tensor&lt;?x?xf32, #encoding2&gt; -&gt; tensor&lt;?x?xf32&gt;{%0, %3}
        iree_tensor_ext.dispatch.tensor.store %12, %6, offsets = [0, 0], sizes = [%0, %3], strides = [1, 1] : tensor&lt;?x?xf32&gt; -&gt; !iree_tensor_ext.dispatch.tensor&lt;writeonly:tensor&lt;?x?xf32&gt;&gt;{%0, %3}
        return
      }
    }
  }
  util.func public @matmul_f32f32f32(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -&gt; !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = &quot;sync func @matmul_f32f32f32(%input0: tensor&lt;?x?xf32&gt;, %input1: tensor&lt;?x?xf32&gt;) -&gt; (%output0: tensor&lt;?x?xf32&gt;)&quot;}} {
    %0 = hal.buffer_view.dim&lt;%arg0 : !hal.buffer_view&gt;[0] : index
    %1 = hal.buffer_view.dim&lt;%arg0 : !hal.buffer_view&gt;[1] : index
    %element_type_f32 = hal.element_type&lt;f32&gt; : i32
    %dense_row_major = hal.encoding_type&lt;dense_row_major&gt; : i32
    hal.buffer_view.assert&lt;%arg0 : !hal.buffer_view&gt; message(&quot;input0&quot;) shape([%0, %1]) type(%element_type_f32) encoding(%dense_row_major)
    %2 = stream.tensor.sizeof on(#hal.device.affinity&lt;@__device_0&gt;) tensor&lt;?x?xf32&gt;{%0, %1} : index
    %3 = stream.tensor.import on(#hal.device.affinity&lt;@__device_0&gt;) %arg0 : !hal.buffer_view -&gt; tensor&lt;?x?xf32&gt;{%0, %1} in !stream.resource&lt;external&gt;{%2}
    %4 = stream.async.transfer %3 : !stream.resource&lt;external&gt;{%2} from(#hal.device.affinity&lt;@__device_0&gt;) -&gt; to(#hal.device.affinity&lt;@__device_0&gt;) !stream.resource&lt;*&gt;{%2}
    %5 = hal.buffer_view.dim&lt;%arg1 : !hal.buffer_view&gt;[0] : index
    %6 = hal.buffer_view.dim&lt;%arg1 : !hal.buffer_view&gt;[1] : index
    %element_type_f32_0 = hal.element_type&lt;f32&gt; : i32
    %dense_row_major_1 = hal.encoding_type&lt;dense_row_major&gt; : i32
    hal.buffer_view.assert&lt;%arg1 : !hal.buffer_view&gt; message(&quot;input1&quot;) shape([%5, %6]) type(%element_type_f32_0) encoding(%dense_row_major_1)
    %7 = stream.tensor.sizeof on(#hal.device.affinity&lt;@__device_0&gt;) tensor&lt;?x?xf32&gt;{%5, %6} : index
    %8 = stream.tensor.import on(#hal.device.affinity&lt;@__device_0&gt;) %arg1 : !hal.buffer_view -&gt; tensor&lt;?x?xf32&gt;{%5, %6} in !stream.resource&lt;external&gt;{%7}
    %9 = stream.async.transfer %8 : !stream.resource&lt;external&gt;{%7} from(#hal.device.affinity&lt;@__device_0&gt;) -&gt; to(#hal.device.affinity&lt;@__device_0&gt;) !stream.resource&lt;*&gt;{%7}
    %10 = stream.tensor.sizeof on(#hal.device.affinity&lt;@__device_0&gt;) tensor&lt;?x?xf32, #encoding&gt;{%0, %1} : index
    %11 = stream.tensor.encode on(#hal.device.affinity&lt;@__device_0&gt;) %4 : tensor&lt;?x?xf32&gt;{%0, %1} in !stream.resource&lt;*&gt;{%2} -&gt; tensor&lt;?x?xf32, #encoding&gt;{%0, %1} in !stream.resource&lt;*&gt;{%10}
    %12 = stream.tensor.sizeof on(#hal.device.affinity&lt;@__device_0&gt;) tensor&lt;?x?xf32, #encoding1&gt;{%5, %6} : index
    %13 = stream.tensor.encode on(#hal.device.affinity&lt;@__device_0&gt;) %9 : tensor&lt;?x?xf32&gt;{%5, %6} in !stream.resource&lt;*&gt;{%7} -&gt; tensor&lt;?x?xf32, #encoding1&gt;{%5, %6} in !stream.resource&lt;*&gt;{%12}
    %14 = stream.tensor.sizeof on(#hal.device.affinity&lt;@__device_0&gt;) tensor&lt;?x?xf32&gt;{%0, %6} : index
    %15 = stream.tensor.dispatch on(#hal.device.affinity&lt;@__device_0&gt;) @matmul_f32f32f32_dispatch_0::@matmul_f32f32f32_dispatch_0_matmul_DxDxD_f32[%0, %1, %5, %6](%11, %13, %0, %1, %5, %6) : (tensor&lt;?x?xf32, #encoding&gt;{%0, %1} in !stream.resource&lt;*&gt;{%10}, tensor&lt;?x?xf32, #encoding1&gt;{%5, %6} in !stream.resource&lt;*&gt;{%12}, index, index, index, index) -&gt; tensor&lt;?x?xf32&gt;{%0, %6} in !stream.resource&lt;*&gt;{%14}
    %16 = stream.async.transfer %15 : !stream.resource&lt;*&gt;{%14} from(#hal.device.affinity&lt;@__device_0&gt;) -&gt; to(#hal.device.affinity&lt;@__device_0&gt;) !stream.resource&lt;external&gt;{%14}
    %17 = stream.tensor.export on(#hal.device.affinity&lt;@__device_0&gt;) %16 : tensor&lt;?x?xf32&gt;{%0, %6} in !stream.resource&lt;external&gt;{%14} -&gt; !hal.buffer_view
    util.return %17 : !hal.buffer_view
  }
}
</code></pre></div></td></tr></table></div>

</details>
<!-- markdownlint-restore -->

<h3 id="specializeencodingspass-stream">SpecializeEncodingsPass (Stream)<a class="headerlink" href="#specializeencodingspass-stream" title="Permanent link">link</a></h3>
<p>The pass resolves the layouts based on Stream affinity analysis. It updates the
encodings of all the Stream tensor ops with resolved layouts, and updates
bindings with resolved layouts.</p>
<p>The key is using <a href="https://github.com/iree-org/iree/blob/main/compiler/src/iree/compiler/Dialect/Stream/IR/StreamInterfaces.h">AffinityAnalysisDialectInterface</a>
to <a href="https://github.com/iree-org/iree/blob/e6fb1e180438c4f78a1ea2bafd9a653fbe7a064b/compiler/src/iree/compiler/Dialect/HAL/IR/HALDialect.cpp#L122-L180">retrieve the encoding
resolver</a>.</p>
<p>In this example, the <code>#iree_gpu.gpu_encoding_resolver&lt;&gt;</code> is attached to the
executable target configuration; it is used to resolve the layouts in the pass.
There are two major interface methods used in the specialization:</p>
<ul>
<li><code>Attribute cloneWithSimplifiedConfig(DictionaryAttr config)</code>: Attributes are
  immutable in MLIR concept; we don't want to duplicate the configs in IR. Thus,
  the encoding resolver does not have any configs; IREE uses the interface
  method to propagate needed information for the specialization.</li>
<li><code>Attribute getLayout(RankedTensorType type)</code>: Returns the serialized encoding
  layout for the given <code>type</code>.</li>
</ul>
<p>The implementation can be found
<a href="https://github.com/iree-org/iree/blob/e6fb1e180438c4f78a1ea2bafd9a653fbe7a064b/compiler/src/iree/compiler/Codegen/ExternalInterfaces/GPUEncodingExternalModels.cpp#L397-L421">here</a>.</p>
<p>The pass iterates all the stream tensor ops and replaces the verbose encodings
with serialized encodings using <code>getLayout</code> method. In the example,
that is dictionary attribute representing the <a href="https://github.com/iree-org/iree/blob/e6fb1e180438c4f78a1ea2bafd9a653fbe7a064b/compiler/src/iree/compiler/Codegen/Dialect/Codegen/IR/IREECodegenTypes.h#L87-L99">MaterializeEncodingInfo
struct</a>.
For example:</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span></pre></div></td><td class="code"><div><pre><span></span><code>#map0 = affine_map&lt;(m, n, k) -&gt; (m, k)&gt;
#map1 = affine_map&lt;(m, n, k) -&gt; (k, n)&gt;
#map2 = affine_map&lt;(m, n, k) -&gt; (m, n)&gt;
#executable_target_vmvx_bytecode_fb = #hal.executable.target&lt;&quot;vmvx&quot;, &quot;vmvx-bytecode-fb&quot;, {iree.encoding.resolver = #iree_cpu.vmvx_encoding_resolver&lt;&gt;}&gt;
#executable_target_x86_64 = #hal.executable.target&lt;&quot;llvm-cpu&quot;, &quot;xyz&quot;, {iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver&lt;&gt;, target_triple=&quot;x86_64-xyz-xyz&quot;, cpu_features=&quot;+avx512f&quot;}&gt;
#executable_target_aarch64 = #hal.executable.target&lt;&quot;llvm-cpu&quot;, &quot;xyz&quot;, {iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver&lt;&gt;, target_triple=&quot;aarch64-xyz-xyz&quot;, cpu_features=&quot;+sve&quot;}&gt;
#device_target_local_0_ = #hal.device.target&lt;&quot;local&quot;, {ordinal = 0 : index}, [#executable_target_vmvx_bytecode_fb]&gt; : !hal.device
#device_target_local_1_ = #hal.device.target&lt;&quot;local&quot;, {ordinal = 1 : index}, [#executable_target_x86_64]&gt; : !hal.device
#device_target_local_2_ = #hal.device.target&lt;&quot;local&quot;, {ordinal = 2 : index}, [#executable_target_aarch64]&gt; : !hal.device
<span class="hll">#encoding = #iree_encoding.encoding&lt;
</span><span class="hll">  operand_index = 0 : index,
</span><span class="hll">  op_type =  matmul,
</span><span class="hll">  element_types = [f32, f32, f32],
</span><span class="hll">  user_indexing_maps = [#map0, #map1, #map2]
</span><span class="hll">&gt;
</span>
util.global private @device_a = #device_target_local_0_
util.global private @device_b = #device_target_local_1_
util.global private @device_c = #device_target_local_2_
util.func public @tensor_sizeof(%d0: index, %d1: index) -&gt; (index, index, index) {
  %size0 = stream.tensor.sizeof on(#hal.device.affinity&lt;@device_a&gt;) tensor&lt;?x?xf32, #encoding&gt;{%d0, %d1} : index
  %size1 = stream.tensor.sizeof on(#hal.device.affinity&lt;@device_b&gt;) tensor&lt;?x?xf32, #encoding&gt;{%d0, %d1} : index
  %size2 = stream.tensor.sizeof on(#hal.device.affinity&lt;@device_c&gt;) tensor&lt;?x?xf32, #encoding&gt;{%d0, %d1} : index
  util.return %size0, %size1, %size2 : index, index, index
}
<span class="hll">// CHECK-DAG:   #[[$ENCODING0:.+]] = #iree_encoding.layout&lt;[#iree_cpu.vmvx_encoding_resolver{{.+}}encoding_info = {innerDimsPos = [{{.+}}], innerTileSizes = [{{.+}}], outerDimsPerm = [{{.+}}]}
</span><span class="hll">// CHECK-DAG:   #[[$ENCODING1:.+]] = #iree_encoding.layout&lt;[#iree_cpu.cpu_encoding_resolver{{.+}}encoding_info = {innerDimsPos = [{{.+}}], innerTileSizes = [{{.+}}], outerDimsPerm = [{{.+}}]}
</span>// CHECK-LABEL: util.func public @tensor_sizeof
// CHECK:         %[[D0_RES:.+]] = stream.tensor.sizeof {{.+}} tensor&lt;?x?xf32, #[[$ENCODING0]]&gt;
// CHECK:         %[[D1_RES:.+]] = stream.tensor.sizeof {{.+}} tensor&lt;?x?xf32, #[[$ENCODING1]]&gt;
// CHECK:         return %[[D0_RES]], %[[D1_RES]]
</code></pre></div></td></tr></table></div>
<p>On the executable side, the encodings attached on stream.bindings are also
updated with resolved layouts, which is consistent with the changes in stream
tensor ops. The encodings on other operations (e.g., set_encoding) will be
materialized later on in CodeGen pipeline. For example:</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span></pre></div></td><td class="code"><div><pre><span></span><code>#pipeline_layout = #hal.pipeline.layout&lt;bindings = [
  #hal.pipeline.binding&lt;storage_buffer&gt;,
  #hal.pipeline.binding&lt;storage_buffer&gt;
]&gt;
#executable_target = #hal.executable.target&lt;&quot;llvm-cpu&quot;, &quot;xyz&quot;, {target_triple = &quot;x86_64-xyz-xyz&quot;, cpu_features = &quot;+avx512f&quot;, iree.encoding.resolver = #iree_cpu.cpu_encoding_resolver&lt;&gt;}&gt;
#encoding = #iree_encoding.encoding&lt;
<span class="hll">  operand_index = 0 : index,
</span><span class="hll">  op_type =  matmul,
</span><span class="hll">  element_types = [f32, f32, f32],
</span><span class="hll">  layouts = [#iree_cpu.cpu_encoding_layout&lt;configuration = {
</span><span class="hll">    encoding_info = {innerDimsPos = [0, 1],
</span><span class="hll">                     innerTileSizes = [1, 1],
</span><span class="hll">                     outerDimsPerm = [0, 1]}
</span><span class="hll">  }&gt;]&gt;
</span>#map = affine_map&lt;(d0, d1, d2) -&gt; (d0, d2)&gt;
#map1 = affine_map&lt;(d0, d1, d2) -&gt; (d2, d1)&gt;
#map2 = affine_map&lt;(d0, d1, d2) -&gt; (d0, d1)&gt;
<span class="hll">#encoding1 = #iree_encoding.encoding&lt;
</span><span class="hll">  operand_index = 0 : index,
</span><span class="hll">  op_type =  matmul,
</span><span class="hll">  element_types = [f32, f32, f32],
</span><span class="hll">  user_indexing_maps = [#map, #map1, #map2],
</span><span class="hll">  round_dims_to = array&lt;i64: 1, 32, 32&gt;&gt;
</span>func.func @set_encoding_LHS_with_layout() attributes {
  hal.executable.target = #executable_target
} {
  %c0 = arith.constant 0 : index
  %0 = hal.interface.binding.subspan layout(#pipeline_layout) binding(0) alignment(64) offset(%c0) flags(&quot;ReadOnly|Indirect&quot;) : !flow.dispatch.tensor&lt;readonly:tensor&lt;1x256xf32&gt;&gt;
<span class="hll">  %1 = hal.interface.binding.subspan layout(#pipeline_layout) binding(1) alignment(64) offset(%c0) flags(Indirect)
</span><span class="hll">    : !flow.dispatch.tensor&lt;writeonly:tensor&lt;1x256xf32, #encoding&gt;&gt;
</span>  %2 = flow.dispatch.tensor.load %0, offsets = [0, 0], sizes = [1, 256], strides = [1, 1] : !flow.dispatch.tensor&lt;readonly:tensor&lt;1x256xf32&gt;&gt; -&gt; tensor&lt;1x256xf32&gt;
<span class="hll">  %3 = iree_encoding.set_encoding %2
</span><span class="hll">    : tensor&lt;1x256xf32&gt; -&gt; tensor&lt;1x256xf32, #encoding1&gt;
</span>  flow.dispatch.tensor.store %3, %1, offsets = [0, 0], sizes = [1, 256], strides = [1, 1] : tensor&lt;1x256xf32, #encoding1&gt; -&gt; !flow.dispatch.tensor&lt;writeonly:tensor&lt;1x256xf32, #encoding&gt;&gt;
  return
}
</code></pre></div></td></tr></table></div>
<!-- markdownlint-disable -->
<details><summary>IR dump after the pass</summary>

<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span>
<span class="normal">86</span>
<span class="normal">87</span>
<span class="normal">88</span>
<span class="normal">89</span>
<span class="normal">90</span>
<span class="normal">91</span>
<span class="normal">92</span>
<span class="normal">93</span>
<span class="normal">94</span>
<span class="normal">95</span>
<span class="normal">96</span>
<span class="normal">97</span>
<span class="normal">98</span>
<span class="normal">99</span></pre></div></td><td class="code"><div><pre><span></span><code>#encoding = #iree_encoding.layout&lt;[
  #iree_gpu.gpu_encoding_resolver&lt;configuration = {encoding_info = {
    innerDimsPos = [0, 1], innerTileSizes = [128, 16], outerDimsPerm = [0, 1],
    swizzle = {expandShape = [[[&quot;CrossThread&quot;, 4 : i16], [&quot;CrossIntrinsic&quot;, 8 : i16], [&quot;CrossThread&quot;, 4 : i16]], [[&quot;CrossIntrinsic&quot;, 4 : i16], [&quot;CrossThread&quot;, 4 : i16]]],
               permutation = [1, 4, 0, 2, 3]}}}&gt;
]&gt;
#encoding1 = #iree_encoding.layout&lt;[
  #iree_gpu.gpu_encoding_resolver&lt;configuration = {encoding_info = {
    innerDimsPos = [1, 0], innerTileSizes = [128, 16], outerDimsPerm = [1, 0],
    swizzle = {expandShape = [[[&quot;CrossThread&quot;, 4 : i16], [&quot;CrossThread&quot;, 16 : i16], [&quot;CrossIntrinsic&quot;, 2 : i16]], [[&quot;CrossIntrinsic&quot;, 4 : i16], [&quot;CrossThread&quot;, 4 : i16]]],
               permutation = [0, 2, 4, 1, 3]}}}&gt;
]&gt;
#executable_target_rocm_hsaco_fb = #hal.executable.target&lt;&quot;rocm&quot;, &quot;rocm-hsaco-fb&quot;, {abi = &quot;hip&quot;, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver&lt;&gt;, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module&lt;&quot;iree_default_tuning_spec_gfx942.mlir&quot;&gt;, iree_codegen.target_info = #iree_gpu.target&lt;arch = &quot;gfx942&quot;, features = &quot;&quot;, wgp = &lt;compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [&lt;MFMA_F32_16x16x16_BF16&gt;, &lt;MFMA_F32_32x32x8_BF16&gt;, &lt;MFMA_F32_16x16x32_F8E5M2FNUZ&gt;, &lt;MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ&gt;, &lt;MFMA_F32_16x16x32_F8E4M3FNUZ&gt;, &lt;MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ&gt;, &lt;MFMA_F32_32x32x16_F8E5M2FNUZ&gt;, &lt;MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ&gt;, &lt;MFMA_F32_32x32x16_F8E4M3FNUZ&gt;, &lt;MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ&gt;, &lt;MFMA_I32_16x16x32_I8&gt;, &lt;MFMA_I32_32x32x16_I8&gt;, &lt;MFMA_F64_16x16x4_F64&gt;, &lt;MFMA_F32_16x16x4_F32&gt;, &lt;MFMA_F32_16x16x16_F16&gt;, &lt;MFMA_F32_32x32x8_F16&gt;], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384&gt;&gt;, ukernels = &quot;none&quot;}&gt;
#map = affine_map&lt;(d0, d1, d2) -&gt; (d0, d2)&gt;
#map1 = affine_map&lt;(d0, d1, d2) -&gt; (d2, d1)&gt;
#map2 = affine_map&lt;(d0, d1, d2) -&gt; (d0, d1)&gt;
#device_target_hip = #hal.device.target&lt;&quot;hip&quot;, [#executable_target_rocm_hsaco_fb]&gt; : !hal.device
#encoding2 = #iree_encoding.encoding&lt;operand_index = 0 : index, op_type =  matmul,
                                     element_types = [f32, f32, f32],
                                     user_indexing_maps = [#map, #map1, #map2],
                                     iteration_sizes = [?, ?, ?]&gt;
#encoding3 = #iree_encoding.encoding&lt;operand_index = 1 : index, op_type =  matmul,
                                     element_types = [f32, f32, f32],
                                     user_indexing_maps = [#map, #map1, #map2],
                                     iteration_sizes = [?, ?, ?]&gt;
#encoding4 = #iree_encoding.encoding&lt;operand_index = 2 : index, op_type =  matmul,
                                     element_types = [f32, f32, f32],
                                     user_indexing_maps = [#map, #map1, #map2],
                                     iteration_sizes = [?, ?, ?]&gt;
module attributes {stream.affinity.default = #hal.device.affinity&lt;@__device_0&gt;} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @matmul_f32f32f32_dispatch_0 {
    stream.executable.export public @matmul_f32f32f32_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index, %arg2: index, %arg3: index) -&gt; (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice(%arg0, %arg1, %arg2, %arg3)
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_f32f32f32_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: index, %arg3: index, %arg4: index, %arg5: index, %arg6: !stream.binding) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = iree_tensor_ext.dispatch.workload.ordinal %arg2, 0 : index
        %1 = iree_tensor_ext.dispatch.workload.ordinal %arg3, 1 : index
        %2 = iree_tensor_ext.dispatch.workload.ordinal %arg4, 2 : index
        %3 = iree_tensor_ext.dispatch.workload.ordinal %arg5, 3 : index
        %4 = stream.binding.subspan %arg0[%c0] : !stream.binding
          -&gt; !iree_tensor_ext.dispatch.tensor&lt;readonly:tensor&lt;?x?xf32, #encoding&gt;&gt;{%0, %1}
        %5 = stream.binding.subspan %arg1[%c0] : !stream.binding
          -&gt; !iree_tensor_ext.dispatch.tensor&lt;readonly:tensor&lt;?x?xf32, #encoding1&gt;&gt;{%2, %3}
        %6 = stream.binding.subspan %arg6[%c0] : !stream.binding
          -&gt; !iree_tensor_ext.dispatch.tensor&lt;writeonly:tensor&lt;?x?xf32&gt;&gt;{%0, %3}
        %7 = iree_tensor_ext.dispatch.tensor.load %4, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1]
          : !iree_tensor_ext.dispatch.tensor&lt;readonly:tensor&lt;?x?xf32, #encoding&gt;&gt;{%0, %1} -&gt; tensor&lt;?x?xf32, #encoding2&gt;
        %8 = iree_tensor_ext.dispatch.tensor.load %5, offsets = [0, 0], sizes = [%2, %3], strides = [1, 1]
          : !iree_tensor_ext.dispatch.tensor&lt;readonly:tensor&lt;?x?xf32, #encoding1&gt;&gt;{%2, %3} -&gt; tensor&lt;?x?xf32, #encoding3&gt;
        %9 = tensor.empty(%0, %3) : tensor&lt;?x?xf32, #encoding4&gt;
        %10 = linalg.fill ins(%cst : f32) outs(%9 : tensor&lt;?x?xf32, #encoding4&gt;) -&gt; tensor&lt;?x?xf32, #encoding4&gt;
        %11 = linalg.matmul
          ins(%7, %8 : tensor&lt;?x?xf32, #encoding2&gt;, tensor&lt;?x?xf32, #encoding3&gt;)
          outs(%10 : tensor&lt;?x?xf32, #encoding4&gt;) -&gt; tensor&lt;?x?xf32, #encoding4&gt;
        %12 = iree_encoding.unset_encoding %11 : tensor&lt;?x?xf32, #encoding4&gt; -&gt; tensor&lt;?x?xf32&gt;{%0, %3}
        iree_tensor_ext.dispatch.tensor.store %12, %6, offsets = [0, 0], sizes = [%0, %3], strides = [1, 1] : tensor&lt;?x?xf32&gt; -&gt; !iree_tensor_ext.dispatch.tensor&lt;writeonly:tensor&lt;?x?xf32&gt;&gt;{%0, %3}
        return
      }
    }
  }
  util.func public @matmul_f32f32f32(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -&gt; !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = &quot;sync func @matmul_f32f32f32(%input0: tensor&lt;?x?xf32&gt;, %input1: tensor&lt;?x?xf32&gt;) -&gt; (%output0: tensor&lt;?x?xf32&gt;)&quot;}} {
    %0 = hal.buffer_view.dim&lt;%arg0 : !hal.buffer_view&gt;[0] : index
    %1 = hal.buffer_view.dim&lt;%arg0 : !hal.buffer_view&gt;[1] : index
    %element_type_f32 = hal.element_type&lt;f32&gt; : i32
    %dense_row_major = hal.encoding_type&lt;dense_row_major&gt; : i32
    hal.buffer_view.assert&lt;%arg0 : !hal.buffer_view&gt; message(&quot;input0&quot;) shape([%0, %1]) type(%element_type_f32) encoding(%dense_row_major)
    %2 = stream.tensor.sizeof on(#hal.device.affinity&lt;@__device_0&gt;) tensor&lt;?x?xf32&gt;{%0, %1} : index
    %3 = stream.tensor.import on(#hal.device.affinity&lt;@__device_0&gt;) %arg0 : !hal.buffer_view -&gt; tensor&lt;?x?xf32&gt;{%0, %1} in !stream.resource&lt;external&gt;{%2}
    %4 = stream.async.transfer %3 : !stream.resource&lt;external&gt;{%2} from(#hal.device.affinity&lt;@__device_0&gt;) -&gt; to(#hal.device.affinity&lt;@__device_0&gt;) !stream.resource&lt;*&gt;{%2}
    %5 = hal.buffer_view.dim&lt;%arg1 : !hal.buffer_view&gt;[0] : index
    %6 = hal.buffer_view.dim&lt;%arg1 : !hal.buffer_view&gt;[1] : index
    hal.buffer_view.assert&lt;%arg1 : !hal.buffer_view&gt; message(&quot;input1&quot;) shape([%5, %6]) type(%element_type_f32) encoding(%dense_row_major)
    %7 = stream.tensor.sizeof on(#hal.device.affinity&lt;@__device_0&gt;) tensor&lt;?x?xf32&gt;{%5, %6} : index
    %8 = stream.tensor.import on(#hal.device.affinity&lt;@__device_0&gt;) %arg1 : !hal.buffer_view -&gt; tensor&lt;?x?xf32&gt;{%5, %6} in !stream.resource&lt;external&gt;{%7}
    %9 = stream.async.transfer %8 : !stream.resource&lt;external&gt;{%7} from(#hal.device.affinity&lt;@__device_0&gt;) -&gt; to(#hal.device.affinity&lt;@__device_0&gt;) !stream.resource&lt;*&gt;{%7}
    %10 = stream.tensor.sizeof on(#hal.device.affinity&lt;@__device_0&gt;)
      tensor&lt;?x?xf32, #encoding&gt;{%0, %1} : index
    %11 = stream.tensor.encode on(#hal.device.affinity&lt;@__device_0&gt;) %4
      : tensor&lt;?x?xf32&gt;{%0, %1} in !stream.resource&lt;*&gt;{%2} -&gt; tensor&lt;?x?xf32, #encoding&gt;{%0, %1} in !stream.resource&lt;*&gt;{%10}
    %12 = stream.tensor.sizeof on(#hal.device.affinity&lt;@__device_0&gt;)
      tensor&lt;?x?xf32, #encoding1&gt;{%5, %6} : index
    %13 = stream.tensor.encode on(#hal.device.affinity&lt;@__device_0&gt;) %9
      : tensor&lt;?x?xf32&gt;{%5, %6} in !stream.resource&lt;*&gt;{%7} -&gt; tensor&lt;?x?xf32, #encoding1&gt;{%5, %6} in !stream.resource&lt;*&gt;{%12}
    %14 = stream.tensor.sizeof on(#hal.device.affinity&lt;@__device_0&gt;)
      tensor&lt;?x?xf32&gt;{%0, %6} : index
    %15 = stream.tensor.dispatch on(#hal.device.affinity&lt;@__device_0&gt;)
      @matmul_f32f32f32_dispatch_0::@matmul_f32f32f32_dispatch_0_matmul_DxDxD_f32[%0, %1, %5, %6](%11, %13, %0, %1, %5, %6)
      : (tensor&lt;?x?xf32, #encoding&gt;{%0, %1} in !stream.resource&lt;*&gt;{%10}, tensor&lt;?x?xf32, #encoding1&gt;{%5, %6} in !stream.resource&lt;*&gt;{%12}, index, index, index, index)
      -&gt; tensor&lt;?x?xf32&gt;{%0, %6} in !stream.resource&lt;*&gt;{%14}
    %16 = stream.async.transfer %15 : !stream.resource&lt;*&gt;{%14} from(#hal.device.affinity&lt;@__device_0&gt;) -&gt; to(#hal.device.affinity&lt;@__device_0&gt;) !stream.resource&lt;external&gt;{%14}
    %17 = stream.tensor.export on(#hal.device.affinity&lt;@__device_0&gt;) %16 : tensor&lt;?x?xf32&gt;{%0, %6} in !stream.resource&lt;external&gt;{%14} -&gt; !hal.buffer_view
    util.return %17 : !hal.buffer_view
  }
}
</code></pre></div></td></tr></table></div>

</details>
<!-- markdownlint-restore -->

<details><summary>Deep dive into multi-device cases</summary>

IREE deduplicates executables after it outlines dispatches to executables. It is
very reasonable in a program because we do not want to generate duplicated
artifacts. However, there are issues when multi-device and encodings are
involved.

<br/>

Take a look at the below snippet. There is an executable that set encodings on
the source tensor, and there are two dispatch ops. One launch the kernel on
`device_a`, and the other launch the kernel on `device_b`. It can produce wrong
codegen artifacts when bindings types are encoded (i.e., the tensor type has an
encoding attribute). Because they can result in different layouts. It is
confusing what the input layouts for the executable because there are two
possibilities. In this case, we have to duplicate the executable with updated
encoding, and modify the dispatch to launch proper executable based on resolved
encoding layouts.

<!-- markdownlint-disable -->
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span></pre></div></td><td class="code"><div><pre><span></span><code>stream.executable private @ex {
  stream.executable.export public @set_encoding
  builtin.module {
    func.func @set_encoding(%arg0: !stream.binding, %arg1: index, %arg2: index, %arg3: !stream.binding) {
      %c0 = arith.constant 0 : index
      %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
      %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
      %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -&gt; !flow.dispatch.tensor&lt;readonly:tensor&lt;?x?xf32&gt;&gt;{%0, %1}
      %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -&gt; !flow.dispatch.tensor&lt;writeonly:tensor&lt;?x?xf32, #encoding&gt;&gt;{%0, %1}
      %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor&lt;readonly:tensor&lt;?x?xf32&gt;&gt;{%0, %1} -&gt; tensor&lt;?x?xf32&gt;
      %5 = iree_encoding.set_encoding %4 : tensor&lt;?x?xf32&gt; -&gt; tensor&lt;?x?xf32, #encoding&gt;
      flow.dispatch.tensor.store %5, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : tensor&lt;?x?xf32, #encoding&gt; -&gt; !flow.dispatch.tensor&lt;writeonly:tensor&lt;?x?xf32, #encoding&gt;&gt;{%0, %1}
      return
    }
  }
}
util.func public @multi_device_set_encoding() {
<span class="hll">  %1 = stream.tensor.dispatch on(#hal.device.affinity&lt;@device_a&gt;) @ex::@set_encoding(%0, %N, %K) : (tensor&lt;?x?xf32&gt;{%N, %K} in !stream.resource&lt;*&gt;{%c16}, index, index) -&gt; (tensor&lt;?x?xf32, #encoding&gt;{%N, %K} in !stream.resource&lt;*&gt;{%c16})
</span><span class="hll">  %4 = stream.tensor.dispatch on(#hal.device.affinity&lt;@device_b&gt;) @ex::@set_encoding(%3, %N, %K) : (tensor&lt;?x?xf32&gt;{%N, %K} in !stream.resource&lt;*&gt;{%c16}, index, index) -&gt; (tensor&lt;?x?xf32, #encoding&gt;{%N, %K} in !stream.resource&lt;*&gt;{%c16})
</span>  util.return
}
</code></pre></div></td></tr></table></div>
<!-- markdownlint-restore -->

Thus, the SpecializeEncoding pass collects all the layout variants per
executable, duplicate the executables with updated encodings, and update the
dispatch op to launch the corresponding executable. See the below example.

<br/>

Note that the duplication does not only look at execution affinity, but also
look at the layouts for each input operands. Because the actual layout can vary
based on where the input operands come from.

<!-- markdownlint-disable -->
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="hll">#encoding = #iree_encoding.encoding&lt;
</span><span class="hll">  operand_index = 0 : index,
</span><span class="hll">  op_type =  matmul,
</span><span class="hll">  element_types = [f32, f32, f32],
</span><span class="hll">  layouts = [#iree_encoding.specialized_encoding&lt;123, tensor&lt;?x?xf32&gt;&gt;]
</span><span class="hll">&gt;
</span><span class="hll">#encoding1 = #iree_encoding.encoding&lt;
</span><span class="hll">  operand_index = 0 : index,
</span><span class="hll">  op_type =  matmul,
</span><span class="hll">  element_types = [f32, f32, f32],
</span><span class="hll">  layouts = [#iree_encoding.specialized_encoding&lt;456, tensor&lt;?x?xf32&gt;&gt;]
</span><span class="hll">&gt;
</span>// -------------------------------- //
// #encoding2 does not have layouts. //
// -------------------------------- //
<span class="hll">#encoding2 = #iree_encoding.encoding&lt;
</span><span class="hll">  operand_index = 0 : index,
</span><span class="hll">  op_type =  matmul,
</span><span class="hll">  element_types = [f32, f32, f32],
</span><span class="hll">  user_indexing_maps = [#map, #map1, #map2]
</span><span class="hll">&gt;
</span>stream.executable private @ex {
  stream.executable.export public @set_encoding
  builtin.module {
    func.func @set_encoding(%arg0: !stream.binding, %arg1: index, %arg2: index, %arg3: !stream.binding) {
      %c0 = arith.constant 0 : index
      %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
      %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
      %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -&gt; !flow.dispatch.tensor&lt;readonly:tensor&lt;?x?xf32&gt;&gt;{%0, %1}
      %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -&gt; !flow.dispatch.tensor&lt;writeonly:tensor&lt;?x?xf32, #encoding&gt;&gt;{%0, %1}
      %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor&lt;readonly:tensor&lt;?x?xf32&gt;&gt;{%0, %1} -&gt; tensor&lt;?x?xf32&gt;
      %5 = iree_encoding.set_encoding %4 : tensor&lt;?x?xf32&gt; -&gt; tensor&lt;?x?xf32, #encoding2&gt;
<span class="hll">      // --------------------------------------------------------------- //
</span><span class="hll">      // This is the key, which is a #encoding2 -&gt; #encoding conversion. //
</span><span class="hll">      // --------------------------------------------------------------- //
</span><span class="hll">      flow.dispatch.tensor.store %5, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1]
</span><span class="hll">        : tensor&lt;?x?xf32, #encoding2&gt;
</span><span class="hll">        -&gt; !flow.dispatch.tensor&lt;writeonly:tensor&lt;?x?xf32, #encoding&gt;&gt;{%0, %1}
</span>      return
    }
  }
}
stream.executable private @ex_dup0 {
  stream.executable.export public @set_encoding
  builtin.module {
    func.func @set_encoding(%arg0: !stream.binding, %arg1: index, %arg2: index, %arg3: !stream.binding) {
      %c0 = arith.constant 0 : index
      %0 = flow.dispatch.workload.ordinal %arg1, 0 : index
      %1 = flow.dispatch.workload.ordinal %arg2, 1 : index
      %2 = stream.binding.subspan %arg0[%c0] : !stream.binding -&gt; !flow.dispatch.tensor&lt;readonly:tensor&lt;?x?xf32&gt;&gt;{%0, %1}
      %3 = stream.binding.subspan %arg3[%c0] : !stream.binding -&gt; !flow.dispatch.tensor&lt;writeonly:tensor&lt;?x?xf32, #encoding1&gt;&gt;{%0, %1}
      %4 = flow.dispatch.tensor.load %2, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !flow.dispatch.tensor&lt;readonly:tensor&lt;?x?xf32&gt;&gt;{%0, %1} -&gt; tensor&lt;?x?xf32&gt;
      %5 = iree_encoding.set_encoding %4 : tensor&lt;?x?xf32&gt; -&gt; tensor&lt;?x?xf32, #encoding2&gt;
<span class="hll">      // --------------------------------------------------------------- //
</span><span class="hll">      // This is the key, which is a #encoding2 -&gt; #encoding1 conversion. //
</span><span class="hll">      // --------------------------------------------------------------- //
</span><span class="hll">      flow.dispatch.tensor.store %5, %3, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1]
</span><span class="hll">        : tensor&lt;?x?xf32, #encoding2&gt;
</span><span class="hll">        -&gt; !flow.dispatch.tensor&lt;writeonly:tensor&lt;?x?xf32, #encoding1&gt;&gt;{%0, %1}
</span>      return
    }
  }
}
util.func public @multi_device_set_encoding() {
<span class="hll">  // Launch @ex::@set_encoding executable, which is specialized for the dispatch op.
</span><span class="hll">  %1 = stream.tensor.dispatch on(#hal.device.affinity&lt;@device_a&gt;) @ex::@set_encoding(%0, %arg2, %arg3) : (tensor&lt;?x?xf32&gt;{%arg2, %arg3} in !stream.resource&lt;*&gt;{%c16}, index, index) -&gt; tensor&lt;?x?xf32, #encoding&gt;{%arg2, %arg3} in !stream.resource&lt;*&gt;{%c16}
</span><span class="hll">  // Launch @ex_dup0::@set_encoding executable, which is specialized for the dispatch op.
</span><span class="hll">  %4 = stream.tensor.dispatch on(#hal.device.affinity&lt;@device_b&gt;) @ex_dup0::@set_encoding(%3, %arg2, %arg3) : (tensor&lt;?x?xf32&gt;{%arg2, %arg3} in !stream.resource&lt;*&gt;{%c16}, index, index) -&gt; tensor&lt;?x?xf32, #encoding1&gt;{%arg2, %arg3} in !stream.resource&lt;*&gt;{%c16}
</span>  util.return
}
</code></pre></div></td></tr></table></div>
<!-- markdownlint-restore -->

For more examples, see the
<a href="https://github.com/iree-org/iree/blob/main/compiler/src/iree/compiler/Dialect/Stream/Transforms/test/specialize_encodings.mlir">
lit tests
</a>.

</details>

<h3 id="encodehosttensorspass-stream">EncodeHostTensorsPass (Stream)<a class="headerlink" href="#encodehosttensorspass-stream" title="Permanent link">link</a></h3>
<p>Later on, the <code>stream.tensor.sizeof</code> op is lowered to the storage buffer size
calculation. Since the new encoding attribute <a href="https://github.com/iree-org/iree/blob/e6fb1e180438c4f78a1ea2bafd9a653fbe7a064b/compiler/src/iree/compiler/Codegen/ExternalInterfaces/GPUEncodingExternalModels.cpp#L385-L395">implements the
SerializableAttr</a>
and it already has all the information. We are able to serve the needs from
target devices.</p>
<!-- markdownlint-disable -->
<details><summary>IR dump after the pass</summary>

<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span></pre></div></td><td class="code"><div><pre><span></span><code>util.func public @matmul_f32f32f32(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -&gt; !hal.buffer_view {
  %c0 = arith.constant 0 : index
  %c16 = arith.constant 16 : index
  %c128 = arith.constant 128 : index
  %c4 = arith.constant 4 : index
  %0 = hal.buffer_view.dim&lt;%arg0 : !hal.buffer_view&gt;[0] : index
  %1 = hal.buffer_view.dim&lt;%arg0 : !hal.buffer_view&gt;[1] : index
  %element_type_f32 = hal.element_type&lt;f32&gt; : i32
  %dense_row_major = hal.encoding_type&lt;dense_row_major&gt; : i32
  hal.buffer_view.assert&lt;%arg0 : !hal.buffer_view&gt; message(&quot;input0&quot;) shape([%0, %1]) type(%element_type_f32) encoding(%dense_row_major)
  %2 = arith.muli %0, %c4 : index
  %3 = arith.muli %2, %1 : index
  %4 = stream.tensor.import on(#hal.device.affinity&lt;@__device_0&gt;) %arg0 : !hal.buffer_view -&gt; tensor&lt;?x?xf32&gt;{%0, %1} in !stream.resource&lt;external&gt;{%3}
  %5 = stream.async.transfer %4 : !stream.resource&lt;external&gt;{%3} from(#hal.device.affinity&lt;@__device_0&gt;) -&gt; to(#hal.device.affinity&lt;@__device_0&gt;) !stream.resource&lt;*&gt;{%3}
  %6 = hal.buffer_view.dim&lt;%arg1 : !hal.buffer_view&gt;[0] : index
  %7 = hal.buffer_view.dim&lt;%arg1 : !hal.buffer_view&gt;[1] : index
  hal.buffer_view.assert&lt;%arg1 : !hal.buffer_view&gt; message(&quot;input1&quot;) shape([%6, %7]) type(%element_type_f32) encoding(%dense_row_major)
  %8 = arith.muli %6, %c4 : index
  %9 = arith.muli %8, %7 : index
  %10 = stream.tensor.import on(#hal.device.affinity&lt;@__device_0&gt;) %arg1 : !hal.buffer_view -&gt; tensor&lt;?x?xf32&gt;{%6, %7} in !stream.resource&lt;external&gt;{%9}
  %11 = stream.async.transfer %10 : !stream.resource&lt;external&gt;{%9} from(#hal.device.affinity&lt;@__device_0&gt;) -&gt; to(#hal.device.affinity&lt;@__device_0&gt;) !stream.resource&lt;*&gt;{%9}
<span class="hll">  %12 = arith.ceildivsi %0, %c128 : index
</span><span class="hll">  %13 = arith.muli %12, %c128 : index
</span><span class="hll">  %14 = arith.ceildivsi %1, %c16 : index
</span><span class="hll">  %15 = arith.muli %14, %c16 : index
</span><span class="hll">  %16 = arith.muli %13, %c4 : index
</span><span class="hll">  %17 = arith.muli %16, %15 : index
</span>  %18 = stream.tensor.encode on(#hal.device.affinity&lt;@__device_0&gt;) %5 : tensor&lt;?x?xf32&gt;{%0, %1} in !stream.resource&lt;*&gt;{%3} -&gt; tensor&lt;?x?xf32, #iree_encoding.layout&lt;[#iree_gpu.gpu_encoding_resolver&lt;configuration = {encoding_info = {innerDimsPos = [0, 1], innerTileSizes = [128, 16], outerDimsPerm = [0, 1], swizzle = {expandShape = [[[&quot;CrossThread&quot;, 4 : i16], [&quot;CrossIntrinsic&quot;, 8 : i16], [&quot;CrossThread&quot;, 4 : i16]], [[&quot;CrossIntrinsic&quot;, 4 : i16], [&quot;CrossThread&quot;, 4 : i16]]], permutation = [1, 4, 0, 2, 3]}}}&gt;]&gt;&gt;{%0, %1} in !stream.resource&lt;*&gt;{%17}
<span class="hll">  %19 = arith.ceildivsi %7, %c128 : index
</span><span class="hll">  %20 = arith.muli %19, %c128 : index
</span><span class="hll">  %21 = arith.ceildivsi %6, %c16 : index
</span><span class="hll">  %22 = arith.muli %21, %c16 : index
</span><span class="hll">  %23 = arith.muli %22, %c4 : index
</span><span class="hll">  %24 = arith.muli %23, %20 : index
</span>  %25 = stream.tensor.encode on(#hal.device.affinity&lt;@__device_0&gt;) %11 : tensor&lt;?x?xf32&gt;{%6, %7} in !stream.resource&lt;*&gt;{%9} -&gt; tensor&lt;?x?xf32, #iree_encoding.layout&lt;[#iree_gpu.gpu_encoding_resolver&lt;configuration = {encoding_info = {innerDimsPos = [1, 0], innerTileSizes = [128, 16], outerDimsPerm = [1, 0], swizzle = {expandShape = [[[&quot;CrossThread&quot;, 4 : i16], [&quot;CrossThread&quot;, 16 : i16], [&quot;CrossIntrinsic&quot;, 2 : i16]], [[&quot;CrossIntrinsic&quot;, 4 : i16], [&quot;CrossThread&quot;, 4 : i16]]], permutation = [0, 2, 4, 1, 3]}}}&gt;]&gt;&gt;{%6, %7} in !stream.resource&lt;*&gt;{%24}
<span class="hll">  %26 = arith.muli %0, %c4 : index
</span><span class="hll">  %27 = arith.muli %26, %7 : index
</span>  %28 = stream.async.dispatch on(#hal.device.affinity&lt;@__device_0&gt;) @matmul_f32f32f32_dispatch_0::@matmul_f32f32f32_dispatch_0_matmul_DxDxD_f32[%0, %1, %6, %7](%18[%c0 to %17 for %17], %25[%c0 to %24 for %24], %0, %1, %6, %7) : (!stream.resource&lt;*&gt;{%17}, !stream.resource&lt;*&gt;{%24}, index, index, index, index) -&gt; !stream.resource&lt;*&gt;{%27}
  %29 = stream.async.transfer %28 : !stream.resource&lt;*&gt;{%27} from(#hal.device.affinity&lt;@__device_0&gt;) -&gt; to(#hal.device.affinity&lt;@__device_0&gt;) !stream.resource&lt;external&gt;{%27}
  %30 = stream.tensor.export on(#hal.device.affinity&lt;@__device_0&gt;) %29 : tensor&lt;?x?xf32&gt;{%0, %7} in !stream.resource&lt;external&gt;{%27} -&gt; !hal.buffer_view
  util.return %30 : !hal.buffer_view
}
</code></pre></div></td></tr></table></div>

</details>
<!-- markdownlint-restore -->

<h3 id="materializeencodingspass-stream">MaterializeEncodingsPass (Stream)<a class="headerlink" href="#materializeencodingspass-stream" title="Permanent link">link</a></h3>
<p>After the encoding specialization, all the encodings are serialized. A
<code>stream.tensor.encode</code> op is folded away, if the source type is identical to the
result type. We may still see some <code>stream.tensor.encode</code> ops on the host
program, and it means that an actual relayout kernel is needed for the case.</p>
<p>The final step in the stream transformation is to materialize uniqued
executables for <code>stream.tensor.encode</code> ops and replace them with dispatches to
those executables.</p>
<!-- markdownlint-disable -->
<details><summary>IR dump after the pass</summary>

<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">  1</span>
<span class="normal">  2</span>
<span class="normal">  3</span>
<span class="normal">  4</span>
<span class="normal">  5</span>
<span class="normal">  6</span>
<span class="normal">  7</span>
<span class="normal">  8</span>
<span class="normal">  9</span>
<span class="normal"> 10</span>
<span class="normal"> 11</span>
<span class="normal"> 12</span>
<span class="normal"> 13</span>
<span class="normal"> 14</span>
<span class="normal"> 15</span>
<span class="normal"> 16</span>
<span class="normal"> 17</span>
<span class="normal"> 18</span>
<span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span></pre></div></td><td class="code"><div><pre><span></span><code>#encoding = #iree_encoding.layout&lt;[#iree_gpu.gpu_encoding_resolver&lt;configuration = {encoding_info = {innerDimsPos = [0, 1], innerTileSizes = [128, 16], outerDimsPerm = [0, 1], swizzle = {expandShape = [[[&quot;CrossThread&quot;, 4 : i16], [&quot;CrossIntrinsic&quot;, 8 : i16], [&quot;CrossThread&quot;, 4 : i16]], [[&quot;CrossIntrinsic&quot;, 4 : i16], [&quot;CrossThread&quot;, 4 : i16]]], permutation = [1, 4, 0, 2, 3]}}}&gt;]&gt;
#encoding1 = #iree_encoding.layout&lt;[#iree_gpu.gpu_encoding_resolver&lt;configuration = {encoding_info = {innerDimsPos = [1, 0], innerTileSizes = [128, 16], outerDimsPerm = [1, 0], swizzle = {expandShape = [[[&quot;CrossThread&quot;, 4 : i16], [&quot;CrossThread&quot;, 16 : i16], [&quot;CrossIntrinsic&quot;, 2 : i16]], [[&quot;CrossIntrinsic&quot;, 4 : i16], [&quot;CrossThread&quot;, 4 : i16]]], permutation = [0, 2, 4, 1, 3]}}}&gt;]&gt;
#executable_target_rocm_hsaco_fb = #hal.executable.target&lt;&quot;rocm&quot;, &quot;rocm-hsaco-fb&quot;, {abi = &quot;hip&quot;, iree.encoding.resolver = #iree_gpu.gpu_encoding_resolver&lt;&gt;, iree_codegen.default_tuning_spec = #rocm.builtin.tuning_module&lt;&quot;iree_default_tuning_spec_gfx942.mlir&quot;&gt;, iree_codegen.target_info = #iree_gpu.target&lt;arch = &quot;gfx942&quot;, features = &quot;&quot;, wgp = &lt;compute =  fp64|fp32|fp16|int64|int32|int16|int8, storage =  b64|b32|b16|b8, subgroup =  shuffle|arithmetic, dot =  dp4xi8toi32, mma = [&lt;MFMA_F32_16x16x16_BF16&gt;, &lt;MFMA_F32_32x32x8_BF16&gt;, &lt;MFMA_F32_16x16x32_F8E5M2FNUZ&gt;, &lt;MFMA_F32_16x16x32_F8E5M2FNUZ_F8E4M3FNUZ&gt;, &lt;MFMA_F32_16x16x32_F8E4M3FNUZ&gt;, &lt;MFMA_F32_16x16x32_F8E4M3FNUZ_F8E5M2FNUZ&gt;, &lt;MFMA_F32_32x32x16_F8E5M2FNUZ&gt;, &lt;MFMA_F32_32x32x16_F8E5M2FNUZ_F8E4M3FNUZ&gt;, &lt;MFMA_F32_32x32x16_F8E4M3FNUZ&gt;, &lt;MFMA_F32_32x32x16_F8E4M3FNUZ_F8E5M2FNUZ&gt;, &lt;MFMA_I32_16x16x32_I8&gt;, &lt;MFMA_I32_32x32x16_I8&gt;, &lt;MFMA_F64_16x16x4_F64&gt;, &lt;MFMA_F32_16x16x4_F32&gt;, &lt;MFMA_F32_16x16x16_F16&gt;, &lt;MFMA_F32_32x32x8_F16&gt;], subgroup_size_choices = [64], max_workgroup_sizes = [1024, 1024, 1024], max_thread_count_per_workgroup = 1024, max_workgroup_memory_bytes = 65536, max_workgroup_counts = [2147483647, 2147483647, 2147483647], max_load_instruction_bits = 128, simds_per_wgp = 4, vgpr_space_bits = 16384&gt;&gt;, ukernels = &quot;none&quot;}&gt;
#map = affine_map&lt;(d0, d1, d2) -&gt; (d0, d2)&gt;
#map1 = affine_map&lt;(d0, d1, d2) -&gt; (d2, d1)&gt;
#map2 = affine_map&lt;(d0, d1, d2) -&gt; (d0, d1)&gt;
#device_target_hip = #hal.device.target&lt;&quot;hip&quot;, [#executable_target_rocm_hsaco_fb]&gt; : !hal.device
#encoding2 = #iree_encoding.encoding&lt;operand_index = 0 : index, op_type =  matmul, element_types = [f32, f32, f32], user_indexing_maps = [#map, #map1, #map2], iteration_sizes = [?, ?, ?]&gt;
#encoding3 = #iree_encoding.encoding&lt;operand_index = 1 : index, op_type =  matmul, element_types = [f32, f32, f32], user_indexing_maps = [#map, #map1, #map2], iteration_sizes = [?, ?, ?]&gt;
#encoding4 = #iree_encoding.encoding&lt;operand_index = 2 : index, op_type =  matmul, element_types = [f32, f32, f32], user_indexing_maps = [#map, #map1, #map2], iteration_sizes = [?, ?, ?]&gt;
module attributes {stream.affinity.default = #hal.device.affinity&lt;@__device_0&gt;} {
  util.global private @__device_0 = #device_target_hip
  stream.executable private @matmul_f32f32f32_dispatch_0 {
    stream.executable.export public @matmul_f32f32f32_dispatch_0_matmul_DxDxD_f32 workgroups(%arg0: index, %arg1: index, %arg2: index, %arg3: index) -&gt; (index, index, index) {
      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice(%arg0, %arg1, %arg2, %arg3)
      stream.return %x, %y, %z : index, index, index
    }
    builtin.module {
      func.func @matmul_f32f32f32_dispatch_0_matmul_DxDxD_f32(%arg0: !stream.binding, %arg1: !stream.binding, %arg2: index, %arg3: index, %arg4: index, %arg5: index, %arg6: !stream.binding) {
        %c0 = arith.constant 0 : index
        %cst = arith.constant 0.000000e+00 : f32
        %0 = iree_tensor_ext.dispatch.workload.ordinal %arg2, 0 : index
        %1 = iree_tensor_ext.dispatch.workload.ordinal %arg3, 1 : index
        %2 = iree_tensor_ext.dispatch.workload.ordinal %arg4, 2 : index
        %3 = iree_tensor_ext.dispatch.workload.ordinal %arg5, 3 : index
        %4 = stream.binding.subspan %arg0[%c0] : !stream.binding -&gt; !iree_tensor_ext.dispatch.tensor&lt;readonly:tensor&lt;?x?xf32, #encoding&gt;&gt;{%0, %1}
        %5 = stream.binding.subspan %arg1[%c0] : !stream.binding -&gt; !iree_tensor_ext.dispatch.tensor&lt;readonly:tensor&lt;?x?xf32, #encoding1&gt;&gt;{%2, %3}
        %6 = stream.binding.subspan %arg6[%c0] : !stream.binding -&gt; !iree_tensor_ext.dispatch.tensor&lt;writeonly:tensor&lt;?x?xf32&gt;&gt;{%0, %3}
        %7 = iree_tensor_ext.dispatch.tensor.load %4, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor&lt;readonly:tensor&lt;?x?xf32, #encoding&gt;&gt;{%0, %1} -&gt; tensor&lt;?x?xf32, #encoding2&gt;
        %8 = iree_tensor_ext.dispatch.tensor.load %5, offsets = [0, 0], sizes = [%2, %3], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor&lt;readonly:tensor&lt;?x?xf32, #encoding1&gt;&gt;{%2, %3} -&gt; tensor&lt;?x?xf32, #encoding3&gt;
        %9 = tensor.empty(%0, %3) : tensor&lt;?x?xf32, #encoding4&gt;
        %10 = linalg.fill ins(%cst : f32) outs(%9 : tensor&lt;?x?xf32, #encoding4&gt;) -&gt; tensor&lt;?x?xf32, #encoding4&gt;
        %11 = linalg.matmul ins(%7, %8 : tensor&lt;?x?xf32, #encoding2&gt;, tensor&lt;?x?xf32, #encoding3&gt;) outs(%10 : tensor&lt;?x?xf32, #encoding4&gt;) -&gt; tensor&lt;?x?xf32, #encoding4&gt;
        %12 = iree_encoding.unset_encoding %11 : tensor&lt;?x?xf32, #encoding4&gt; -&gt; tensor&lt;?x?xf32&gt;{%0, %3}
        iree_tensor_ext.dispatch.tensor.store %12, %6, offsets = [0, 0], sizes = [%0, %3], strides = [1, 1] : tensor&lt;?x?xf32&gt; -&gt; !iree_tensor_ext.dispatch.tensor&lt;writeonly:tensor&lt;?x?xf32&gt;&gt;{%0, %3}
        return
      }
    }
  }
<span class="hll">  stream.executable private @_encoding_0 {
</span><span class="hll">    stream.executable.export public @_encoding_0_encode_DxDxf32_to_DxDxf32 workgroups(%arg0: index, %arg1: index, %arg2: index, %arg3: index) -&gt; (index, index, index) {
</span><span class="hll">      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice(%arg0, %arg1, %arg2, %arg3)
</span><span class="hll">      stream.return %x, %y, %z : index, index, index
</span><span class="hll">    }
</span><span class="hll">    builtin.module {
</span><span class="hll">      func.func @_encoding_0_encode_DxDxf32_to_DxDxf32(%arg0: !stream.binding, %arg1: index, %arg2: index, %arg3: index, %arg4: index, %arg5: !stream.binding) {
</span><span class="hll">        %0 = iree_tensor_ext.dispatch.workload.ordinal %arg1, 0 : index
</span><span class="hll">        %1 = iree_tensor_ext.dispatch.workload.ordinal %arg2, 1 : index
</span><span class="hll">        %2 = iree_tensor_ext.dispatch.workload.ordinal %arg3, 2 : index
</span><span class="hll">        %3 = iree_tensor_ext.dispatch.workload.ordinal %arg4, 3 : index
</span><span class="hll">        %c0 = arith.constant 0 : index
</span><span class="hll">        %4 = stream.binding.subspan %arg0[%c0] : !stream.binding -&gt; !iree_tensor_ext.dispatch.tensor&lt;readonly:tensor&lt;?x?xf32&gt;&gt;{%0, %1}
</span><span class="hll">        %5 = stream.binding.subspan %arg5[%c0] : !stream.binding -&gt; !iree_tensor_ext.dispatch.tensor&lt;writeonly:tensor&lt;?x?xf32, #encoding&gt;&gt;{%2, %3}
</span><span class="hll">        %6 = iree_tensor_ext.dispatch.tensor.load %4, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor&lt;readonly:tensor&lt;?x?xf32&gt;&gt;{%0, %1} -&gt; tensor&lt;?x?xf32&gt;
</span><span class="hll">        %7 = iree_encoding.set_encoding %6 : tensor&lt;?x?xf32&gt; -&gt; tensor&lt;?x?xf32, #encoding&gt;
</span><span class="hll">        iree_tensor_ext.dispatch.tensor.store %7, %5, offsets = [0, 0], sizes = [%2, %3], strides = [1, 1] : tensor&lt;?x?xf32, #encoding&gt; -&gt; !iree_tensor_ext.dispatch.tensor&lt;writeonly:tensor&lt;?x?xf32, #encoding&gt;&gt;{%2, %3}
</span><span class="hll">        return
</span><span class="hll">      }
</span><span class="hll">    }
</span><span class="hll">  }
</span><span class="hll">  stream.executable private @_encoding_1 {
</span><span class="hll">    stream.executable.export public @_encoding_1_encode_DxDxf32_to_DxDxf32 workgroups(%arg0: index, %arg1: index, %arg2: index, %arg3: index) -&gt; (index, index, index) {
</span><span class="hll">      %x, %y, %z = iree_tensor_ext.dispatch.workgroup_count_from_slice(%arg0, %arg1, %arg2, %arg3)
</span><span class="hll">      stream.return %x, %y, %z : index, index, index
</span><span class="hll">    }
</span><span class="hll">    builtin.module {
</span><span class="hll">      func.func @_encoding_1_encode_DxDxf32_to_DxDxf32(%arg0: !stream.binding, %arg1: index, %arg2: index, %arg3: index, %arg4: index, %arg5: !stream.binding) {
</span><span class="hll">        %0 = iree_tensor_ext.dispatch.workload.ordinal %arg1, 0 : index
</span><span class="hll">        %1 = iree_tensor_ext.dispatch.workload.ordinal %arg2, 1 : index
</span><span class="hll">        %2 = iree_tensor_ext.dispatch.workload.ordinal %arg3, 2 : index
</span><span class="hll">        %3 = iree_tensor_ext.dispatch.workload.ordinal %arg4, 3 : index
</span><span class="hll">        %c0 = arith.constant 0 : index
</span><span class="hll">        %4 = stream.binding.subspan %arg0[%c0] : !stream.binding -&gt; !iree_tensor_ext.dispatch.tensor&lt;readonly:tensor&lt;?x?xf32&gt;&gt;{%0, %1}
</span><span class="hll">        %5 = stream.binding.subspan %arg5[%c0] : !stream.binding -&gt; !iree_tensor_ext.dispatch.tensor&lt;writeonly:tensor&lt;?x?xf32, #encoding1&gt;&gt;{%2, %3}
</span><span class="hll">        %6 = iree_tensor_ext.dispatch.tensor.load %4, offsets = [0, 0], sizes = [%0, %1], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor&lt;readonly:tensor&lt;?x?xf32&gt;&gt;{%0, %1} -&gt; tensor&lt;?x?xf32&gt;
</span><span class="hll">        %7 = iree_encoding.set_encoding %6 : tensor&lt;?x?xf32&gt; -&gt; tensor&lt;?x?xf32, #encoding1&gt;
</span><span class="hll">        iree_tensor_ext.dispatch.tensor.store %7, %5, offsets = [0, 0], sizes = [%2, %3], strides = [1, 1] : tensor&lt;?x?xf32, #encoding1&gt; -&gt; !iree_tensor_ext.dispatch.tensor&lt;writeonly:tensor&lt;?x?xf32, #encoding1&gt;&gt;{%2, %3}
</span><span class="hll">        return
</span><span class="hll">      }
</span><span class="hll">    }
</span><span class="hll">  }
</span>  util.func public @matmul_f32f32f32(%arg0: !hal.buffer_view, %arg1: !hal.buffer_view) -&gt; !hal.buffer_view attributes {iree.abi.stub, iree.reflection = {iree.abi.declaration = &quot;sync func @matmul_f32f32f32(%input0: tensor&lt;?x?xf32&gt;, %input1: tensor&lt;?x?xf32&gt;) -&gt; (%output0: tensor&lt;?x?xf32&gt;)&quot;}} {
    %c0 = arith.constant 0 : index
    %c16 = arith.constant 16 : index
    %c128 = arith.constant 128 : index
    %c4 = arith.constant 4 : index
    %0 = hal.buffer_view.dim&lt;%arg0 : !hal.buffer_view&gt;[0] : index
    %1 = hal.buffer_view.dim&lt;%arg0 : !hal.buffer_view&gt;[1] : index
    %element_type_f32 = hal.element_type&lt;f32&gt; : i32
    %dense_row_major = hal.encoding_type&lt;dense_row_major&gt; : i32
    hal.buffer_view.assert&lt;%arg0 : !hal.buffer_view&gt; message(&quot;input0&quot;) shape([%0, %1]) type(%element_type_f32) encoding(%dense_row_major)
    %2 = arith.muli %0, %c4 : index
    %3 = arith.muli %2, %1 : index
    %4 = stream.tensor.import on(#hal.device.affinity&lt;@__device_0&gt;) %arg0 : !hal.buffer_view -&gt; tensor&lt;?x?xf32&gt;{%0, %1} in !stream.resource&lt;external&gt;{%3}
    %5 = stream.async.transfer %4 : !stream.resource&lt;external&gt;{%3} from(#hal.device.affinity&lt;@__device_0&gt;) -&gt; to(#hal.device.affinity&lt;@__device_0&gt;) !stream.resource&lt;*&gt;{%3}
    %6 = hal.buffer_view.dim&lt;%arg1 : !hal.buffer_view&gt;[0] : index
    %7 = hal.buffer_view.dim&lt;%arg1 : !hal.buffer_view&gt;[1] : index
    hal.buffer_view.assert&lt;%arg1 : !hal.buffer_view&gt; message(&quot;input1&quot;) shape([%6, %7]) type(%element_type_f32) encoding(%dense_row_major)
    %8 = arith.muli %6, %c4 : index
    %9 = arith.muli %8, %7 : index
    %10 = stream.tensor.import on(#hal.device.affinity&lt;@__device_0&gt;) %arg1 : !hal.buffer_view -&gt; tensor&lt;?x?xf32&gt;{%6, %7} in !stream.resource&lt;external&gt;{%9}
    %11 = stream.async.transfer %10 : !stream.resource&lt;external&gt;{%9} from(#hal.device.affinity&lt;@__device_0&gt;) -&gt; to(#hal.device.affinity&lt;@__device_0&gt;) !stream.resource&lt;*&gt;{%9}
    %12 = arith.ceildivsi %0, %c128 : index
    %13 = arith.muli %12, %c128 : index
    %14 = arith.ceildivsi %1, %c16 : index
    %15 = arith.muli %14, %c16 : index
    %16 = arith.muli %13, %c4 : index
    %17 = arith.muli %16, %15 : index
    %c0_0 = arith.constant 0 : index
<span class="hll">    %18 = stream.async.dispatch on(#hal.device.affinity&lt;@__device_0&gt;) @_encoding_0::@_encoding_0_encode_DxDxf32_to_DxDxf32[%0, %1, %0, %1](%5[%c0_0 to %3 for %3], %0, %1, %0, %1) : (!stream.resource&lt;*&gt;{%3}, index, index, index, index) -&gt; !stream.resource&lt;*&gt;{%17}
</span>    %19 = arith.ceildivsi %7, %c128 : index
    %20 = arith.muli %19, %c128 : index
    %21 = arith.ceildivsi %6, %c16 : index
    %22 = arith.muli %21, %c16 : index
    %23 = arith.muli %22, %c4 : index
    %24 = arith.muli %23, %20 : index
    %c0_1 = arith.constant 0 : index
<span class="hll">    %25 = stream.async.dispatch on(#hal.device.affinity&lt;@__device_0&gt;) @_encoding_1::@_encoding_1_encode_DxDxf32_to_DxDxf32[%6, %7, %6, %7](%11[%c0_1 to %9 for %9], %6, %7, %6, %7) : (!stream.resource&lt;*&gt;{%9}, index, index, index, index) -&gt; !stream.resource&lt;*&gt;{%24}
</span>    %26 = arith.muli %0, %c4 : index
    %27 = arith.muli %26, %7 : index
    %28 = stream.async.dispatch on(#hal.device.affinity&lt;@__device_0&gt;) @matmul_f32f32f32_dispatch_0::@matmul_f32f32f32_dispatch_0_matmul_DxDxD_f32[%0, %1, %6, %7](%18[%c0 to %17 for %17], %25[%c0 to %24 for %24], %0, %1, %6, %7) : (!stream.resource&lt;*&gt;{%17}, !stream.resource&lt;*&gt;{%24}, index, index, index, index) -&gt; !stream.resource&lt;*&gt;{%27}
    %29 = stream.async.transfer %28 : !stream.resource&lt;*&gt;{%27} from(#hal.device.affinity&lt;@__device_0&gt;) -&gt; to(#hal.device.affinity&lt;@__device_0&gt;) !stream.resource&lt;external&gt;{%27}
    %30 = stream.tensor.export on(#hal.device.affinity&lt;@__device_0&gt;) %29 : tensor&lt;?x?xf32&gt;{%0, %7} in !stream.resource&lt;external&gt;{%27} -&gt; !hal.buffer_view
    util.return %30 : !hal.buffer_view
  }
}
</code></pre></div></td></tr></table></div>

</details>
<!-- markdownlint-restore -->

<h2 id="code-generation-target-dependent">Code Generation (Target-Dependent)<a class="headerlink" href="#code-generation-target-dependent" title="Permanent link">link</a></h2>
<p>The post is using GPU as an example, but most context can be shared between
backends. E.g., materializing operations that have encodings is a common step
between backends. The only difference is how a resolver is implemented.</p>
<h3 id="materializedeviceencodingpass">MaterializeDeviceEncodingPass<a class="headerlink" href="#materializedeviceencodingpass" title="Permanent link">link</a></h3>
<p>The first step in code-generation is to materialize the ops that have encodings.
The pass uses the encoding resolver to do the conversion, and the patterns can
be found in
<a href="https://github.com/iree-org/iree/blob/main/compiler/src/iree/compiler/Codegen/Common/MaterializeEncodingPatterns.cpp">MaterializeEncodingPatterns.cpp</a>:</p>
<ul>
<li>The interface binding ops and load/store ops are replaced with the same op on
  packed domain.</li>
<li>The SetEncodingOp and UnSetEncodingOp are materialized to relayout ops, e.g.,
  <code>linalg.pack</code>, <code>linalg.unpack</code>, etc.</li>
<li>The compute ops, e.g., <code>linalg.matmul</code>, are replaced with the ops without
  encodings. In the example, the GPU encoding resolver lowers <code>linalg.matmul</code> to
  <code>iree_codegen.inner_tiled</code> ops. The implementation is done by
  <a href="https://github.com/iree-org/iree/blob/e6fb1e180438c4f78a1ea2bafd9a653fbe7a064b/compiler/src/iree/compiler/Codegen/ExternalInterfaces/GPUEncodingExternalModels.cpp#L364-L383">interface methods</a>.</li>
</ul>
<p>After the encoding materialization, the code-generation pipeline is as the same
as regular input. In the example, they all go down to GPU TileAndFuse pipeline.</p>
<h4 id="ir-dump">IR Dump<a class="headerlink" href="#ir-dump" title="Permanent link">link</a></h4>
<!-- markdownlint-disable -->
<details><summary>Gemm IR dump after the pass</summary>

<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span></pre></div></td><td class="code"><div><pre><span></span><code>func.func @matmul_f32f32f32_dispatch_0_matmul_DxDxD_f32() {
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.constant.load layout(&lt;constants = 10, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(&lt;constants = 10, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(&lt;constants = 10, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(&lt;constants = 10, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) ordinal(3) : i32
  %4 = hal.interface.constant.load layout(&lt;constants = 10, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) ordinal(4) : i32
  %5 = hal.interface.constant.load layout(&lt;constants = 10, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) ordinal(5) : i32
  %6 = hal.interface.constant.load layout(&lt;constants = 10, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) ordinal(6) : i32
  %7 = hal.interface.constant.load layout(&lt;constants = 10, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) ordinal(7) : i32
  %8 = hal.interface.constant.load layout(&lt;constants = 10, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) ordinal(8) : i32
  %9 = hal.interface.constant.load layout(&lt;constants = 10, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) ordinal(9) : i32
  %10 = arith.extui %0 : i32 to i64
  %11 = arith.extui %1 : i32 to i64
  %12 = arith.shli %11, %c32_i64 : i64
  %13 = arith.ori %10, %12 : i64
  %14 = arith.index_castui %13 : i64 to index
  %15 = arith.extui %2 : i32 to i64
  %16 = arith.extui %3 : i32 to i64
  %17 = arith.shli %16, %c32_i64 : i64
  %18 = arith.ori %15, %17 : i64
  %19 = arith.index_castui %18 : i64 to index
  %20 = arith.extui %4 : i32 to i64
  %21 = arith.extui %5 : i32 to i64
  %22 = arith.shli %21, %c32_i64 : i64
  %23 = arith.ori %20, %22 : i64
  %24 = arith.index_castui %23 : i64 to index
  %25 = arith.extui %6 : i32 to i64
  %26 = arith.extui %7 : i32 to i64
  %27 = arith.shli %26, %c32_i64 : i64
  %28 = arith.ori %25, %27 : i64
  %29 = arith.index_castui %28 : i64 to index
  %30 = arith.extui %8 : i32 to i64
  %31 = arith.extui %9 : i32 to i64
  %32 = arith.shli %31, %c32_i64 : i64
  %33 = arith.ori %30, %32 : i64
  %34 = arith.index_castui %33 : i64 to index
  %35:5 = util.assume.int
      %14&lt;udiv = 8192&gt;,
      %19&lt;umin = 0, umax = 9007199254740991&gt;,
      %24&lt;umin = 0, umax = 9007199254740991&gt;,
      %29&lt;umin = 0, umax = 9007199254740991&gt;,
      %34&lt;umin = 0, umax = 9007199254740991&gt;
    : index, index, index, index, index
  %36 = iree_tensor_ext.dispatch.workload.ordinal %35#1, 0 : index
  %37 = iree_tensor_ext.dispatch.workload.ordinal %35#2, 1 : index
  %38 = iree_tensor_ext.dispatch.workload.ordinal %35#3, 2 : index
  %39 = iree_tensor_ext.dispatch.workload.ordinal %35#4, 3 : index
  %40 = affine.apply affine_map&lt;()[s0] -&gt; (s0 ceildiv 128)&gt;()[%36]
  %41 = affine.apply affine_map&lt;()[s0] -&gt; (s0 ceildiv 16)&gt;()[%37]
  %42 = hal.interface.binding.subspan layout(&lt;constants = 10, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) binding(0) alignment(64) offset(%c0) flags(&quot;ReadOnly|Indirect&quot;) : !iree_tensor_ext.dispatch.tensor&lt;readonly:tensor&lt;?x?x8x4x4x4x4xf32&gt;&gt;{%40, %41}
  %43 = affine.apply affine_map&lt;()[s0] -&gt; (s0 ceildiv 128)&gt;()[%39]
  %44 = affine.apply affine_map&lt;()[s0] -&gt; (s0 ceildiv 16)&gt;()[%38]
  %45 = hal.interface.binding.subspan layout(&lt;constants = 10, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) binding(0) alignment(64) offset(%35#0) flags(&quot;ReadOnly|Indirect&quot;) : !iree_tensor_ext.dispatch.tensor&lt;readonly:tensor&lt;?x?x4x2x4x16x4xf32&gt;&gt;{%43, %44}
  %46 = hal.interface.binding.subspan layout(&lt;constants = 10, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) binding(1) alignment(64) offset(%c0) flags(Indirect) : !iree_tensor_ext.dispatch.tensor&lt;writeonly:tensor&lt;?x?xf32&gt;&gt;{%36, %39}
  %47 = iree_tensor_ext.dispatch.tensor.load %42, offsets = [0, 0, 0, 0, 0, 0, 0], sizes = [%40, %41, 8, 4, 4, 4, 4], strides = [1, 1, 1, 1, 1, 1, 1] : !iree_tensor_ext.dispatch.tensor&lt;readonly:tensor&lt;?x?x8x4x4x4x4xf32&gt;&gt;{%40, %41} -&gt; tensor&lt;?x?x8x4x4x4x4xf32&gt;
  %48 = iree_tensor_ext.dispatch.tensor.load %45, offsets = [0, 0, 0, 0, 0, 0, 0], sizes = [%43, %44, 4, 2, 4, 16, 4], strides = [1, 1, 1, 1, 1, 1, 1] : !iree_tensor_ext.dispatch.tensor&lt;readonly:tensor&lt;?x?x4x2x4x16x4xf32&gt;&gt;{%43, %44} -&gt; tensor&lt;?x?x4x2x4x16x4xf32&gt;
<span class="hll">  %49 = tensor.empty(%40, %43) : tensor&lt;?x?x4x8x2x4x16x4xf32&gt;
</span><span class="hll">  %50 = linalg.fill ins(%cst : f32) outs(%49 : tensor&lt;?x?x4x8x2x4x16x4xf32&gt;) -&gt; tensor&lt;?x?x4x8x2x4x16x4xf32&gt;
</span><span class="hll">  %51 = iree_codegen.inner_tiled ins(%47, %48) outs(%50) {indexing_maps = [affine_map&lt;(d0, d1, d2) -&gt; (d0, d2)&gt;, affine_map&lt;(d0, d1, d2) -&gt; (d1, d2)&gt;, affine_map&lt;(d0, d1, d2) -&gt; (d0, d1)&gt;], iterator_types = [#linalg.iterator_type&lt;parallel&gt;, #linalg.iterator_type&lt;parallel&gt;, #linalg.iterator_type&lt;reduction&gt;], kind = #iree_gpu.data_tiled_mma_layout&lt;intrinsic = MFMA_F32_16x16x4_F32, intrinsics_m = 8, intrinsics_n = 2, subgroups_n = 4, intrinsics_k = 4, operands_interleaving_intrinsics_k = [0, 1]&gt;} : tensor&lt;?x?x8x4x4x4x4xf32&gt;, tensor&lt;?x?x4x2x4x16x4xf32&gt; into tensor&lt;?x?x4x8x2x4x16x4xf32&gt;
</span><span class="hll">  %dim = tensor.dim %51, %c0 : tensor&lt;?x?x4x8x2x4x16x4xf32&gt;
</span><span class="hll">  %dim_0 = tensor.dim %51, %c1 : tensor&lt;?x?x4x8x2x4x16x4xf32&gt;
</span><span class="hll">  %52 = tensor.empty(%dim, %dim_0) : tensor&lt;?x?x4x8x4x4x16x2xf32&gt;
</span><span class="hll">  %transposed = linalg.transpose ins(%51 : tensor&lt;?x?x4x8x2x4x16x4xf32&gt;) outs(%52 : tensor&lt;?x?x4x8x4x4x16x2xf32&gt;) permutation = [0, 1, 5, 3, 7, 2, 6, 4]
</span><span class="hll">  %collapsed = tensor.collapse_shape %transposed [[0], [1], [2, 3, 4], [5, 6, 7]] : tensor&lt;?x?x4x8x4x4x16x2xf32&gt; into tensor&lt;?x?x128x128xf32&gt;
</span><span class="hll">  %53 = tensor.empty(%36, %39) : tensor&lt;?x?xf32&gt;
</span><span class="hll">  %unpack = linalg.unpack %collapsed outer_dims_perm = [0, 1] inner_dims_pos = [0, 1] inner_tiles = [128, 128] into %53 : tensor&lt;?x?x128x128xf32&gt; -&gt; tensor&lt;?x?xf32&gt;
</span>  iree_tensor_ext.dispatch.tensor.store %unpack, %46, offsets = [0, 0], sizes = [%36, %39], strides = [1, 1] : tensor&lt;?x?xf32&gt; -&gt; !iree_tensor_ext.dispatch.tensor&lt;writeonly:tensor&lt;?x?xf32&gt;&gt;{%36, %39}
  return
}
</code></pre></div></td></tr></table></div>

</details>
<!-- markdownlint-restore -->

<!-- markdownlint-disable -->
<details><summary>Relayout IR dump after the pass</summary>

<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span></pre></div></td><td class="code"><div><pre><span></span><code>func.func @_encoding_0_encode_DxDxf32_to_DxDxf32() {
  %cst = arith.constant 0.000000e+00 : f32
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %0 = hal.interface.constant.load layout(&lt;constants = 4, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(&lt;constants = 4, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(&lt;constants = 4, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(&lt;constants = 4, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) ordinal(3) : i32
  %4 = arith.extui %0 : i32 to i64
  %5 = arith.extui %1 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.ori %4, %6 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %2 : i32 to i64
  %10 = arith.extui %3 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.ori %9, %11 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:4 = util.assume.int
      %8&lt;umin = 0, umax = 9007199254740991&gt;,
      %13&lt;umin = 0, umax = 9007199254740991&gt;,
      %8&lt;umin = 0, umax = 9007199254740991&gt;,
      %13&lt;umin = 0, umax = 9007199254740991&gt;
<span class="hll">    : index, index, index, index
</span><span class="hll">  %15 = iree_tensor_ext.dispatch.workload.ordinal %14#0, 0 : index
</span><span class="hll">  %16 = iree_tensor_ext.dispatch.workload.ordinal %14#1, 1 : index
</span><span class="hll">  %17 = iree_tensor_ext.dispatch.workload.ordinal %14#2, 2 : index
</span><span class="hll">  %18 = iree_tensor_ext.dispatch.workload.ordinal %14#3, 3 : index
</span><span class="hll">  %19 = hal.interface.binding.subspan layout(&lt;constants = 4, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) binding(0) alignment(64) offset(%c0) flags(&quot;ReadOnly|Indirect&quot;) : !iree_tensor_ext.dispatch.tensor&lt;readonly:tensor&lt;?x?xf32&gt;&gt;{%15, %16}
</span><span class="hll">  %20 = affine.apply affine_map&lt;()[s0] -&gt; (s0 ceildiv 128)&gt;()[%17]
</span><span class="hll">  %21 = affine.apply affine_map&lt;()[s0] -&gt; (s0 ceildiv 16)&gt;()[%18]
</span><span class="hll">  %22 = hal.interface.binding.subspan layout(&lt;constants = 4, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) binding(1) alignment(64) offset(%c0) flags(Indirect) : !iree_tensor_ext.dispatch.tensor&lt;writeonly:tensor&lt;?x?x8x4x4x4x4xf32&gt;&gt;{%20, %21}
</span><span class="hll">  %23 = iree_tensor_ext.dispatch.tensor.load %19, offsets = [0, 0], sizes = [%15, %16], strides = [1, 1] : !iree_tensor_ext.dispatch.tensor&lt;readonly:tensor&lt;?x?xf32&gt;&gt;{%15, %16} -&gt; tensor&lt;?x?xf32&gt;
</span><span class="hll">  %24 = affine.apply affine_map&lt;()[s0] -&gt; (s0 ceildiv 128)&gt;()[%15]
</span><span class="hll">  %25 = affine.apply affine_map&lt;()[s0] -&gt; (s0 ceildiv 16)&gt;()[%16]
</span><span class="hll">  %26 = tensor.empty(%24, %25) : tensor&lt;?x?x128x16xf32&gt;
</span><span class="hll">  %pack = linalg.pack %23 padding_value(%cst : f32) outer_dims_perm = [0, 1] inner_dims_pos = [0, 1] inner_tiles = [128, 16] into %26 : tensor&lt;?x?xf32&gt; -&gt; tensor&lt;?x?x128x16xf32&gt;
</span><span class="hll">  %expanded = tensor.expand_shape %pack [[0], [1], [2, 3, 4], [5, 6]] output_shape [%24, %25, 4, 8, 4, 4, 4] : tensor&lt;?x?x128x16xf32&gt; into tensor&lt;?x?x4x8x4x4x4xf32&gt;
</span><span class="hll">  %27 = tensor.empty(%24, %25) : tensor&lt;?x?x8x4x4x4x4xf32&gt;
</span><span class="hll">  %transposed = linalg.transpose ins(%expanded : tensor&lt;?x?x4x8x4x4x4xf32&gt;) outs(%27 : tensor&lt;?x?x8x4x4x4x4xf32&gt;) permutation = [0, 1, 3, 6, 2, 4, 5]
</span>  iree_tensor_ext.dispatch.tensor.store %transposed, %22, offsets = [0, 0, 0, 0, 0, 0, 0], sizes = [%20, %21, 8, 4, 4, 4, 4], strides = [1, 1, 1, 1, 1, 1, 1] : tensor&lt;?x?x8x4x4x4x4xf32&gt; -&gt; !iree_tensor_ext.dispatch.tensor&lt;writeonly:tensor&lt;?x?x8x4x4x4x4xf32&gt;&gt;{%20, %21}
  return
}
</code></pre></div></td></tr></table></div>

</details>
<!-- markdownlint-restore -->

<h4 id="challenge-code-generation-for-index-remapping">Challenge: Code Generation for Index Remapping<a class="headerlink" href="#challenge-code-generation-for-index-remapping" title="Permanent link">link</a></h4>
<p>Index remapping is hard, because some ops do not implement <code>TilingInterface</code>.
IREE develops <a href="https://github.com/iree-org/iree/blob/e6fb1e180438c4f78a1ea2bafd9a653fbe7a064b/compiler/src/iree/compiler/Dialect/LinalgExt/IR/LinalgExtOps.td#L334-L349">LinalgExt::MapScatterOp</a>
to represent the index remapping. Since unpack ops have slicing semantics, the
<code>LinalgExt::MapScatterOp</code> yields an additional i1 value that represents the
<code>mask</code>.</p>
<p>Furthermore, <code>linalg.pack</code> ops have padding semantics; it is really hard to
represent such indexing remapping in pure tensor world, because the index
space is not 1-1 mapping and it requires padding values getting written.</p>
<p>IREE takes an early bufferization approach, that bufferizes the boundaries and
capture the core operations on tensors. If there are padding, it generates a
<code>scf.forall</code> op that writes the padding value.</p>
<p>The design idea is using the same codegen pipeline even if relayout ops are
fused within the dispatch region. E.g., developers do not need to rework on the
codegen of attention dispatches because the fusion happens automatically in the
case.</p>
<h3 id="bufferizedispatchtensorloadstorepass">BufferizeDispatchTensorLoadStorePass<a class="headerlink" href="#bufferizedispatchtensorloadstorepass" title="Permanent link">link</a></h3>
<p>The pass bufferizes the edges of dispatch regions, converting
<code>iree_tensor_ext.dispatch.tensor.load</code> ops to <code>iree_codegen.load_from_buffer</code>,
and <code>iree_tensor_ext.dispatch.tensor.store</code> ops to
<code>iree_codegen.store_to_buffer</code>.</p>
<!-- markdownlint-disable -->
<details><summary>Gemm IR dump after the pass</summary>

<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span></pre></div></td><td class="code"><div><pre><span></span><code>func.func @matmul_f32f32f32_dispatch_0_matmul_DxDxD_f32() {
  %c32_i64 = arith.constant 32 : i64
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.constant.load layout(&lt;constants = 10, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(&lt;constants = 10, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(&lt;constants = 10, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(&lt;constants = 10, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) ordinal(3) : i32
  %4 = hal.interface.constant.load layout(&lt;constants = 10, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) ordinal(4) : i32
  %5 = hal.interface.constant.load layout(&lt;constants = 10, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) ordinal(5) : i32
  %6 = hal.interface.constant.load layout(&lt;constants = 10, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) ordinal(6) : i32
  %7 = hal.interface.constant.load layout(&lt;constants = 10, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) ordinal(7) : i32
  %8 = hal.interface.constant.load layout(&lt;constants = 10, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) ordinal(8) : i32
  %9 = hal.interface.constant.load layout(&lt;constants = 10, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) ordinal(9) : i32
  %10 = arith.extui %0 : i32 to i64
  %11 = arith.extui %1 : i32 to i64
  %12 = arith.shli %11, %c32_i64 : i64
  %13 = arith.ori %10, %12 : i64
  %14 = arith.index_castui %13 : i64 to index
  %15 = arith.extui %2 : i32 to i64
  %16 = arith.extui %3 : i32 to i64
  %17 = arith.shli %16, %c32_i64 : i64
  %18 = arith.ori %15, %17 : i64
  %19 = arith.index_castui %18 : i64 to index
  %20 = arith.extui %4 : i32 to i64
  %21 = arith.extui %5 : i32 to i64
  %22 = arith.shli %21, %c32_i64 : i64
  %23 = arith.ori %20, %22 : i64
  %24 = arith.index_castui %23 : i64 to index
  %25 = arith.extui %6 : i32 to i64
  %26 = arith.extui %7 : i32 to i64
  %27 = arith.shli %26, %c32_i64 : i64
  %28 = arith.ori %25, %27 : i64
  %29 = arith.index_castui %28 : i64 to index
  %30 = arith.extui %8 : i32 to i64
  %31 = arith.extui %9 : i32 to i64
  %32 = arith.shli %31, %c32_i64 : i64
  %33 = arith.ori %30, %32 : i64
  %34 = arith.index_castui %33 : i64 to index
  %35:5 = util.assume.int
      %14&lt;udiv = 8192&gt;,
      %19&lt;umin = 0, umax = 9007199254740991&gt;,
      %24&lt;umin = 0, umax = 9007199254740991&gt;,
      %29&lt;umin = 0, umax = 9007199254740991&gt;,
      %34&lt;umin = 0, umax = 9007199254740991&gt;
    : index, index, index, index, index
  %36 = iree_tensor_ext.dispatch.workload.ordinal %35#1, 0 : index
  %37 = iree_tensor_ext.dispatch.workload.ordinal %35#2, 1 : index
  %38 = iree_tensor_ext.dispatch.workload.ordinal %35#3, 2 : index
  %39 = iree_tensor_ext.dispatch.workload.ordinal %35#4, 3 : index
  %40 = affine.apply affine_map&lt;()[s0] -&gt; (s0 ceildiv 128)&gt;()[%36]
  %41 = affine.apply affine_map&lt;()[s0] -&gt; (s0 ceildiv 16)&gt;()[%37]
  %42 = hal.interface.binding.subspan layout(&lt;constants = 10, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) binding(0) alignment(64) offset(%c0) flags(&quot;ReadOnly|Indirect&quot;) : memref&lt;?x?x8x4x4x4x4xf32, #hal.descriptor_type&lt;storage_buffer&gt;&gt;{%40, %41}
  %43 = hal.interface.binding.subspan layout(&lt;constants = 10, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) binding(0) alignment(64) offset(%c0) flags(&quot;ReadOnly|Indirect&quot;) : !iree_tensor_ext.dispatch.tensor&lt;readonly:tensor&lt;?x?x8x4x4x4x4xf32&gt;&gt;{%40, %41}
  %44 = affine.apply affine_map&lt;()[s0] -&gt; (s0 ceildiv 128)&gt;()[%39]
  %45 = affine.apply affine_map&lt;()[s0] -&gt; (s0 ceildiv 16)&gt;()[%38]
  %46 = hal.interface.binding.subspan layout(&lt;constants = 10, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) binding(0) alignment(64) offset(%35#0) flags(&quot;ReadOnly|Indirect&quot;) : memref&lt;?x?x4x2x4x16x4xf32, strided&lt;[?, 2048, 512, 256, 64, 4, 1], offset: ?&gt;, #hal.descriptor_type&lt;storage_buffer&gt;&gt;{%44, %45}
  %47 = hal.interface.binding.subspan layout(&lt;constants = 10, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) binding(0) alignment(64) offset(%35#0) flags(&quot;ReadOnly|Indirect&quot;) : !iree_tensor_ext.dispatch.tensor&lt;readonly:tensor&lt;?x?x4x2x4x16x4xf32&gt;&gt;{%44, %45}
  %48 = hal.interface.binding.subspan layout(&lt;constants = 10, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref&lt;?x?xf32, #hal.descriptor_type&lt;storage_buffer&gt;&gt;{%36, %39}
  %49 = hal.interface.binding.subspan layout(&lt;constants = 10, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) binding(1) alignment(64) offset(%c0) flags(Indirect) : !iree_tensor_ext.dispatch.tensor&lt;writeonly:tensor&lt;?x?xf32&gt;&gt;{%36, %39}
<span class="hll">  %50 = iree_codegen.load_from_buffer %42 : memref&lt;?x?x8x4x4x4x4xf32, #hal.descriptor_type&lt;storage_buffer&gt;&gt; -&gt; tensor&lt;?x?x8x4x4x4x4xf32&gt;
</span><span class="hll">  %51 = iree_codegen.load_from_buffer %46 : memref&lt;?x?x4x2x4x16x4xf32, strided&lt;[?, 2048, 512, 256, 64, 4, 1], offset: ?&gt;, #hal.descriptor_type&lt;storage_buffer&gt;&gt; -&gt; tensor&lt;?x?x4x2x4x16x4xf32&gt;
</span>  %52 = tensor.empty(%40, %44) : tensor&lt;?x?x4x8x2x4x16x4xf32&gt;
  %53 = linalg.fill ins(%cst : f32) outs(%52 : tensor&lt;?x?x4x8x2x4x16x4xf32&gt;) -&gt; tensor&lt;?x?x4x8x2x4x16x4xf32&gt;
  %54 = iree_codegen.inner_tiled ins(%50, %51) outs(%53) {indexing_maps = [affine_map&lt;(d0, d1, d2) -&gt; (d0, d2)&gt;, affine_map&lt;(d0, d1, d2) -&gt; (d1, d2)&gt;, affine_map&lt;(d0, d1, d2) -&gt; (d0, d1)&gt;], iterator_types = [#linalg.iterator_type&lt;parallel&gt;, #linalg.iterator_type&lt;parallel&gt;, #linalg.iterator_type&lt;reduction&gt;], kind = #iree_gpu.data_tiled_mma_layout&lt;intrinsic = MFMA_F32_16x16x4_F32, intrinsics_m = 8, intrinsics_n = 2, subgroups_n = 4, intrinsics_k = 4, operands_interleaving_intrinsics_k = [0, 1]&gt;} : tensor&lt;?x?x8x4x4x4x4xf32&gt;, tensor&lt;?x?x4x2x4x16x4xf32&gt; into tensor&lt;?x?x4x8x2x4x16x4xf32&gt;
  %55 = tensor.empty(%40, %44) : tensor&lt;?x?x4x8x4x4x16x2xf32&gt;
  %56 = linalg.generic {indexing_maps = [affine_map&lt;(d0, d1, d2, d3, d4, d5, d6, d7) -&gt; (d0, d1, d5, d3, d7, d2, d6, d4)&gt;, affine_map&lt;(d0, d1, d2, d3, d4, d5, d6, d7) -&gt; (d0, d1, d2, d3, d4, d5, d6, d7)&gt;], iterator_types = [&quot;parallel&quot;, &quot;parallel&quot;, &quot;parallel&quot;, &quot;parallel&quot;, &quot;parallel&quot;, &quot;parallel&quot;, &quot;parallel&quot;, &quot;parallel&quot;]} ins(%54 : tensor&lt;?x?x4x8x2x4x16x4xf32&gt;) outs(%55 : tensor&lt;?x?x4x8x4x4x16x2xf32&gt;) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -&gt; tensor&lt;?x?x4x8x4x4x16x2xf32&gt;
  %collapsed = tensor.collapse_shape %56 [[0], [1], [2, 3, 4], [5, 6, 7]] : tensor&lt;?x?x4x8x4x4x16x2xf32&gt; into tensor&lt;?x?x128x128xf32&gt;
  %57 = tensor.empty(%36, %39) : tensor&lt;?x?xf32&gt;
  %unpack = linalg.unpack %collapsed outer_dims_perm = [0, 1] inner_dims_pos = [0, 1] inner_tiles = [128, 128] into %57 : tensor&lt;?x?x128x128xf32&gt; -&gt; tensor&lt;?x?xf32&gt;
<span class="hll">  iree_codegen.store_to_buffer %unpack, %48 : tensor&lt;?x?xf32&gt; into memref&lt;?x?xf32, #hal.descriptor_type&lt;storage_buffer&gt;&gt;
</span>  return
}
</code></pre></div></td></tr></table></div>

</details>
<!-- markdownlint-restore -->

<!-- markdownlint-disable -->
<details><summary>Relayout IR dump after the pass</summary>

<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span></pre></div></td><td class="code"><div><pre><span></span><code>func.func @_encoding_0_encode_DxDxf32_to_DxDxf32() {
  %cst = arith.constant 0.000000e+00 : f32
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %0 = hal.interface.constant.load layout(&lt;constants = 4, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(&lt;constants = 4, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(&lt;constants = 4, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(&lt;constants = 4, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) ordinal(3) : i32
  %4 = arith.extui %0 : i32 to i64
  %5 = arith.extui %1 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.ori %4, %6 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %2 : i32 to i64
  %10 = arith.extui %3 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.ori %9, %11 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int
      %8&lt;umin = 0, umax = 9007199254740991&gt;,
      %13&lt;umin = 0, umax = 9007199254740991&gt;
    : index, index
  %15 = iree_tensor_ext.dispatch.workload.ordinal %14#0, 0 : index
  %16 = iree_tensor_ext.dispatch.workload.ordinal %14#1, 1 : index
  %17 = iree_tensor_ext.dispatch.workload.ordinal %14#0, 2 : index
  %18 = iree_tensor_ext.dispatch.workload.ordinal %14#1, 3 : index
  %19 = hal.interface.binding.subspan layout(&lt;constants = 4, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) binding(0) alignment(64) offset(%c0) flags(&quot;ReadOnly|Indirect&quot;) : memref&lt;?x?xf32, #hal.descriptor_type&lt;storage_buffer&gt;&gt;{%15, %16}
  %20 = hal.interface.binding.subspan layout(&lt;constants = 4, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) binding(0) alignment(64) offset(%c0) flags(&quot;ReadOnly|Indirect&quot;) : !iree_tensor_ext.dispatch.tensor&lt;readonly:tensor&lt;?x?xf32&gt;&gt;{%15, %16}
  %21 = affine.apply affine_map&lt;()[s0] -&gt; (s0 ceildiv 128)&gt;()[%17]
  %22 = affine.apply affine_map&lt;()[s0] -&gt; (s0 ceildiv 16)&gt;()[%18]
  %23 = hal.interface.binding.subspan layout(&lt;constants = 4, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref&lt;?x?x8x4x4x4x4xf32, #hal.descriptor_type&lt;storage_buffer&gt;&gt;{%21, %22}
  %24 = hal.interface.binding.subspan layout(&lt;constants = 4, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) binding(1) alignment(64) offset(%c0) flags(Indirect) : !iree_tensor_ext.dispatch.tensor&lt;writeonly:tensor&lt;?x?x8x4x4x4x4xf32&gt;&gt;{%21, %22}
<span class="hll">  %25 = iree_codegen.load_from_buffer %19 : memref&lt;?x?xf32, #hal.descriptor_type&lt;storage_buffer&gt;&gt; -&gt; tensor&lt;?x?xf32&gt;
</span>  %26 = affine.apply affine_map&lt;()[s0] -&gt; (s0 ceildiv 128)&gt;()[%15]
  %27 = affine.apply affine_map&lt;()[s0] -&gt; (s0 ceildiv 16)&gt;()[%16]
  %28 = tensor.empty(%26, %27) : tensor&lt;?x?x128x16xf32&gt;
  %pack = linalg.pack %25 padding_value(%cst : f32) outer_dims_perm = [0, 1] inner_dims_pos = [0, 1] inner_tiles = [128, 16] into %28 : tensor&lt;?x?xf32&gt; -&gt; tensor&lt;?x?x128x16xf32&gt;
  %expanded = tensor.expand_shape %pack [[0], [1], [2, 3, 4], [5, 6]] output_shape [%26, %27, 4, 8, 4, 4, 4] : tensor&lt;?x?x128x16xf32&gt; into tensor&lt;?x?x4x8x4x4x4xf32&gt;
  %29 = tensor.empty(%26, %27) : tensor&lt;?x?x8x4x4x4x4xf32&gt;
  %30 = linalg.generic {indexing_maps = [affine_map&lt;(d0, d1, d2, d3, d4, d5, d6) -&gt; (d0, d1, d4, d2, d5, d6, d3)&gt;, affine_map&lt;(d0, d1, d2, d3, d4, d5, d6) -&gt; (d0, d1, d2, d3, d4, d5, d6)&gt;], iterator_types = [&quot;parallel&quot;, &quot;parallel&quot;, &quot;parallel&quot;, &quot;parallel&quot;, &quot;parallel&quot;, &quot;parallel&quot;, &quot;parallel&quot;]} ins(%expanded : tensor&lt;?x?x4x8x4x4x4xf32&gt;) outs(%29 : tensor&lt;?x?x8x4x4x4x4xf32&gt;) {
  ^bb0(%in: f32, %out: f32):
    linalg.yield %in : f32
  } -&gt; tensor&lt;?x?x8x4x4x4x4xf32&gt;
<span class="hll">  iree_codegen.store_to_buffer %30, %23 : tensor&lt;?x?x8x4x4x4x4xf32&gt; into memref&lt;?x?x8x4x4x4x4xf32, #hal.descriptor_type&lt;storage_buffer&gt;&gt;
</span>  return
}
</code></pre></div></td></tr></table></div>

</details>
<!-- markdownlint-restore -->

<h3 id="gpucombinelayouttransformationpass">GPUCombineLayoutTransformationPass<a class="headerlink" href="#gpucombinelayouttransformationpass" title="Permanent link">link</a></h3>
<p>Starting from <code>iree_codegen.store_to_buffer</code> ops, iteratively combine producer
layout/indexing transformation ops (<code>linalg.transpose</code>, <code>tensor.collapse_shape</code>,
etc.) into a single <code>iree_linalg_ext.map_scatter</code> operation. For <code>tensor.pad</code>
ops, the writing of pad values is distributed to workgroups and threads, and
then the padding values are written directly to the output buffer of the
<code>iree_codegen.store_to_buffer</code> op.</p>
<!-- markdownlint-disable -->
<details><summary>IR dump after the pass</summary>

<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span>
<span class="normal">86</span>
<span class="normal">87</span>
<span class="normal">88</span></pre></div></td><td class="code"><div><pre><span></span><code>func.func @matmul_f32f32f32_dispatch_0_matmul_DxDxD_f32() {
  %c1 = arith.constant 1 : index
  %c32_i64 = arith.constant 32 : i64
  %cst = arith.constant 0.000000e+00 : f32
  %c0 = arith.constant 0 : index
  %0 = hal.interface.constant.load layout(&lt;constants = 10, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(&lt;constants = 10, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(&lt;constants = 10, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(&lt;constants = 10, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) ordinal(3) : i32
  %4 = hal.interface.constant.load layout(&lt;constants = 10, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) ordinal(4) : i32
  %5 = hal.interface.constant.load layout(&lt;constants = 10, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) ordinal(5) : i32
  %6 = hal.interface.constant.load layout(&lt;constants = 10, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) ordinal(6) : i32
  %7 = hal.interface.constant.load layout(&lt;constants = 10, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) ordinal(7) : i32
  %8 = hal.interface.constant.load layout(&lt;constants = 10, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) ordinal(8) : i32
  %9 = hal.interface.constant.load layout(&lt;constants = 10, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) ordinal(9) : i32
  %10 = arith.extui %0 : i32 to i64
  %11 = arith.extui %1 : i32 to i64
  %12 = arith.shli %11, %c32_i64 : i64
  %13 = arith.ori %10, %12 : i64
  %14 = arith.index_castui %13 : i64 to index
  %15 = arith.extui %2 : i32 to i64
  %16 = arith.extui %3 : i32 to i64
  %17 = arith.shli %16, %c32_i64 : i64
  %18 = arith.ori %15, %17 : i64
  %19 = arith.index_castui %18 : i64 to index
  %20 = arith.extui %4 : i32 to i64
  %21 = arith.extui %5 : i32 to i64
  %22 = arith.shli %21, %c32_i64 : i64
  %23 = arith.ori %20, %22 : i64
  %24 = arith.index_castui %23 : i64 to index
  %25 = arith.extui %6 : i32 to i64
  %26 = arith.extui %7 : i32 to i64
  %27 = arith.shli %26, %c32_i64 : i64
  %28 = arith.ori %25, %27 : i64
  %29 = arith.index_castui %28 : i64 to index
  %30 = arith.extui %8 : i32 to i64
  %31 = arith.extui %9 : i32 to i64
  %32 = arith.shli %31, %c32_i64 : i64
  %33 = arith.ori %30, %32 : i64
  %34 = arith.index_castui %33 : i64 to index
  %35:5 = util.assume.int
      %14&lt;udiv = 8192&gt;,
      %19&lt;umin = 0, umax = 9007199254740991&gt;,
      %24&lt;umin = 0, umax = 9007199254740991&gt;,
      %29&lt;umin = 0, umax = 9007199254740991&gt;,
      %34&lt;umin = 0, umax = 9007199254740991&gt;
    : index, index, index, index, index
  %36 = iree_tensor_ext.dispatch.workload.ordinal %35#1, 0 : index
  %37 = iree_tensor_ext.dispatch.workload.ordinal %35#2, 1 : index
  %38 = iree_tensor_ext.dispatch.workload.ordinal %35#3, 2 : index
  %39 = iree_tensor_ext.dispatch.workload.ordinal %35#4, 3 : index
  %40 = affine.apply affine_map&lt;()[s0] -&gt; (s0 ceildiv 128)&gt;()[%36]
  %41 = affine.apply affine_map&lt;()[s0] -&gt; (s0 ceildiv 16)&gt;()[%37]
  %42 = hal.interface.binding.subspan layout(&lt;constants = 10, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) binding(0) alignment(64) offset(%c0) flags(&quot;ReadOnly|Indirect&quot;) : memref&lt;?x?x8x4x4x4x4xf32, #hal.descriptor_type&lt;storage_buffer&gt;&gt;{%40, %41}
  %43 = affine.apply affine_map&lt;()[s0] -&gt; (s0 ceildiv 128)&gt;()[%39]
  %44 = affine.apply affine_map&lt;()[s0] -&gt; (s0 ceildiv 16)&gt;()[%38]
  %45 = hal.interface.binding.subspan layout(&lt;constants = 10, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) binding(0) alignment(64) offset(%35#0) flags(&quot;ReadOnly|Indirect&quot;) : memref&lt;?x?x4x2x4x16x4xf32, strided&lt;[?, 2048, 512, 256, 64, 4, 1], offset: ?&gt;, #hal.descriptor_type&lt;storage_buffer&gt;&gt;{%43, %44}
  %46 = hal.interface.binding.subspan layout(&lt;constants = 10, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref&lt;?x?xf32, #hal.descriptor_type&lt;storage_buffer&gt;&gt;{%36, %39}
  %47 = iree_codegen.load_from_buffer %42 : memref&lt;?x?x8x4x4x4x4xf32, #hal.descriptor_type&lt;storage_buffer&gt;&gt; -&gt; tensor&lt;?x?x8x4x4x4x4xf32&gt;
  %48 = iree_codegen.load_from_buffer %45 : memref&lt;?x?x4x2x4x16x4xf32, strided&lt;[?, 2048, 512, 256, 64, 4, 1], offset: ?&gt;, #hal.descriptor_type&lt;storage_buffer&gt;&gt; -&gt; tensor&lt;?x?x4x2x4x16x4xf32&gt;
  %49 = tensor.empty(%40, %43) : tensor&lt;?x?x4x8x2x4x16x4xf32&gt;
  %50 = linalg.fill ins(%cst : f32) outs(%49 : tensor&lt;?x?x4x8x2x4x16x4xf32&gt;) -&gt; tensor&lt;?x?x4x8x2x4x16x4xf32&gt;
  %51 = iree_codegen.inner_tiled ins(%47, %48) outs(%50) {indexing_maps = [affine_map&lt;(d0, d1, d2) -&gt; (d0, d2)&gt;, affine_map&lt;(d0, d1, d2) -&gt; (d1, d2)&gt;, affine_map&lt;(d0, d1, d2) -&gt; (d0, d1)&gt;], iterator_types = [#linalg.iterator_type&lt;parallel&gt;, #linalg.iterator_type&lt;parallel&gt;, #linalg.iterator_type&lt;reduction&gt;], kind = #iree_gpu.data_tiled_mma_layout&lt;intrinsic = MFMA_F32_16x16x4_F32, intrinsics_m = 8, intrinsics_n = 2, subgroups_n = 4, intrinsics_k = 4, operands_interleaving_intrinsics_k = [0, 1]&gt;} : tensor&lt;?x?x8x4x4x4x4xf32&gt;, tensor&lt;?x?x4x2x4x16x4xf32&gt; into tensor&lt;?x?x4x8x2x4x16x4xf32&gt;
  %dim = tensor.dim %51, %c0 : tensor&lt;?x?x4x8x2x4x16x4xf32&gt;
  %dim_0 = tensor.dim %51, %c1 : tensor&lt;?x?x4x8x2x4x16x4xf32&gt;
  %dim_1 = tensor.dim %51, %c0 : tensor&lt;?x?x4x8x2x4x16x4xf32&gt;
  %dim_2 = tensor.dim %51, %c1 : tensor&lt;?x?x4x8x2x4x16x4xf32&gt;
  %dim_3 = tensor.dim %51, %c0 : tensor&lt;?x?x4x8x2x4x16x4xf32&gt;
  %dim_4 = tensor.dim %51, %c1 : tensor&lt;?x?x4x8x2x4x16x4xf32&gt;
  %dim_5 = tensor.dim %51, %c0 : tensor&lt;?x?x4x8x2x4x16x4xf32&gt;
  %52 = affine.apply affine_map&lt;()[s0] -&gt; (s0 * 128)&gt;()[%dim_5]
  %dim_6 = tensor.dim %51, %c1 : tensor&lt;?x?x4x8x2x4x16x4xf32&gt;
  %53 = affine.apply affine_map&lt;()[s0] -&gt; (s0 * 128)&gt;()[%dim_6]
  %54 = tensor.empty(%36, %39) : tensor&lt;?x?xf32&gt;
<span class="hll">  %55 = iree_linalg_ext.map_scatter %51 into %54 {
</span><span class="hll">  ^bb0(%arg0: index, %arg1: index, %arg2: index, %arg3: index, %arg4: index, %arg5: index, %arg6: index, %arg7: index):
</span><span class="hll">    %56 = affine.linearize_index disjoint [%arg0, %arg1, %arg5, %arg3, %arg7, %arg2, %arg6, %arg4] by (%dim, %dim_0, 4, 8, 4, 4, 16, 2) : index
</span><span class="hll">    %57:4 = affine.delinearize_index %56 into (%dim_1, %dim_2, 128, 128) : index, index, index, index
</span><span class="hll">    %58 = affine.linearize_index disjoint [%57#0, %57#2, %57#1, %57#3] by (%dim_3, 128, %dim_4, 128) : index
</span><span class="hll">    %59:2 = affine.delinearize_index %58 into (%52, %53) : index, index
</span><span class="hll">    %60 = arith.cmpi ult, %59#0, %36 : index
</span><span class="hll">    %61 = arith.cmpi ult, %59#1, %39 : index
</span><span class="hll">    %62 = arith.andi %60, %61 : i1
</span><span class="hll">    iree_linalg_ext.yield %59#0, %59#1, %62 : index, index, i1
</span><span class="hll">  } : tensor&lt;?x?x4x8x2x4x16x4xf32&gt; into tensor&lt;?x?xf32&gt; -&gt; tensor&lt;?x?xf32&gt;
</span>  iree_codegen.store_to_buffer %55, %46 : tensor&lt;?x?xf32&gt; into memref&lt;?x?xf32, #hal.descriptor_type&lt;storage_buffer&gt;&gt;
  return
}
</code></pre></div></td></tr></table></div>

</details>
<!-- markdownlint-restore -->

<!-- markdownlint-disable -->
<details><summary>IR dump after the pass</summary>

<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span>
<span class="normal">86</span>
<span class="normal">87</span>
<span class="normal">88</span>
<span class="normal">89</span>
<span class="normal">90</span>
<span class="normal">91</span>
<span class="normal">92</span>
<span class="normal">93</span>
<span class="normal">94</span>
<span class="normal">95</span></pre></div></td><td class="code"><div><pre><span></span><code>func.func @_encoding_0_encode_DxDxf32_to_DxDxf32() {
  %c1 = arith.constant 1 : index
  %true = arith.constant true
  %c16 = arith.constant 16 : index
  %c128 = arith.constant 128 : index
  %cst = arith.constant 0.000000e+00 : f32
  %c32_i64 = arith.constant 32 : i64
  %c0 = arith.constant 0 : index
  %0 = hal.interface.constant.load layout(&lt;constants = 4, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) ordinal(0) : i32
  %1 = hal.interface.constant.load layout(&lt;constants = 4, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) ordinal(1) : i32
  %2 = hal.interface.constant.load layout(&lt;constants = 4, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) ordinal(2) : i32
  %3 = hal.interface.constant.load layout(&lt;constants = 4, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) ordinal(3) : i32
  %4 = arith.extui %0 : i32 to i64
  %5 = arith.extui %1 : i32 to i64
  %6 = arith.shli %5, %c32_i64 : i64
  %7 = arith.ori %4, %6 : i64
  %8 = arith.index_castui %7 : i64 to index
  %9 = arith.extui %2 : i32 to i64
  %10 = arith.extui %3 : i32 to i64
  %11 = arith.shli %10, %c32_i64 : i64
  %12 = arith.ori %9, %11 : i64
  %13 = arith.index_castui %12 : i64 to index
  %14:2 = util.assume.int
      %8&lt;umin = 0, umax = 9007199254740991&gt;,
      %13&lt;umin = 0, umax = 9007199254740991&gt;
    : index, index
  %15 = iree_tensor_ext.dispatch.workload.ordinal %14#0, 0 : index
  %16 = iree_tensor_ext.dispatch.workload.ordinal %14#1, 1 : index
  %17 = iree_tensor_ext.dispatch.workload.ordinal %14#0, 2 : index
  %18 = iree_tensor_ext.dispatch.workload.ordinal %14#1, 3 : index
  %19 = hal.interface.binding.subspan layout(&lt;constants = 4, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) binding(0) alignment(64) offset(%c0) flags(&quot;ReadOnly|Indirect&quot;) : memref&lt;?x?xf32, #hal.descriptor_type&lt;storage_buffer&gt;&gt;{%15, %16}
  %20 = affine.apply affine_map&lt;()[s0] -&gt; (s0 ceildiv 128)&gt;()[%17]
  %21 = affine.apply affine_map&lt;()[s0] -&gt; (s0 ceildiv 16)&gt;()[%18]
  %22 = hal.interface.binding.subspan layout(&lt;constants = 4, bindings = [#hal.pipeline.binding&lt;storage_buffer, &quot;ReadOnly|Indirect&quot;&gt;, #hal.pipeline.binding&lt;storage_buffer, Indirect&gt;], flags = Indirect&gt;) binding(1) alignment(64) offset(%c0) flags(Indirect) : memref&lt;?x?x8x4x4x4x4xf32, #hal.descriptor_type&lt;storage_buffer&gt;&gt;{%20, %21}
  %23 = iree_codegen.load_from_buffer %19 : memref&lt;?x?xf32, #hal.descriptor_type&lt;storage_buffer&gt;&gt; -&gt; tensor&lt;?x?xf32&gt;
  %24 = affine.apply affine_map&lt;()[s0] -&gt; (s0 ceildiv 128)&gt;()[%15]
  %25 = affine.apply affine_map&lt;()[s0] -&gt; (s0 ceildiv 16)&gt;()[%16]
  %26 = affine.apply affine_map&lt;()[s0, s1, s2] -&gt; (s0 * 128 - s1 + s2)&gt;()[%24, %15, %15]
  %27 = affine.apply affine_map&lt;()[s0, s1, s2] -&gt; (s0 * 16 - s1 + s2)&gt;()[%25, %16, %16]
  %28 = arith.divsi %26, %c128 : index
  %29 = arith.divsi %27, %c16 : index
  %30 = affine.apply affine_map&lt;()[s0, s1, s2] -&gt; (s0 * 128 - s1 + s2)&gt;()[%24, %15, %15]
  %31 = affine.apply affine_map&lt;()[s0, s1, s2] -&gt; (s0 * 16 - s1 + s2)&gt;()[%25, %16, %16]
  %32 = tensor.empty(%24, %25) : tensor&lt;?x?x8x4x4x4x4xf32&gt;
<span class="hll">  %33 = iree_linalg_ext.map_scatter %23 into %32 {
</span><span class="hll">  ^bb0(%arg0: index, %arg1: index):
</span><span class="hll">    %36 = affine.linearize_index disjoint [%arg0, %arg1] by (%30, %31) : index
</span><span class="hll">    %37:4 = affine.delinearize_index %36 into (%28, 128, %29, 16) : index, index, index, index
</span><span class="hll">    %38 = affine.linearize_index disjoint [%37#0, %37#2, %37#1, %37#3] by (%28, %29, 128, 16) : index
</span><span class="hll">    %39:7 = affine.delinearize_index %38 into (%24, %25, 4, 8, 4, 4, 4) : index, index, index, index, index, index, index
</span><span class="hll">    iree_linalg_ext.yield %39#0, %39#1, %39#3, %39#6, %39#2, %39#4, %39#5, %true : index, index, index, index, index, index, index, i1
</span><span class="hll">  } : tensor&lt;?x?xf32&gt; into tensor&lt;?x?x8x4x4x4x4xf32&gt; -&gt; tensor&lt;?x?x8x4x4x4x4xf32&gt;
</span>  iree_codegen.store_to_buffer %33, %22 : tensor&lt;?x?x8x4x4x4x4xf32&gt; into memref&lt;?x?x8x4x4x4x4xf32, #hal.descriptor_type&lt;storage_buffer&gt;&gt;
  %34 = affine.apply affine_map&lt;()[s0, s1, s2] -&gt; (s0 * 128 - s1 + s2)&gt;()[%24, %15, %15]
  %35 = affine.apply affine_map&lt;()[s0, s1, s2] -&gt; (s0 * 16 - s1 + s2)&gt;()[%25, %16, %16]
<span class="hll">  scf.forall (%arg0, %arg1) = (%15, 0) to (%34, %35) step (1, 64) {
</span><span class="hll">    %36 = affine.min affine_map&lt;(d0)[s0] -&gt; (d0 + 1, s0)&gt;(%arg0)[%34]
</span><span class="hll">    %37 = affine.min affine_map&lt;(d0)[s0] -&gt; (d0 + 64, s0)&gt;(%arg1)[%35]
</span><span class="hll">    scf.forall (%arg2, %arg3) = (%arg0, %arg1) to (%36, %37) step (1, 1) {
</span><span class="hll">      %38 = affine.min affine_map&lt;(d0, d1) -&gt; (d0 + 1, d1)&gt;(%arg2, %36)
</span><span class="hll">      %39 = affine.min affine_map&lt;(d0, d1) -&gt; (d0 + 1, d1)&gt;(%arg3, %37)
</span><span class="hll">      scf.for %arg4 = %arg2 to %38 step %c1 {
</span><span class="hll">        scf.for %arg5 = %arg3 to %39 step %c1 {
</span><span class="hll">          %40 = affine.linearize_index disjoint [%arg4, %arg5] by (%30, %31) : index
</span><span class="hll">          %41:4 = affine.delinearize_index %40 into (%28, 128, %29, 16) : index, index, index, index
</span><span class="hll">          %42 = affine.linearize_index disjoint [%41#0, %41#2, %41#1, %41#3] by (%28, %29, 128, 16) : index
</span><span class="hll">          %43:7 = affine.delinearize_index %42 into (%24, %25, 4, 8, 4, 4, 4) : index, index, index, index, index, index, index
</span><span class="hll">          scf.if %true {
</span><span class="hll">            memref.store %cst, %22[%43#0, %43#1, %43#3, %43#6, %43#2, %43#4, %43#5] : memref&lt;?x?x8x4x4x4x4xf32, #hal.descriptor_type&lt;storage_buffer&gt;&gt;
</span><span class="hll">          }
</span><span class="hll">        }
</span><span class="hll">      }
</span><span class="hll">    } {mapping = [#gpu.thread&lt;linear_dim_1&gt;, #gpu.thread&lt;linear_dim_0&gt;]}
</span><span class="hll">  } {mapping = [#iree_codegen.workgroup_mapping&lt;x&gt;, #iree_codegen.workgroup_mapping&lt;y&gt;]}
</span><span class="hll">  scf.forall (%arg0, %arg1) = (0, %16) to (%34, %35) step (1, 64) {
</span><span class="hll">    %36 = affine.min affine_map&lt;(d0)[s0] -&gt; (d0 + 1, s0)&gt;(%arg0)[%34]
</span><span class="hll">    %37 = affine.min affine_map&lt;(d0)[s0] -&gt; (d0 + 64, s0)&gt;(%arg1)[%35]
</span><span class="hll">    scf.forall (%arg2, %arg3) = (%arg0, %arg1) to (%36, %37) step (1, 1) {
</span><span class="hll">      %38 = affine.min affine_map&lt;(d0, d1) -&gt; (d0 + 1, d1)&gt;(%arg2, %36)
</span><span class="hll">      %39 = affine.min affine_map&lt;(d0, d1) -&gt; (d0 + 1, d1)&gt;(%arg3, %37)
</span><span class="hll">      scf.for %arg4 = %arg2 to %38 step %c1 {
</span><span class="hll">        scf.for %arg5 = %arg3 to %39 step %c1 {
</span><span class="hll">          %40 = affine.linearize_index disjoint [%arg4, %arg5] by (%30, %31) : index
</span><span class="hll">          %41:4 = affine.delinearize_index %40 into (%28, 128, %29, 16) : index, index, index, index
</span><span class="hll">          %42 = affine.linearize_index disjoint [%41#0, %41#2, %41#1, %41#3] by (%28, %29, 128, 16) : index
</span><span class="hll">          %43:7 = affine.delinearize_index %42 into (%24, %25, 4, 8, 4, 4, 4) : index, index, index, index, index, index, index
</span><span class="hll">          scf.if %true {
</span><span class="hll">            memref.store %cst, %22[%43#0, %43#1, %43#3, %43#6, %43#2, %43#4, %43#5] : memref&lt;?x?x8x4x4x4x4xf32, #hal.descriptor_type&lt;storage_buffer&gt;&gt;
</span><span class="hll">          }
</span><span class="hll">        }
</span><span class="hll">      }
</span><span class="hll">    } {mapping = [#gpu.thread&lt;linear_dim_1&gt;, #gpu.thread&lt;linear_dim_0&gt;]}
</span><span class="hll">  } {mapping = [#iree_codegen.workgroup_mapping&lt;x&gt;, #iree_codegen.workgroup_mapping&lt;y&gt;]}
</span>  return
}
</code></pre></div></td></tr></table></div>

</details>
<!-- markdownlint-restore -->

<h2 id="build-your-own-encoding-attributes-and-resolver">Build Your Own Encoding Attributes and Resolver<a class="headerlink" href="#build-your-own-encoding-attributes-and-resolver" title="Permanent link">link</a></h2>
<p>Data-tiling is an optional optimization technique, and it is not supported by
all backends. The targets that support data-tiling are:</p>
<ul>
<li>CPU (x86)</li>
<li>CPU (AArch64)</li>
<li>CPU (RISC-V)</li>
<li>GPU (ROCm)</li>
<li>VMVX</li>
</ul>
<p>More targets may be supported in the future, and contributions are welcome. You
can explore the available options in
<a href="https://github.com/iree-org/iree/tree/main/compiler/src/iree/compiler/Codegen/ExternalInterfaces">Codegen/ExternalInterfaces/</a>.</p>
<p>The encoding type attributes are defined in
<a href="https://github.com/iree-org/iree/blob/main/compiler/src/iree/compiler/Dialect/Encoding/IR/EncodingAttrs.td">EncodingAttrs.td</a>;
the target-specific encoding resolvers, which decide how these attributes are
lowered, are defined in their dialects. E.g., CPU defines the encoding
resolvers in
<a href="https://github.com/iree-org/iree/blob/main/compiler/src/iree/compiler/Codegen/Dialect/CPU/IR/IREECPUAttrs.td">IREECPUAttrs.td</a>,
and GPU defines the encoding resolvers in
<a href="https://github.com/iree-org/iree/blob/main/compiler/src/iree/compiler/Codegen/Dialect/GPU/IR/IREEGPUAttrs.td">IREEGPUAttrs.td</a>.</p>
<p>The interface implementations are isolated in
<a href="https://github.com/iree-org/iree/tree/main/compiler/src/iree/compiler/Codegen/ExternalInterfaces">Codegen/ExternalInterfaces/</a>,
to avoid moving domain-specific logic into the dialect implementations. You can
follow one of the implementations to build your own encoding resolver.</p>







  
  




  



      
    </article>
  </div>

          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2025 IREE a Series of LF Projects, LLC.
For web site terms of use, trademark policy and other project policies please
see <a href="https://lfprojects.org">https://lfprojects.org</a>.

    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    
    
    <a href="https://github.com/iree-org/iree" target="_blank" rel="noopener" title="IREE on GitHub" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
    
    
    
    
    <a href="https://discord.gg/wEWh6Z9nMU" target="_blank" rel="noopener" title="IREE Discord Server" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M524.531 69.836a1.5 1.5 0 0 0-.764-.7A485 485 0 0 0 404.081 32.03a1.82 1.82 0 0 0-1.923.91 338 338 0 0 0-14.9 30.6 447.9 447.9 0 0 0-134.426 0 310 310 0 0 0-15.135-30.6 1.89 1.89 0 0 0-1.924-.91 483.7 483.7 0 0 0-119.688 37.107 1.7 1.7 0 0 0-.788.676C39.068 183.651 18.186 294.69 28.43 404.354a2.02 2.02 0 0 0 .765 1.375 487.7 487.7 0 0 0 146.825 74.189 1.9 1.9 0 0 0 2.063-.676A348 348 0 0 0 208.12 430.4a1.86 1.86 0 0 0-1.019-2.588 321 321 0 0 1-45.868-21.853 1.885 1.885 0 0 1-.185-3.126 251 251 0 0 0 9.109-7.137 1.82 1.82 0 0 1 1.9-.256c96.229 43.917 200.41 43.917 295.5 0a1.81 1.81 0 0 1 1.924.233 235 235 0 0 0 9.132 7.16 1.884 1.884 0 0 1-.162 3.126 301.4 301.4 0 0 1-45.89 21.83 1.875 1.875 0 0 0-1 2.611 391 391 0 0 0 30.014 48.815 1.86 1.86 0 0 0 2.063.7A486 486 0 0 0 610.7 405.729a1.88 1.88 0 0 0 .765-1.352c12.264-126.783-20.532-236.912-86.934-334.541M222.491 337.58c-28.972 0-52.844-26.587-52.844-59.239s23.409-59.241 52.844-59.241c29.665 0 53.306 26.82 52.843 59.239 0 32.654-23.41 59.241-52.843 59.241m195.38 0c-28.971 0-52.843-26.587-52.843-59.239s23.409-59.241 52.843-59.241c29.667 0 53.307 26.82 52.844 59.239 0 32.654-23.177 59.241-52.844 59.241"/></svg>
    </a>
  
    
    
    
    
    <a href="https://lists.lfaidata.foundation/g/iree-announce" target="_blank" rel="noopener" title="IREE Announcement Mailing List" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M480 32c0-12.9-7.8-24.6-19.8-29.6S434.5.2 425.3 9.3L381.7 53c-48 48-113.1 75-181 75H64c-35.3 0-64 28.7-64 64v96c0 35.3 28.7 64 64 64v128c0 17.7 14.3 32 32 32h64c17.7 0 32-14.3 32-32V352h8.7c67.9 0 133 27 181 75l43.6 43.6c9.2 9.2 22.9 11.9 34.9 6.9s19.8-16.6 19.8-29.6V300.3c18.6-8.8 32-32.5 32-60.4s-13.4-51.6-32-60.4zm-64 76.7v262.6C357.2 317.8 280.5 288 200.7 288H192v-96h8.7c79.8 0 156.5-29.8 215.3-83.3"/></svg>
    </a>
  
    
    
    
    
    <a href="https://lists.lfaidata.foundation/g/iree-technical-discussion" target="_blank" rel="noopener" title="IREE Technical Discussion Mailing List" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M48 64C21.5 64 0 85.5 0 112c0 15.1 7.1 29.3 19.2 38.4l217.6 163.2c11.4 8.5 27 8.5 38.4 0l217.6-163.2c12.1-9.1 19.2-23.3 19.2-38.4 0-26.5-21.5-48-48-48zM0 176v208c0 35.3 28.7 64 64 64h384c35.3 0 64-28.7 64-64V176L294.4 339.2a63.9 63.9 0 0 1-76.8 0z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../..", "features": ["content.action.edit", "content.code.annotate", "content.code.copy", "content.tabs.link", "navigation.instant", "navigation.tracking", "navigation.sections", "navigation.expand", "navigation.tabs", "navigation.tabs.sticky", "navigation.top", "navigation.indexes", "toc.follow"], "search": "../../../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.83f73b43.min.js"></script>
      
    
  </body>
</html>